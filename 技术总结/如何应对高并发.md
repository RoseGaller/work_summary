 高并发的本质，**就是海量的读和写**

# 如何应对高并发

## 架构原则：“4 要 1 不要”

### 1、数据要尽量少	

首先是指用户请求的数据能少就少。

其次，还要求系统依赖的数据能少就少，包括系统完成某些业务逻辑需要读取和保存的数据

### 2、请求数要尽量少

减少请求数最常用的一个实践就是合并 CSS 和 JavaScript 文件

合并请求

门面模式，为客户端访问的多个接口提供统一的接口

客户端限制单位时间内请求次数

按钮置灰，不可点击

浏览器、App端缓存

Nginx内容缓存

​		Nginx 会将多个并发请求合并为1条回源请求，并锁住所有的客户端请求，直到回源请求返回后，才会更新缓存，同时向所有客户端返回响应

### 3、路径要尽量短

缩短请求路径不仅可以增加可用性，同样可以有效提升性能（减少中间节点可以减少数据的序列化与反序列化），并减少延时

多个相互强依赖的应用合并部署在一起，把远程过程调用（RPC）变成 JVM 内部之间的方法调用

多机房部署，避免跨机房服务调用

将数据放在离用户近的地方，DNS用户就近接入，CDN

将频繁访问数据，放入缓存

### 4、依赖要尽量少

所谓依赖，指的是要完成一次用户请求必须依赖的系统或者服务，这里的依赖指的是强依赖。

要减少依赖，我们可以给系统进行分级，比如 0 级系统、1 级系统、2 级系统、3 级系统，0 级系统如果是最重要的系统，那么 0 级系统强依赖的系统也同样是最重要的系统

### 5、不要有单点

应用无状态化，可以任意扩容。但是要注意下游依赖所支撑的上限

存储服务本身很难无状态化，一般要通过冗余多个备份的方式来解决单点问题

**架构是一种平衡的艺术，而最好的架构一旦脱离了它所适应的场景，一切都将是空谈。**

## 流量削峰

### 排队

最容易想到的解决方案就是用消息队列来缓冲瞬时流量，把同步的直接调用转换成异步的间接推送，中间通过一个队列在一端承接瞬时的流量洪峰，在另一端平滑地将消息推送出去。

排队，就是把“一步的操作”变成“两步的操作”，其中增加的一步操作用来起到缓冲的作用

### 答题

延缓请求，起到对请求流量进行削峰的作用，从而让系统能够更好地支持瞬时的流量高峰

### 分层过滤

层过滤其实就是采用“漏斗”的方式，对请求进行分层过滤，从而过滤掉一些无效的请求

大部分数据和流量在用户浏览器或者 CDN 上获取，这一层可以拦截大部分数据的读取

nginx代也可以缓存数据，拦截大部分数据的读取

应用服务层，本地缓存、远端缓存，对系统做好保护和限流

数据库层完成数据的强一致性校验

## 处理热点数据

1、优化

优化热点数据最有效的办法就是缓存热点数据，本地缓存、远端缓存（redis）、nginx缓存、多副本存放

2、限制

限制更多的是一种保护机制

对热点数据的key计算Hash，然后根据 Hash 做分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点数据占用太多的服务器资源，而使其他请求始终得不到处理

3、隔离

数据隔离

​	启用单独的 Cache 集群或者MySQL 数据库来放热点数据

系统隔离

​	系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外 99% 分开，让请求落到不同集群中

## 如何设计兜底方案

### 高可用建设

#### 架构阶段

避免系统出现单点、分组隔离，单元化部署、异步化、异地容灾

#### 编码阶段

错误捕获

异步线程

超时处理

限流保护

#### 测试阶段

自动化对比测试、beta测试

#### 发布阶段

多版本发布/分批发布

#### 运行阶段

实时监控报警

过载保护

自动降级

#### 故障发生

快速恢复

故障定位

### 降级

所谓“降级”，就是当系统的容量达到一定程度时，限制或者关闭系统的某些非核心功能，从而把有限的资源保留给更核心的业务

执行降级无疑是在系统性能和用户体验之间选择了前者

### 限流

当系统容量达到瓶颈时，通过限制一部分流量来保护系统，并做到既可以人工执行开关，也支持自动化保护的措施

限流既可以是在客户端限流，也可以是在服务端限流

限流的实现方式既要支持 URL 以及方法级别的限流，也要支持基于QPS 和线程的限流

### 拒绝服务

当系统负载达到一定阈值时，例如 CPU 使用率达到 90% 或者系统 load 值达到 2*CPU 核数时，系统直接拒绝所有请求

在最前端的 Nginx 上设置过载保护，当机器负载达到某个值时直接拒绝HTTP 请求并返回 503 错误码，在 Java 层同样也可以设计过载保护

## 提高性能

### 性能指标

服务端性能，一般用 QPS（Query Per Second，每秒请求数）来衡量，另一个就是响应时间（Response Time，RT），它可以理解为服务器处理响应的耗时

正常情况下响应时间（RT）越短，一秒钟处理的请求数（QPS）自然也就会越多

总 QPS =（1000ms / 响应时间）× 线程数量

### 影响因素

性能就和两个因素相关了，一个是一次响应的服务端耗时，一个是处理请求的线程数

要提升性能我们就要减少 CPU 的执行时间，另外就是要设置一个合理的并发线程数，通过这两方面来显著提升服务器的性能

### 如何发现瓶颈

JProfiler 和 Yourkit 这两个工具，它们可以列出整个请求中每个函数的 CPU 执行时间，可以发现哪个函数消耗的 CPU 时间最多，以便针对性地做优化

怎样简单地判断 CPU 是不是瓶颈呢？一个办法就是看当 QPS 达到极限时，服务器的CPU 使用率是不是超过了 95%，如果没有超过，那么表示 CPU 还有提升的空间，要么是有锁限制，要么是有过多的本地 I/O 等待发生。

### 如何优化系统

1、 减少序列化

序列化大部分是在 RPC 中发生的，因此避免或者减少 RPC 就可以减少序列化

可以将多个关联性比较强的应用进行“合并部署”，而减少不同应用之间的 RPC 也可以减少序列化的消耗。
所谓“合并部署”，就是把两个原本在不同机器上的不同应用合并部署到一台机器上，当然不仅仅是部署在一台机器上，还要在同一个 Tomcat 容器中，且不能走本机的 Socket，这样才能避免序列化的产生

2、Java 极致优化

对大流量的 Web 系统做静态化改造，让大部分请求和数据直接在 Nginx 服务器或者 Web 代理服务器（如 Varnish、Squid 等）上直接返回，而 Java 层只需处理少量数据的动态请求

直接使用 Servlet 处理请求，避免使用传统的 MVC 框架

直接输出流数据。使用 resp.getOutputStream() 而不是 resp.getWriter() 函数，可以省掉一些不变字符数据的编码，从而提升性能；数据输出时推荐使用 JSON 而不是模板引擎（一般都是解释执行）来输出页面

3、并发读优化

采用应用层的 LocalCache，即在系统的单机上缓存相关的数据

对于动态数据，会采用“被动失效”的方式缓存一定时间，失效后再去缓存拉取最新的数据

数据中心优化

​	采用多数据中心方案，就近为区域用户提供服务，加快响应速度

硬件优化

​	cpu、内存、磁盘、网络

操作系统优化

​	cpu、内存、磁盘、网络

虚拟机优化

​	比如垃圾回收，可能会导致应用程序出现巨大的卡顿

基础组件优化

​	比如 Web 容器，数据库连接池，MVC 框架等等

架构优化

​	缓存：减少后端计算压力，提升读的性能

​	消息队列：异步进行计算处理提升写的性能

​	集群：将单一服务器进行伸缩，构建成一个集群完成同一种计算任务，从而提高系统在高并发压力时候的性能。

代码优化

​	利用各种设计模式和设计原则，开发清晰、易维护的代码

​	使用线程池、连接池等对象池化技术，复用资源，减少资源的创建

​	高性能的数据结构

​	编写性能更好的 SQL 语句以及使用更好的数据库访问方式

​	实现异步 I/O 与异步方法调用，避免不必要的阻塞

## 海量读请求

### 分散的读请求

当百万的 QPS 属于不同用户时，因缓存是集群化的，所有到达业务后台的请求会根据一定路由规则，分散到请求缓存集群中的某一个节点

假设一个节点最大能够支撑10WQPS，我们只需要在集群中部署 10 台节点即可支持百万流量

#### 1、架构尽量不要分层

​	读服务的业务逻辑都比较简单，性能主要消耗在网络传输上。读服务要尽可能和数据靠近，减少网络传输

​	比如数据前置，浏览器缓存、CDN缓存

#### 2、代码尽可能简单

​	精细化地按需打印日志

​	对于读取的内容要在存储处按需取，如果存储为 MySQL，则不要使用 select *，需要手动指定你要查询的字段。如果存储为 Redis，则使用 Redis 的 hash 结构存储数据

#### 3、缓存的懒加载模式

​	在初始的时候，所有数据都存储在数据库中。

​	当读服务接受请求时，会先去缓存中查询数据，如果没有查询到数据，就会降级到数据库中查询，并将查询结果保存在 Redis 中。

​	保存在 Redis 中的数据会设置一个过期时间，防止数据库的数据变更了，请求还一直读取缓存中的脏数据

存在的问题：

1、存在缓存穿透的风险

​		针对数据库中没有的数据，可以在缓存中设置一个占位符。在第二次请求处理时，读取缓存中的占位符即可识别数据库中没有此数据，然后直接返回给业务前台系统即可。
​	使用占位符虽然解决了穿透的问题，但也带来了另外一个问题。如果恶意请求不断变换请求的条件，同时这些条件对应的数据在数据库中均不存在，那么缓存中存储的表示无数据的占位符也会把整个缓存撑爆，进而导致有效数据被缓存清理策略清除或者整个读服务宕机。
​	对于此种恶意请求，就需要在业务上着手处理。对于请求的参数可以内置一些 token 或者一些验证数据，在读服务中前置进行校验并拦截，而不是透传到缓存或数据库中

2、缓存集中过期导致雪崩
	将设置的过期时间随机化，避免同一时间过期

3、懒加载无法感知实时变更

​	在缓存中设置过期时间，虽然可以让用户感知到数据的变更。但感知并不是实时的，会有一定延迟

​	修改数据时，删除缓存，订阅binlog，重写缓存

4、懒加载无法摆脱毛刺的困扰

​	使用懒加载的缓存过期方案，还有一个无法避免的问题，就是性能毛刺。当缓存过期时，读服务的请求都会穿透到数据库中，对于穿透请求的性能和使用缓存的性能差距非常大，时长是毫秒和秒级别的差异

#### 4、全量缓存

##### 基本概述

​	全量缓存是指将数据库中的所有数据都存储在缓存中，同时在缓存中不设置过期时间的一种实现方式

​	所有数据都存储在缓存里，读服务在查询时不会再降级到数据库里，所有的请求都完全依赖缓存。此时，因降级到数据库导致的毛刺问题就解决了

​	全量缓存对数据更新要求更加严格，要求所有数据库已有数据和实时更新的数据必须完全同步至缓存，不能有遗漏。一种有效的方案是采用订阅数据库的 Binlog 实现数据同步

​	将 Binlog 的中间件（Canal）挂载至目标数据库上，就可以实时获取该数据库的所有变更数据。对这些变更数据解析后，便可直接写入缓存里

**任何方案在带来某一方面的提升时，必然是在其他方面做出了一些取舍，架构其实是一门平衡的艺术**

##### **全量缓存存在的问题**			

第一个问题：提升了系统的整体复杂度

第二个问题：缓存的容量会成倍上升，相应的资源成本也大幅上升	

如何节省内存？

​		1、首先是存储在缓存中的数据需要经过筛选，有业务含义且会被查询的才进行存储。比如数据库常见的修改时间、创建时间、修改人、数据有效位等一些记录性字段可以不存储在缓存中

​		2、其次是存储在缓存中的数据可以进行压缩。采用 Gzip、Snappy 等常见的压缩算法进行处理，但压缩算法通常较消耗 CPU。

​		3、节约缓存的技巧	
​		技巧一：将数据按 JSON 格式序列化时，可以在字段上添加替代标识，表示在序列化后此字段的名称用替代标识进行表示
​		技巧二：如果你使用的缓存是 Redis 且使用了其 Hash 结构存储数据。其 Hash 结构的 Field 字段，也可以使用和上述 JSON 标识一样的模式，使用一个较短的标识进行代替

##### 其他优化点

###### 多机房实时热备

为了提升性能和可用性，可以将数据同步模块写入的缓存由一个集群变成两个集群.两套缓存集群可以分别部署到不同城市的机房或者同城市的不同分区。另外，读服务也相应地部署到不同城市或不同分区

此方案提升了可用性

###### 异步并行化

对于需要多次和存储交互的场景，可以采用异步并行化的方式——接收到一次读请求后，在读服务内部，将串行与存储交互的模式改为异步并行与存储进行交互

##### 如何保证一致性

###### Binlog 高效消费

1、全串行的方式进行消费

​	在消费时，对此 Binlog 文件使用 ACK 机制进行串行消费，每消费一条确认一条，然后再消费一条，以此重复

2、采用并行的方式提升吞吐量及扩展性

​	借用了 MQ 进行拆分。在 Binlog 处仍然进行串行消费，但只是 ACK 数据。ACK 后数据直接发送到 MQ 的某一个 Topic 里即可。因为只做 ACK 并转发至 MQ，不涉及业务逻辑，所以性能消耗非常小

​	为避免并行性带来的数据乱序的问题，将对同一条数据的修改记录都发送到同一个分区中，即根据数据的主键计算分区。

采用 Redis 的 Hash 结构进行局部更新

###### 最后的兜底，直接写入

​	一些关键场景在写完数据库后，主动将数据写入缓存中去。

​	但对于写入缓存可能出现的失败可以不处理，因为主动写入是为了解决缓存延迟的问题，主动写入导致的丢失数据由 Binlog 保障最终一致性

### 集中读请求

即热点数据读请求，当百万 QPS 都属于对同一条数据读取时，即使缓存是集群化的，同一个用户的请求都会被路由至集群中的某一个节点

热点查询是对相同的数据进行不断重复查询的一种场景。特点是次数多，但需要存储的数据少，因为数据都是相同的

#### 热点key探测

##### 京东[HotKey](https://gitee.com/mirrors/Tair.git)

###### etcd集群

​		存放配置热key的规则、worker地址

###### worker节点

​		通过滑动窗口探测热点key，将热点key推送给服务实例

###### 服务实例

​		启动从etcd拉取worker地址，建立连接，拉取热key规则，将符合规则的key上报给worker节点（对key计算hash，根据worker节点的数量取模）；接收worker节点推送的热key，将数据缓存再本机

##### [淘宝Tair](https://gitee.com/mirrors/Tair.git)

###### DataServer端

​		在DataServer上划分一块HotZone存储区域存放热点数据，每个HotZone都存储相同的读热点数据
对于Tair来说，每个key的访问都会落到同一数据节点DataServer上，由DataServer探测热点key，将热点推送其他节点的HotZone中

###### 客户端

​		客户端在第一次请求前初始化时，会获取配置HotZone的数据节点
​		客户端随机选择一个HotZone区域作为自身固定的读写HotZone区域（挑选前将数据节点地址打散）
​		在DataServer未发生变化的情况下，不会改变选择。即每个客户端只访问唯一的HotZone区域
​		客户端收到服务端反馈的热点Key信息后，至少在客户端生效N秒
​		客户端首先请求HotZone节点，如果数据不存在，则继续请求源数据节点，获取数据后异步将数据存储到HotZone节点里

##### [饿了么samaritan](https://github.com/samaritan-proxy/samaritan.git)

###### 设计前提

​			类似于Codis，都是中间层代理
​			所有的 Redis 请求都是经过代理 Samaritan，由代理层进行收集上报热点key
​			不️依赖任何外部组件，外部聚和组件的初衷是为了聚合不同机器的数据.基于局部可以代表整体的原则，那么单实例上的热 key 就可以代表全局的一个情况

###### 实现

​			每个代理会有一个全局的 Hotkey Collector
​			每个Redis的连接维护自己独立的 Counter，Counter 采用LFU 算法（只保留访问频次最高的key）
​			Collector 会定时地去收集每个 Counter 的数据并进行聚合，聚合的时候不会使用真实的计数，而是使用概率计数，并且为了适应访问模式的变化 counter 的值会随着时间衰减

###### 注意

​			当前的方案只能够快速定位系统中的热 key，但并没有真正解决热 key 本身带来的问题，仍旧需要业务方自行改造或者将那些热点 key 调度到单独的节点上

#### 利用应用内的前置缓存

应用内的缓存存储的均是热点数据。当应用扩容后，热点缓存的数量也随之增加。在采用了前置缓存后，在面对热查询时只需扩容应用即可。前端负载均衡器（如 Nginx 等）会将所有请求平均地分发到各应用中去

##### 首先是应用内缓存需要设置上限

​	必须设置容量的上限且设置容量满时的逐出策略。逐出策略可以是 LRU，将最少使用的缓存在容量满时清理掉，因为热点缓存需要存储的是访问次数多的数据。前置缓存也需要设置过期时间

##### 其次是根据业务对待延迟的问题

​	如果业务上可以容忍一定时间的延迟，可以在缓存数据上设置一个刷新时间即可

##### 要把控好瞬间的逃逸流量

​	在初始化时，瞬间出现热点查询或者缓存时间到期，那么所有的请求都会逃逸至后端加载最新的缓存，也有可能把后端缓存打挂

​	为了避免上述情况，在从后端加载数据时，通过加锁，只允许一个请求逃逸请求后端缓存

​	对于数据过期需要更新时，并不主动清理掉数据。其他非逃逸请求使用历史脏数据，而逃逸的那一个请求负责把数据取回来并刷新前置缓存

#### 降级兜底不可少

​	所部署的机器能够支持的 QPS 未必都能够大于当次的热点查询。对于可能出现的超预期流量，可以使用前置限流的策略进行应对

#### 其他前置策略

除了采用后端应用内的前置缓存进行应对外，在前端的架构里也有一些应对手段。比如在接入层（如 Nginx）进行前置缓存（nginx还可实现对请求的合并）、数据前置至离用户更近的 CDN 及开启浏览器缓存

#### 分散存储

将热点数据打散，分散到缓存集群中的各个节点

### 多维度富查询

1、为了满足和原有分库维度不一样的查询，最简单的方式是按新的维度异构一套数据

2、使用 ES 满足多维度查询

​	第一步需要做的便是数据异构，将数据库的数据同步至 ES 中

## 海量写请求

分库分表只解决了容量的问题，并没有解决写服务的高可用问题

写业务是指需要将用户传入的数据进行全部存储的一种场景，对于写入业务，当出现各种故障时，最重要的是保证系统可写入

### 如何保证随时可写入？

只要有可用存储即可写入。

引入写服务集群，当写请求到达时，将数据写入到写服务集群中，然后通过同步模块，将数据写入到目标库中。

### 如何维护可用列表？

可以通过自动感知或人工确认的方式维护可用的数据库列表

在写服务调用数据库写入时，可以设置一个阈值。如果写入某一台数据库，在连续几分钟内，失败多少次，则可以判定此数据库故障，并将此判定进行上报

当整个写服务集群里，超过半数都认为此数据库故障了，则可以将此数据库从可用列表中剔除

为了防止误剔除某一台只是发生网络抖动的数据库，可以在真正下线某一个机器前，增加一个报警，给人工确认一个机会。可以设置当多少时间内，人工未响应，即可自动下线

通过对写服务集群扩容，可以增加写业务的可用性，同时可以提高TPS。写服务集群扩容后，将写请求负载均衡的顺序随机写入升级为按权重写入，比如对新加入的机器设置更高的写入权重，让数据更快地在全部数据库里变得均衡

### 如何保证同步成功？

#### 1、同步模块

​	订阅写服务集群的binlog，根据分库分表规则，写入目标分库分表集群

#### 2、主动同步

​	在写入请求中主动触发同步模块进行迁移，同步模块在接收到请求后，立刻将数据同步至分库分表及缓存中

#### 3、兜底同步

​	主动触发同步模块的请求及同步模块本身运行都有可能出现异常，对于可能出现的异常情况，可以设计兜底策略进行处理

​	兜底的同步对于无状态存储中的数据按创建时间进行不断轮询，轮询会对超过设置的时间阈值（如 5S）仍未得到同步的数据进行主动同步

### 如何保证写入的可见性？

#### 1、写入成功，返回写入的全部数据

​	对于有时延要求的场景，当数据写入随机存储成功后，可以在请求返回前，主动地将数据写入缓存中，同时将此次写入的数据全部返回给前台。但此处并不强制缓存一定要写成功，缓存写入失败也可以返回成功。

#### 2、同步模块同步缓存

​	同步模块除了将数据同步至分库分表，也会写入到缓存中

#### 3、缓存可降级

​	因为主动写入缓存可能存在异常，导致数据未写入缓存，且主动数据同步和兜底同步是先写分库分表再通过 Binlog 刷新缓存，存在一定的延迟。

​	因此在查询时需要具备降级功能，当缓存中未查询到时，可以主动降级到数据库进行一次兜底查询，并将查询到的值存储至缓存中。

### 提高写性能

#### 1、将依赖的串行改并行

#### 2、依赖后置化

​		第一，在写入数据时，对于用户不太关心的数据信息，可以在重要的数据写入成功后，通过一个异步任务进行补齐。对于一些可以后置补齐的数据，可以在写请求完成时将原始数据写入一张任务表

​		第二，整个链路上会有较多外部接口，但大部分场景里，很多接口都是可以后置化的

#### 3、显式设置超时和重试

​	后置接口处理请求前，需要判断来自前置接口的请求是否已经超时，如果超时，直接返回请求超时，	后置接口的超时时间的设定应该考虑前置接口的超时时间

​	将超时时间设置为 TP999 和 Max 之间的值

​	自动重试只能设置读接口，设置自动重试是为了提高接口的可用性

#### 4、降级方式

​	1、对产生故障的依赖进行后置处理，比如需要风控的场景，写入的数据自己可见，其他人不可见，待风控故障恢复后再进行数据校验，校验通过后再允许所有人可见。通过有损+异步最终校验，也是一种常见的降级方案

​	2、对于需要写下游的场景，比如下单，库存故障时，可降级直接跳过库存扣减，但需要提示用户后续可能无货。修复故障后进行异步校验库存。

## 海量扣减请求

### 1、并发修改优化为串行修改

扣减请求，主要就是保证大并发请求时据库中的库存字段值不能为负数	

一种是在应用程序中通过事务来判断，即保证减后库存不能为负数，否则就回滚

一种办法是直接设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时会直接执行 SQL 语句来报错

一种就是使用 CASE WHEN 判断语句，例如：UPDATE item SET inventory = CASE WHEN inventory >= xxx THENinventory-xxx ELSE inventory END

应对大并发的读库存，可以将库存放到缓存中，应用程序的本地缓存，也可以放到nginx中，当库存为0，不再请求后端服务

大并发扣减库存

如果秒杀商品的减库存逻辑非常单一，可以直接在缓存中减库存

如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存

由于 MySQL 存储数据的特点，同一数据在数据库里肯定是一行存储，因此会有大量线程来竞争InnoDB 行锁，而并发度越高时等待线程会越多，TPS会下降，响应时间会上升，数据库的吞吐量就会严重受影响。单个热点商品会影响整个数据库的性能

一个解决思路是遵循前隔离的原则，把热点商品放到单独的热点库中。但是会带来维护上的麻烦

一个解决思路是应用层做排队，按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用太多的数据库连接

在某些场景下有些多条 SQL（比如修改lastmodifytime修改时间字段） 是可以合并的，一定时间内只要执行最后一条 SQL 就行了，以便减少对数据库的更新操作

### 2、随机更新优化为顺序写

顺序写要比随机更新性能好

1、参数校验

2、开启事务

3、扣减明细插入任务数据库

​	任务库主要提供两个作用，一个是事务支持，其次是随机的扣减流水任务的存取;这两个功能均不依赖具体的路由规则，也是随机的、无状态的

4、插入失败，回滚事务

5、插入成功，进行缓存扣减

​		在Redis中的lua 脚本执行时，会按 SKU获取对应的剩余库存状态判断，如果此次扣减的数量大于剩余数量，直接返回错误提示数量不足；否则进行库存的扣减，返回成功

​		对于热门商品的扣减，往往集中到单台redis上，为避免海量请求超过redis负载，将库存按redis的数量进行平均等分，每一个缓存里均存储一等份即可。在处理秒杀请求时，不只是固定地命中某一个缓存分片，而是在每次请求时轮询命中缓存集群中的每一个缓存分片

6、缓存扣减失败，回滚

7、缓存扣减成功，事务提交，结束

缓存扣减失败，两种情况，第一种是扣减的数量不足，第二种就是缓存出现故障，缓存失败的可能性有很多，比如网络不通、调用缓存扣减超时、在扣减到一半时缓存突然宕机（故障 failover）了，以及在上述返回的过程中产生异常等。针对上述请求，都有相应的异常抛出，根据异常进行数据库回滚即可，最终任务库里的数据都是准的

## 预热

数据预热

​	模拟应用的访问，通过这种访问将数据加载到缓存和数据库中

应用预热

​	预先建立好连接，防止在高峰时建立连接

​	线程池预热，ThreadpoolExecutor提供了prestartAllCoreThreads方法可以预先启动核心线程 

​	JIT预热，JAVA代码是解释执行的，如果在高峰时同时做JIT编译，会消耗了大量的CPU，系统响应时间会拉长，通过JIT预热，保证代码可以提前充分编译



# 如何通过监控

## 微服务入口

1、次数监控

​	次数监控中被监控体就是次数，具体指微服务里各项代码逻辑运行的次数，可以是微服务对外提供接口的被调用次数、某一个方法被执行的次数

2、性能监控
	性能监控里的被监控体是性能，可以是微服务对外提供接口的性能、微服务依赖下游其他接口或存储的性能

3、可用率监控
	可用率里的被监控体是在指定时间里，代码执行成功的占比

1、需要设置调用次数报警，调用次数的报警阈值可以参考单机压测瓶颈值

2、按调用方设置调用次数监控

3、关于调用次数的阈值，需要设置调用次数的同环比监控

## 微服务自身

JVM、线程池数量、负载、cpu和内存的使用率

## 微服务依赖

并不是微服务内部的所有方法都要加监控，而是要挑选重点和可能存在问题的方法

如果是 Java 应用，监控的方式可以采用统一的 AOP 切面来实现。此外，也可以借助一些框架的功能统一拦截并进行监控，比如 MyBatis 里就提供用 Interceptor 拦截所有 SQL 的执行，在此处就可以添加统一的监控

# 日志收集

1、应用中开辟一个本地缓存，所有日志数据先存放在这个缓存中，然后后台线程通过异步的方式将缓存中的日志发送给存储

2、设置缓存的大小，避免把内存撑爆

3、流量大时，可以配置采样比例控制日志的数据量

4、日志不需要永久保存，通常保存1/2个月的数据，可以结合公司的实际情况进行配置

# 联调阶段，依赖的接口没好怎么办？

编写Mock 接口服务，提供与正式服务的URI、出入参一样的接口，区别是主机名或者 URL 的前缀不一样

为了预防线上环境使用 Mock 服务，在服务启动时，如果判断当前的环境名称是prod，则判断 mock.apis 中是否有值，有值的话提示异常。

# 如何做写压测

方法：

第一种是采用模拟账号进行替换或数据修改（不可见）进行压测

第二种方式是采用压测数据打标 + 影子库的方式进行特殊处理

压测过程中有两方面重要的数据，一个是压测过程中的各项指标数据，另一个是压测的结果即服务所能够支撑的QPS。

压测过程的各项指标数据有：压测时机器的CPU 利用率的变化、内存的变化、进程里各线程的CPU 利用率、微服务依赖的存储的CPU利用率、内存使用率等。压测过程中监控这些数据是为了发现系统瓶颈点，并快速优化，进而提升微服务能够支撑的QPS

如果压测过程中，发现被压测应用的CPU 都被某一个或某一类线程消耗，同时通过堆栈信息，确定这个或这类线程的所有 CPU 消耗都集中在一个方法里

# BFF（Backend for Front）

BFF 不是一个架构，而是一个设计模式，它的主要职责是为前端设计出优雅的后台服务，即一个 API

一般而言，每个客户端都有自己的 API 服务，不同的客户端请求经过同一个网关后，它们都将分别重定向到为对应客户端设计的 API 服务中

API 层实现一下三点：


聚合：一个接口需要聚合多个后台服务返回的数据，并将数据返回给客户端。


分布式调用：一个接口可能需要依次调用多个后台服务，才能实现多个后台服务的数据修改。

装饰：一个接口需要重新装饰后台返回的数据，比如删除一些字段或者对某些字段进行封装，然后组成客户端需要的数据

API 服务其实就是一个 Spring Web 服务，它没有自己的数据库，主要职责是聚合、分布式调用及装饰数据，并通过 Feign 或者RPC调用后台服务

# 构建微服务高效法则

## 1、防备上游

第一个原则：增加接口调用鉴权 比如是否按照调用次序

第二个原则：接口里的入参需要是对象类型，而不是原子类型

第三个原则：接口的出入参不要设计为 Map<String,String> 等集合格式

第四个原则：入参需要增加条件限制和参数校验

第五个原则：写接口需要保证幂等性

第六个原则：接口返回的结果需要统一

第七个原则：返回的数据量必须要分页

第八个原则：所有的接口需要根据接口能力前置设置限流

## 2、做好自己

### 微服务 CPU 被打满如何排查

1、在 Linux 系统里，可以使用top 命令进行定位， top 命令可以按进程维度输出各个进程占用的 CPU 的资源并支持排序，同时还会显示对应的进程名称、进程 ID 等信息

2、top 命令支持查看指定进程里的各线程的 CPU 占用量，命令格式为：top -Hp 进程号。通过此方式便可以获得指定进程中最消耗 CPU 资源的线程编号、线程名称等信息

3、假设导致 CPU 飙升的应用是基于 Java 开发的，此时，便可以通过 Java 里自带的 jstack 导出该进程的详细线程栈信息

### 如何预防故障

部署层面
首先，微服务及存储需要双机房部署

其次，机房内至少部署两台及以上机器

再者，不同类型的接口需要单独部署,比如读服务和写服务

最后，至少要线程池隔离

代码层面

第一，不要基于 JSON 格式打印太多、太复杂的日志

第二，需要具有日志级别的动态降级功能

第三，for 循环不要嵌套太深，原则上不要超过三层嵌套

第四，多层嵌套需要有动态跳出的降级手段

第五，如果使用应用内的本地缓存，需要配置容量上限

## 3、怀疑下游

微服务会依赖很多其他微服务提供的接口、数据库、缓存，以及消息中间件等，这些接口及存储可能会因为代码 Bug、网络、磁盘故障、上线操作失误等因素引发线上问题

为了防止上述情况的发生，在构建微服务时，就需要预先考虑微服务所依赖的各项“下游”出现故障时的应对方案

### 对其他微服务的依赖

依赖后置、依赖并行化、设置超时和重试、服务降级等手段，来对它的依赖进行治理，进而保障服务的高可用

对于分布式事务，在不引入外部TCC 和 Saga 的成熟基础框架时，可以采用本地事务任务表的方法

### 对数据库的依赖

原则一：数据库一定要配置从库，且从库部署的机房需要与主库不同，从而保障数据库具备跨机房灾备的能力

原则二：在能够完成功能的前提下，使用的 SQL 要尽可能简单

原则三：在业务需求不断更新迭代的场景里，最好不要使用外键

原则四：表结构中尽可能不要创建一个长度为上千或上万的 varchar 类型字段，且用其来存储类似 JSON 格式的数据，因为这会带来并发更新的问题

### 对消息中间件的依赖

原则一：数据要先写入数据库或缓存后，再发送消息通知

原则二：发送的消息要有版本号*

原则三：消息的数据要尽可能全，进而减少消息消费方的反查

# 负载均衡

## 含义

将负载(访问的请求)“均衡”地分配到多个处理节点上。这样可以减少单个处理节点的请求量，提升整体系统的性能。

## 类别

代理类的负载均衡服务

以单独的服务方式部署，所有的请求都要先经过负载均衡服务，在 负载均衡服务中，选出一个合适的服务节点后，再由负载均衡服务，调用这个服务节点来实 现流量的分发。

四层负载LVS，七层负载nginx

一般会同时部署 LVS 和 Nginx 来做 HTTP 应用服务的负载均衡。也 就是说，在入口处部署 LVS，将流量分发到多个 Nginx 服务器上，再由 Nginx 服务器分发 到应用服务器上

客户端负载均衡服务

## 负载均衡策略

静态策略

在选择服务节点时，不会参考后端服务的实 际运行的状态

动态策略

依据后端服务的一些负载特性，来决定要 选择哪一个服务节点

Nginx 来说，我们要如何保证配置的服务节点是可用的呢?

淘宝开源的 Nginx 模块nginx_upstream_check_module了，这个模块可以 让 Nginx 定期地探测后端服务的一个指定的接口，然后根据返回的状态码，来判断服务是
否还存活。当探测不存活的次数达到一定阈值时，就自动将这个后端服务从负载均衡服务器 中摘除

如何动态更新nginx的up_stream

nginx-upsync-module

# 数据库

池化技术，数据库连接池

最小连接数

最大连接数

空闲时间

定时检测连接的可用性,，比如使用连接发送“select 1”的命令给数据库看是否会抛出异常(C3P0)

主从分离

分库分表

水平拆分

垂直拆分

任务库

​	优化随机更新为顺序写

​	异步将数据同步给真实的业务数据库

# 分布式系统设计策略

## 心跳检测

检测节点是否存活

 周期检测心跳机制、累计失效检测机制

## 高可用

经过设计来减少系统不能提供服务的时间 

### 主备（MS模式）

Active-Standby模式

当主机宕机时，备机接管主机的一切工作

在数据库高可用性方案中比较常用，如 MySQL、Redis等就采用MS模式实现主从复制。保证高可用

### 互备（MM模式）

两台主机同时运行各自的服务工作

一个系统存在多个master，每个master都具有 read-write能力

在数据库中通过双主，对外提供读写服务并且互相进行数据同步

### 集群

有多个节点在运行，同时可以通过主控节点分担服务请求

集群模式需要解决主控节点本身的高可用问题，一般采用主备模式。

### 脑裂问题

同时用两条心跳线路

引入仲裁机制，由第三方仲裁

Lease机制

## 容错性

IT系统对于错误包容的能力

保障分布式环境下相应系统的高可用或者健壮性

## 负载均衡

使用多台集群服务器共同分担计算任务，把网络请求分配到集群可用的不同服务器节点上，从而达到高可用性及较好的用户操作体验。

## 服务协调

主要用来解决分布式环境下多个进程之间的同步控制，有序的访问某种临界资源
基于缓存redis实现的分布式锁
		使用setnx加锁，并设置过期时间，超过时间自动释放，value值用来标识锁的持有者，释放锁时根据value来判断是否有资格释放锁
基于zookeeper实现的分布式锁
		创建一个目录，获取锁时在此目录下创建临时的顺序节点
		获取目录下的所有节点，如果自己是最小的节点，获取锁
		如果不是，设置监听比自己小的节点

## 服务削峰

​	为了应对短时间上亿用户的涌入，瞬间巨大的流量
​	削峰本质上，就是更多的延缓用户的请求，以及层层过滤用户的访问请求，遵从最后落地到数据库的请求尽量少的原则
​	消息队列削峰
​	流量削峰漏斗：层层削峰
​		CDN
​		缓存
​		后台系统
​		数据库系统

## 服务降级

​	保证核心或者基本服务的正常运行，可以将一些不重要或不紧急的任务进行服务的延时使用或者暂停使用
​	降级策略
​		缓存降级，使用缓存方式来降级部分读频繁的接口
​		读降级，直接禁止相关读的服务请求
​		写降级，直接禁止相关写的服务请求
​		延迟服务，如定时任务延迟处理，消息写入mq延迟处理

## 服务限流

​	通过对并发请求进行限速或者一个时间窗口内的请求数量尽心限速来保护系统，一旦达到限制的速率，则可以拒绝服务、排队或等待

### 	多维度限流

​		客户端
​			防重点击校验
​		nginx
​			限制单位时间内的请求数、限制同一时间的连接数
​		tomcat服务器
​			配置tomcat线程池、配置最大连接数、配置请求队列等参数
​		服务api接口
​			限制单位时间内的调用次数

### 	限流算法

​		计数器

 		固定时间窗口

​		滑动时间窗口
​		漏桶
​			请求会在桶内排队，请求会被匀速处理。服务器空闲时，理论上服务器可以直接处理一次洪峰，但是漏桶的机制是请求处理速率恒定，因此，前期服务器资源只能根据恒定的漏水速率逐步处理请求	

​			令牌桶

​			匀速产生令牌。服务器空闲时，是可以把令牌桶一下子装满 的，当洪峰来的时候可以直接拿取令牌，处理请求  

## 服务熔断

​	避免调用链中的异常请求，拖垮调用方甚至宕机
​	熔断器的工作机制主要是关闭、打开和半打开这三个状态之间的切换
​	在正常情况下，熔断器是关闭的
​	基于滑动窗口统计异常/超时的百分比，超过配置的阈值，熔断器打开；此时再发起请求，直接被熔断拦截
​	当熔断器打开一段时间后，会转为半打开状态。这时发送一个请求给服务端，如果能够正常地得到服务端的响应，则将状态置为关闭状态，否则设置为打开。

注意事项

1、数据一致性

2、超时降级

3、用户体验

4、熔断监控

# 灰度发布

又名金丝雀发布，指在黑与白之间，能够平滑过渡的一种发布方式。
在其上可以进行 A/B testing， 即让一部分用户继续用产品特性 A，一部分用户开始用产品特性 B

灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现调 整问题，以保证其影响度

服务分组或者版本号



# 架构的目的

架构设计是为了解决软件复杂度带来的问题

通过熟悉和理解需求，识别系统复杂性所在的地方，然后针对这些复杂点进行架构设计

不是每个架构都具备高性能、高可用、高扩展等特点，而是要识别出复杂点然后有针对性地解决问题

复杂度的来源：高性能、高可用（计算和存储）、扩展性（伸缩、开闭原则）、安全性、成本

架构遵循的原则：合适原则、简单原则、演化原则

# 容量保障

互联网软件系统容量的概念，即“单位时间内软件系统能够承载的最大业务量”

容量保障，就是用各种方法保证软件系统的容量充足，预防容量隐患的重要工作

## 容量保障的目标是什么？如何度量？

### 目标

第一，以尽可能小的成本确保系统当前和未来的容量充足，即容量规划；
第二，解决已知的容量问题，预防未知的容量问题，即容量治理

### 度量

1、服务等级协议（SLA）

SLA 就是对服务可用性的一个保证，它可以细分为 SLI 和 SLO。

其中，SLI 定义测量的具体指标，如 QPS、带宽等；SLO 定义服务提供功能的期望状态，如 QPS 99 线≤100ms

SLA 用一个简单的公式来描述就是：SLA = SLO + 后果。 这里的后果指的是不满足 SLO情况下的补偿协议，比如赔款、延长使用期，等等。

2、QPS/TPS

QPS（Queries per Second）指的是每秒查询率，是一台服务器每秒能够响应的查询次数，一般针对读请求居多。
TPS（Transactions per Second）指的是每秒处理的事务数，一般针对写请求居多

通常说“系统容量是否足够”，一般就是指系统或服务能否在可接受的响应时间和成功率下支撑目标 QPS/TPS

在实际工作中，我们有时可能无法直接给出 QPS/TPS 的目标值，比如说，针对某个将要上线的大促活动，业务方预估的活动热度往往是以业务指标的形式呈现的，如PV（Page View）、UV（Unique View）、DAU（Daily Active User）等，我们需要将其转换为 QPS/TPS，才能作为容量保障可实施的技术目标

首先，A万 PV 是分布在整个活动期间的，但不一定是均匀分布的。假设我们根据二八原则，也就是 80% 的 PV 分布在 20% 的时间内，4.8 小时中将有 800 万 PV，平均每秒463PV。

然后再根据页面中接口的调用情况，计算出接口调用次数，就可以得出接口的预估QPS

3、 用户体验

有些容量问题尽管没有影响可用性，但会导致用户操作时响应延迟，页面打开缓慢等体验问题

用户体验完全可以作为容量保障更高级的目标

### 技术人员看待容量的视角

1、系统可用时长

2、关键路径正常

3、性能可接受范围

## 怎样科学实施容量测试？

容量测试是验证手段，不是测试手段。我们应该先努力设计和建造出满足容量要求的服务，再通过容量测试去验证它

### 确定容量测试的范围

针对容易产生容量风险的服务重点考虑进行容量测试

1、关键路径上的核心服务

2、有明显流量峰值特征的服务

3、对响应时间敏感的服务

4、占用资源大的服务

5、曾经发生过容量事故的服务

6、高峰期已经存在容量隐患的服务

7、新上线对容量情况未知的服务

### 科学实施容量测试

1、测试方案设计

测试背景、测试目标、测试模型和数据、测试计划、监控指标、止损策略

2、测试方案评审

在测试方案评审中，相关研发人员和测试人员都要参与评审，确保测试模型和数据合理，没有遗漏关键信息

3、测试准备

撰写测试脚本，准备测试数据。准备完毕后，调试脚本和数据，确保能够正常执行，服务无异常

准备的测试数据尽可能贴近真实的业务场景

4、测试执行

容量测试一般在线上执行居多，除非在线下能构建出完全对等的环境，否则即便将服务规模和硬件资源等比例缩放，容量的表现情况也不一定是线性的

容量测试是循序渐进的过程，逐步对目标服务施加压力，期间需要严密监控各项指标，一旦出现异常，应确保无风险的情况下才能继续施压。在达到容量目标值后，可以同时进行适当的摸高（在更高压力下维持一段时间）和脉冲（模拟瞬时的高并发场景），或对限流进行验证等工作

5、测试反馈

容量测试结束后，要有明确结论，总结测试过程中的各项指标和数据，与各方确认数据结论是否正常以及是否达到预期，编写测试报告，输出结论

6、持续跟进

容量测试不是单纯的测完就好，暴露的问题需要有效跟进，并在一定时间内跟踪解决，改进后确定时间再次进行验收，确保改进措施有效。

## 容量指标分析

响应时间应更关注分位线，我们常说的 TP95、TP99 或 95 线、99 线这类称呼
就是指分位线

响应时间越短越好，是建立在场景正确，服务无异常的基础上的，加强全方位的指标监控

CPU 利用率低只能说明 CPU 不忙，并不能说明在其他地方没有容量瓶颈

压不上去，不一定就是服务不行，有可能是施压端自身出现了瓶颈

当遇到容量指标抖动的情况，不要忽视它，尽可能找到根因

## 容量治理的三板斧：扩容、限流与降级

### 扩容的实践要点

要建立服务性能优化胜过简单扩容的意识，努力通过性能优化腾出容量，避免不经思考直接扩容

扩容要联动系统整体资源共同规划，不能只关注服务资源，还应同时关注对底层资源的影响

### 限流的实践要点

限流就是在控制成本的情况下对服务容量的一种保护措施

提前设置合理的限流对系统进行过载保护，是更主动的方式

与业务场景紧密相关的三大流量控制方式

流量整形： 指不管流量到达的速率多么不稳定，在接收流量后，都将其匀速输出的过程，即“乱进齐出”

容忍突发流量： 指的是限流策略允许流量在短时间内突增，且在突增结束后不会影响后续流量的正常限流

平滑限流： 指的是在限流周期内流量分布均匀，比如限制 10 秒内请求次数不超过
1000，平滑限流应做到分摊到每秒不超过 100 次请求

固定窗口无法容忍突发流量，但它实现简单，资源消耗少

如果你的应用服务经常需要应对诸如大促场景这样的突发流量，那么使用令牌桶算法进行限流往往会更适合

根据不同的限流位置，限流可以划分为网关层限流、接入层限流、应用层限流、数据库层限流等

### 降级的实践要点

降级是从系统功能角度出发，人为或自动地将某些不重要的功能停掉或者简化，以降低服务负载，这部分释放的资源可以去支持更核心的功能

降级与限流有明显的区别，前者依靠牺牲一部分功能或体验保住容量，而后者则是依靠牺牲一部分流量来保住容量

## 全链路压测

全链路压测本质上也是一种容量测试的手段，因此容量测试需要解决的问题也是全链路压测面对的重点问题，比如**数据隔离、压测场景置信度、对正常业务的影响**等

全链路压测遵循与用户访问相同的流量轨迹，因此会涉及大量的服务链路，我们需要保证压测流量在这些链路中流动时的完整性和可识别性。此外，有别于**单链路压测只需要制造局部流量，全链路压测需要制造大规模的整体流量**

### 应该如何建设

#### 三项改造工作

##### 数据隔离

常见的数据隔离方式有两种，分别是：逻辑隔离和物理隔离

逻辑隔离是指通过数据打标的方式区分真实数据和压测数据，在各实体（如用户、商户、订单等）中添加压测类型标识。比如针对用户这个实体，可以设置一个用户类型字段，其他系统或服务可以根据这个字段硬编码走相应的隔离逻辑

逻辑隔离实现简单，容易理解，但难以标准化，因为具体的字段设置是由业务技术方决定的。上游系统如果需要同时识别多种数据的压测标识时，会比较困扰。

物理隔离
它的做法是先通过在压测流量中进行打标的方式，区分真实请求和压测请求，再将压测请求所涉及的数据存储到另一个与真实表数据结构对等的表中（俗称影子表）

涉及两个重点工作，一是在压测流量中打标，二是建立影子表

通常情况下，流量入口大多是 HTTP 请求，压测流量标识可以置于 HTTP Header 中，进入内网后，相关中间件需要将 HTTP Header 中的压测流量标识转移至内部请求

要确保压测流量标识能够一路透传（传输过程中不对标识进行改变）至数据层不
丢失；最后，数据层，如数据库中间件通过对压测流量标识的识别，将数据写入影子表，完成整个物理隔离的全过程

建立影子表的过程

1、针对某张真实表建立相应的影子表，表名可以通过增加前缀或后缀区分，比如原表名为User，影子表名可以设定为 User_T，其他影子表也都基于 _T 这个后缀建立。
2、将真实表的数据进行脱敏，部分 id 类字段需要进行偏移，以免增长后与真实表冲突，比如真实的订单号都是以 1 开头，那么影子表中的订单号可以偏移为以 9 开头。
3、脱敏和偏移后的数据导入到影子表中。
4、进行完整性检查（数据量、表结构等内容），确保数据无误。

##### 中间件改造

对消息队列需要进行改造，当接收到带有压测请求标识的生产者推送消息时，需要将压测标识转存至数据中，以免丢失，当异步服务消费数据时，再将该标识恢复至请求体或上下文中继续传递

##### 应用服务改造

应用服务也需要进行一定的改造，确保压测请求能被反复执行，并且不影响真实场景

绕开限制逻辑： 比如系统针对短时间内反复下单的用户将进行限制，这个逻辑针对压测流量需要放开

Mock 逻辑： 有些对外交互的服务是不太方便发起大量真实请求的，比如支付和清结算等，这些功能可以在识别到压测流量后走 Mock 服务，也就是模拟一个正常的返回，而不是直接调用真实服务

#### 两项压测工作

##### 压测模型构建

业务模型（压测场景、业务模型、数据）

​	读请求
​		读请求不会对数据造成污染，因此可以直接使用真实请求和数据进行回放

​	写请求

​		写请求一般需要单独构造压测模型，并做好数据隔离和清理工作

压测模型构建的核心要点是，要利用好生产环境的各种信息来帮助我们构建贴近真实业务的压测模型

生产环境中的请求的依赖关系、调用比例、数据特征都是我们构建压测模型的素材，将这些数据抽取出来再进行精加工，即可得到贴合实际的压测模型

##### 压测流量构建

全链路压测对于压测流量构造的技术选型主要取决于流量的规模

如果规模不大，传统的压测工具是可以支持的，如 JMeter、Locust、nGrinder 等

如果是大规模流量乃至超大规模流量（百万请求量级），成本就会比较高。对于后者，可以考虑自研一套压测平台

## 怎样做好大促活动的容量保障工作

### 明确背景与目标

找到产品和业务方，了解大促的业务背景，最好能拿到 PRD（产品需求文档）
和具体的业务指标，先了解一下到底要举办哪些活动，活动的策略是什么，希望达到的效果是什么，活动周期和预估访问量是多少，等等

一定要获得量化的业务指标，没有也要让业务方拍个脑袋出来

最后，针对各类活动场景，拆解出容量保障的侧重点，说白了，就是将业务目标转换为容量保障的技术目标

### 重点链路梳理

1、同步链路

同步链路指的是，链路上的服务是强依赖的，调用方需要等待被调用方执行完成后才能继续工作

2、异步链路

异步链路与同步链路的概念正好相反，链路上的服务没有强依赖关系，调用方不需要等待被调用方执行完成，可以继续执行后续工作，被调用方在另一个线程内执行完成后，通过回调通知调用方

3、旁支业务链路

平时流量不大的“小”业务在大促场景下，流量是否会放大，是否会有叠加

4、高并发链路

类似秒杀和红包雨这类链路，可能瞬间会产生极高的并发量，这类链路要尽量做到集群物理隔离，分层过滤流量，再通过容量测试去检验效果

如何来梳理高并发链路

首先我们需要识别出高并发的“爆点” 在哪？也就是说，哪个环节，哪个接口，承受了最高的并发量

识别出爆点后，下面就要从两方面考虑：爆点的逻辑是否合理，能不能减少爆点的容量压力？比如其中的有些是否必要、是否可以缓存预热、是否可以异步执行等等

确定了合理的逻辑后，就可以规划容量测试方案了，方案需要尽可能与真实场景保持一致

最后，根据容量测试的结论，对整体链路进行合理的限流，预防容量事故的发生

梳理工作的思路都是类似的，先识别其中的容量风险（爆点），再看能不能通过优化链路设计减少容量压力，并结合容量测试不断接近目标，最后通过限流等手段合理控制容量风险

### 服务架构治理

#### 新服务和新功能的架构治理

对新服务和新功能的架构治理，倾向于通过绘制各种架构图（调用关系图、部署图、时序图，等等）的方式在架构评审时使用

调用关系图：调用关系图表示服务之间主要模块的交互关系，以及与外部系统的交互关系。绘制调用关系图的目的是为了完整识别出服务的上下游和外部依赖，这是容量保障工作所需要的基础信息

部署图：部署图描述服务部署的物理拓扑结构，在容量评估时我们需要知道服务的部署情况，来判断容量保障的范围

时序图：时序图描述服务对象之间的调用顺序，它可以帮助我们快速识别出同步调用和异步调用，在链路梳理时很有用

#### 存量服务的架构治理

由于时间成本的约束，从性价比的角度考虑，可以优先梳理历史上发生过的事故和冒烟

另一个切入点是代码评审，通过对已有代码进行审查，发现潜在的隐患，同时制定改进策略。评审工作由架构师牵头，联合研发与测试一同进行

代码逻辑：逻辑是否合理，有没有冗余的逻辑，有没有嵌套过深的逻辑

代码调用：调用是否恰当，是否存在重复调用

代码规范：代码可读性是否良好、可维护性是否良好

依赖管理：依赖关系是否严格，弱依赖是否明确

数据库使用：数据库字段是否合理，数据库连接池大小是否合适

中间件使用：Redis是否有热点key，MQ中的数据是否可以清除，有没有过度堆积的情况



### 大促流量预估

在梳理出核心场景链路后，对各服务进行流量预估时，特别要注意对下游服务的流量预估，一方面需要从核心场景入手计算，另一方面还要考虑到上游其他服务的依赖

上游负责制，简单说，所有依赖方应负责预估对被依赖方的调用量，并及时通知下游进行保障。对于调用量很高，且非常关键的调用方，下游服务甚至可以切割出一个物理隔离的集群，专门为这个调用方服务，以降低容量相互影响的可能性

### 大促容量测试

除了常态的全链路测试工作外，针对大促场景需要进行多次单链路压测，每次单链路压测都包含压测模型构建、压测数据准备、压测方案和计划准备、影响范围预估，以及监控和预案等步骤

在单链路压测通过后，需要再和全链路压测叠加进行混压，方能确保全局容量不出问题

### 大促容量保障预案

扩容、限流、降级等预案减少和避免损失

预案编写应非常具体，避免歧义，还要落实到具体的人，负责人、服务对象、执行条件、预案内容与操作步骤、影响面等五大要素
完善预案覆盖率是保证业务快速恢复的有效手段，为保障预案是可执行的，平时要进行演练，而且是频繁的演练，通过演练提升人员操作熟练度，减少误判

### 大促容量保障体系

首先，为规避一些单场景容量评估存在疏漏的情况，在各个大促场景的容量预估完成后，组织了一次全
局评审，全局评审的目的是拉齐各方之间的信息，查遗补漏，确实能发现一些单场景梳理缺失的信息

其次，在全场景混压前 1 小时，安排了一个简单的流程通气会，会议的内容是串讲压测流程，并现场答疑，答疑结束后立刻进入实战

最后，在大促活动完成后，应该及时组织复盘，总结经验，将不足之处尽可能多的暴露出来，以免将来再犯

## 建设经济实用型的容量保障体系？

### 方法一：粗放式保障

抓大放小，去做那些性价比高的事情，适当牺牲掉一些细节，这就是粗放式保障的思维

具体怎么去实施？或者说，哪些环节可以粗放式保障

在服务容量的观测能力方面，对容量指标的监控告警就可以是粗放式的，你可以针对服务的各项容量指标划定一个警戒值，比如 CPU 利用率≥80%，响应时间 99 线≥500ms，成功率≤95% 等，超过警戒值后，监控系统直接发出告警

对于那些趋势型的指标监控，还有带有业务语义的监控，实现的成本高，还要理解业务逻辑，就可以次要考虑

粗放式的容量保障并不是无谓地放弃一些工作，而是有策略地选择性价比高的“大头”去优先保障，以较低的成本堵住最严重的容量风险

### 方法二：善用云服务商的收费机制

云服务商也提供了弹性伸缩的服务，通过设置伸缩规则，在业务流量增长时能够自动增加实例，以保证计算力充足，反之则自动缩减实例。弹性伸缩是可以计量收费的

# 服务拆分维度

​	业务维度

​	功能维度

​	资源维度

​		高频高并发场景

​			商品详情	

​			优惠计算

​			热点数据、热点隔离

​		低频突发场景

​			秒杀

​			服务隔离

​		IO密集

​		CPU密集

用户维度

​	2C

​	2B

​	用户端

​	采购端

​	运营端

前后台业务

​	买家业务

​	卖家业务

​	运营业务

# 接口版本控制

RPC接口，消费方指定版本号，请求指定版本好的服务提供方

HTTP接口，Header中指定版本号，业务网关根据根据版本号路由到指定的服务

# 设计模式

对接口编程而不是实现编程,优先使用对象组合而不是继承

## 基石

封装

继承

多态

分类

## 创建型模式

怎么样创建对象
将对象的创建和使用分离
降低系统耦合度

单例

原型

工厂方法

抽象工厂

建造者

## 结构型模式

代理

适配器

装饰

门面

## 行为型模式

模板

策略

命令

职责链

状态

观察者

迭代者

# CAP理论

CAP 理论含义是，一个分布式系统不可能同时满足一致性（C:Consistency)，可用性（A: Availability）和分区容错性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中的2个

 C一致性 

​	分布式系统当中的一致性指的是所有节点的数据一致，或者说是所有副本的数据一致
A 可用性

 Reads and writes always succeed. 也就是说系统一直可用，而且服务一直保持正常
P 分区容错性 

系统在遇到一些节点或者网络分区故障的时候，仍然能够提供满足一致性和可用性的服务
在分布式系统当中，CAP三个特性我们是无法同时满足的，必然要舍弃一个。三者舍弃一个，显然排列组合一共有三种可能

# BASE理论

什么是BASE理论
BASE：全称：Basically Available(基本可用)，So state（软状态）,和 Eventually consistent（最终一致性）三个短语的缩写

BASE是对CAP中一致性和可用性权衡的结果，BASE理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性

①Basically Available(基本可用)
基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性

②Soft state（软状态）
软状态指的是允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同
节点的数据副本之间进行数据同步的过程中存在延迟。

③Eventually consistent（最终一致性）
最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。

# 异地多活

异地就是指地理位置上不同的地方，多活就是指不同地理位置上的系统都能够提供业务服务

## 同城异区

将业务部署在同一个城市不同区的多个机房

应对机房级别故障的最优架构

## 跨城异区

业务部署在不同城市的多个机房，而且距离最好要远一些

有效应对这类极端灾难事件。跨城异地距离较远带来的网络传输延迟问题，给异地多活架构设计带来了复杂性。导致数据的不一致性

保证核心业务的异地多活

保证核心数据最终一致性

采用多种手段同步数据

存储系统自带的同步、消息队列同步，使用不同的网络连接，可以一个走内网、一个走公网

二次读取，接口访问和同步通道使用不同的网络连接

单机房架构

单机房部署全量的服务，站点层、服务层、基础层、数据层。全连接，只能容单节点故障的错误，不能容机房故障的错误

多机房多活架构

每个机房都部署全量的服务，都有各自的数据库，使用同步工具进行多机房的的异步复制，数据延迟时间比较长

不会出现跨机房的调用，只适用于举杯数据聚集效应的服务，比如快狗打车，所有的下单的用户都在同一个城市，城市与城市之间的数据基本上没有交集

最小化跨机房连接

一个主机房、一个备用机房，同时提供服务，主机房负责数据的写入，备用机房写入数据时需要跨机房调用，写入到主机房的数据库。备用机房的数据库只提供读请求

# 基于共识算法（Raft）的跨机房部署

## 两地三中心

一城市部署两个数据中心，另一城市部署一个数据中心。每个数据中心部署一个数据节点

能满足单个数据中心级的容灾，但是不能满足城市级容灾

## 三地五中心

5 个节点基本平分到了 3 个城市的数据中心，2个中心部署2个副本，1个中心部署1个副本

任何一个城市网络出现了问题，raft 协议都能正常运行，也是普遍使用的较高容灾级别的部署方式

# 如何保证数据安全？

数据篡改

​	数据签名

请求重放

​	基于时间戳的解决方案、Token，请求幂等

存储安全

​	加密存储，明文数据不落盘，需知道明文的敏感数据加密存储，无需知道明文的数据使用hash存储

敏感信息

​	避免将用户隐私信息明文用于传输展示，服务端数据脱敏

Sql 注入

​	采用预编译Sql、数据检查

XSS 跨站攻击

​	输入输出检查，尽可能把检查逻辑放入后端以防绕过

CSRF 跨站请求

​	验证码、验证Referer、CSRF Token

# 后台系统的归类和共性

##  读业务（资讯类业务系统）

产品

​	微博、头条、知乎、抖音、快手

目的

​	尽可能的保证读的可用性和用户体验

功能要求

​	高可用，保证系统可读（即使不能写，但是需要可以浏览）

​	高性能（比如TP99要在100ms以内）

​	支持QPS非常高

实现

​	读业务的代码尽可能的简单

​	架构尽量不要分层，分层之后多一次网络传输

​	CQRS原则，将读写分离，分开优化

数据前置

​	浏览器，减少请求的次数，降低了延迟

​	CDN，缩短了传输距离，降低了延迟

缓存穿透

​	校验key的合法性，拦截无效请求

​	不存在的key存储空值，但是造成空间的浪费

​	布隆过滤器拦截

缓存集中过期导致雪崩

​	过期时间加上一个随机值，避免同一时间过期

​	多级缓存、前置缓存

nginx缓存

​	开启缓存功能，设置过期时间

​	开启请求合并功能，对于相同的请求只调用一次后台服务

数据变更导致的无法实时感知

​	采用Binlog方式，Canal+Mq

缓存数据压缩

​	将数据按照json格式序列化时，可以在字段上添加较短的替代标志，表示序列化后此字段的名称可以用替代标志进行表示；如果使用了redis中的Hash结构存储，也可以采取上述方式进行存储

热点数据的查询

​	缓存的主从，增加从节点 

​	为了应对热点数据的查询，增加从节点，并发性能并不会翻倍增加，而且造成了资源浪费

读服务中添加前置缓存模块

​	设置缓存容量的上限及逐出策略

​	数据变更感知的问题

​		定期刷新，有一定的延迟

​		实时感知，采用Binlog的方式在变更时主动刷新

控制穿透到缓存、数据库的流量

​		对于相同的查询请求，只有其中一个可以穿透到数据库，防止重复查询

流量超出预期，对读服务进行限流

## 写服务（外卖、打车）

保证写的高可用，支持海量数据的写入

分库分表

​	按用户分库

​	按照业务记录的唯一标志分库

分库分表中中间件

​	代理模式

​	内嵌模式

多维度查询

​	异构数据，通过Binlog方式，将数据导入ES

## 扣减服务（库存）

保障扣减的高可用，保证数据一致性，抗住高并发

纯数据库实现扣减

​	扣减库存、插入流水记录

基于缓存实现缓存扣减

​	1、Redis只支持单条命令的原子性，需要借助Lua实现批量扣减的原子性

​	2、Lua脚本中，首先判断数量是否满足，满足的话就扣减数量、记录流水

​	3、Lua扣减成功后，异步的将扣减内容保存至数据库

​	4、运营后台修改库存时需要同步增加至Redis

​	Redis宕机，扣减成功但是流水记录失败；异步刷新数据库失败；导致出现丢数据、少卖的情况。为了保证不出现少卖的情况需要做对账、异常处理等设计

缓存+数据库构建高可靠的扣减

1、扣减明细插入任务数据库（顺序插入；配置多个任务库，分摊写压力）
2、Redis扣减库存（运营后台修改库存需实时同步至Redis）
3、扣减成功，事务提交；扣减失败，事务回滚
4、异步将任务数据库的数据导入正式数据库

极端情况下，扣减成功后，还没给扣减服务返回响应，Redis就宕机，导致事务回滚，出现丢数据、少卖的情况。

应对热点缓存扣减*

引入秒杀库存分发器，将秒杀商品的库存平均分配到每个缓存分片

应对秒杀流量

扣减服务设置单机限流，实时并且精准；远程的集群限流多一次网络传输而且并不精准

引入兜底限流配置中心，推送每个分片在每台应用中的限流值，避免缓存分片被流量打垮

# 高并发系统分类

## 高并发读

策略1：加缓存

本地缓存或Memcached/Redis集中式缓存

MySQL的Master/Slave

CDN静态文件加速（动静分离）

策略2：并发读

异步RPC

Google的“冗余请求”

客户端同时向多台服务器发送请求，哪个返回得快就用哪个，其他的丢弃，但这会让整个系统的调用量翻倍

策略3：重写轻读

把计算逻辑从“读”的一端移到了“写”的一端

多表的关联查询：宽表与搜索引擎

策略4：读写分离（CQRS架构）

分别为读和写设计不同的数据结构

定时任务定期把业务数据库中的数据转换成适合高并发读的数据结构

## 高并发写

策略1：数据分片

数据库的分库分表

JDK的ConcurrentHashMap实现

Kafka的partition

ES的分布式索引

策略2：任务分片

Map/Reduce

Tomcat的1+N+M网络模型

策略3：异步化

LSM树（写内存+Write-Ahead日志）

凡是不阻碍主流程的业务逻辑，都可以异步化，放到后台去做

策略4：批量

Kafka的百万QPS写入







# DDD领域驱动设计

DDD 包括战略设计和战术设计两部分

战略设计主要从业务视角出发，建立业务领域模型，划分领域边界，建立通用语言的限界上下文，限界上下文可以作为微服务设计的参考边界

战术设计则从技术视角出发，侧重于领域模型的技术实现，完成软件开发和落地，包括：聚合根、实体、值对象、领域服务、应用服务和资源库等代码逻辑的设计和实现

如何划定领域模型和微服务的边界

第一步：在事件风暴中梳理业务过程中的用户操作、事件以及外部依赖关系等，根据这些要素梳理出领域实体等领域对象。

第二步：根据领域实体之间的业务关联性，将业务紧密相关的实体进行组合形成聚合，同时确定聚合中的聚合根、值对象和实体。

第三步：根据业务及语义边界等因素，将一个或者多个聚合划定在一个限界上下文内，形成领域模型。限界上下文之间的边界就是未来微服务的边界

领域具体指一种特定的范围或区域。领域可以进一步划分为子领域。我们把划分出来的多个子领域称为子域，每个子域对应一个更小的问题域或更小的业务范围。领域可以通过细分为子域的方法，来降低研究的复杂度

决定产品和公司核心竞争力的子域是核心域，它是业务成功的主要因素和公司的核心竞争力

没有太多个性化的诉求，同时被多个子域使用的通用功能子域是通用域

还有一种功能子域是必需的，但既不包含决定产品和公司核心竞争力的功能，也不包含通用功能的子域，它就是支撑域。

在公司领域细分、建立领域模型和系统建设时，我们就要结合公司战略重点和商业模式，找到核心域了，且重点关注核心域。

通用语言定义上下文含义，限界上下文则定义领域边界

什么是通用语言？

在事件风暴过程中，通过团队交流达成共识的，能够简单、清晰、准确描述业务涵义和规则的语言就是通用语言。它可以解决交流障碍这个问题

限界上下文可以拆解为两个词：限界和上下文。限界就是领域的边界，而上下文则是语义环境。通过领域的限界上下文，我们就可以在统一的领域边界内用统一的语言进行交流

领域专家、架构师和开发人员的主要工作就是通过事件风暴来划分限界上下文。限界上下文确定了微服务的设计和拆分方向，是微服务设计和拆分的主要依据

## 实体和值对象

实体

在 DDD 中有这样一类对象，它们拥有唯一标识符，且标识符在历经各种状态变更后仍能保持一致

领域模型中的实体是多个属性、操作或行为的载体

实体和值对象是组成领域模型的基础单元

在代码模型中，实体的表现形式是实体类，这个类包含了实体的属性和方法，通过这些方法实现实体自身的业务逻辑。

实体以 DO（领域对象）的形式存在，每个实体对象都有唯一的 ID

DDD 是先构建领域模型，针对实际业务场景构建实体对象和行为，再将实体对象映射到数据持久化对象

值对象

通过对象属性值来识别的对象，它将多个相关属性组合为一个概念整体

DDD 提倡从领域模型设计出发，而不是先设计数据模型

 聚合和聚合根：怎样设计聚合

聚合

在 DDD 中，实体和值对象是很基础的领域对象。实体一般对应业务对象，它具有业务属性和业务行为；而值对象主要是属性集合，对实体的状态和特征进行描述

聚合就是由业务和逻辑紧密关联的实体和值对象组合而成的，聚合是数据修改和持久化的基本单元，每一个聚合对应一个仓储，实现数据的持久化

聚合有一个聚合根和上下文边界，这个边界根据业务单一职责和高内聚原则，定义了聚合内部应该包含哪些实体和值对象，而聚合之间的边界是松耦合的。

聚合在 DDD 分层架构里属于领域层，领域层包含了多个聚合，共同实现核心业务逻辑。聚合内实体以充血模型实现个体业务能力，以及业务逻辑的高内聚

聚合根

聚合根的主要目的是为了避免由于复杂数据模型缺少统一的业务规则控制，而导致聚合、实体之间数据不一致性的问题

如果把聚合比作组织，那聚合根就是这个组织的负责人。聚合根也称为根实体，它不仅是实体，还是聚合的管理者

首先它作为实体本身，拥有实体的属性和业务行为，实现自身的业务逻辑

其次它作为聚合的管理者，在聚合内部负责协调实体和值对象按照固定的业务规则协同完成共同的业务逻辑

最后在聚合之间，它还是聚合对外的接口人，以聚合根 ID 关联的方式接受外部任务和请求，在上下文内实现聚合之间的业务协同。

怎样设计聚合

第 1 步：采用事件风暴，根据业务行为，梳理出在业务中发生这些行为的所有的实体和值对象

第 2 步：从众多实体中选出适合作为对象管理者的根实体，也就是聚合根。判断一个实体是否是聚合根，你可以结合以下场景分析：是否有独立的生命周期？是否有全局唯一 ID？是否可以创建或修改其它对象？是否有专门的模块来管这个实体

第 3 步：根据业务单一职责和高内聚原则，找出与聚合根关联的所有紧密依赖的实体和值对象。构建出 1 个包含聚合根（唯一）、多个实体和值对象的对象集合，这个集合就是聚合

第 4 步：在聚合内根据聚合根、实体和值对象的依赖关系，画出对象的引用和依赖模型。

第 5 步：多个聚合根据业务语义和上下文一起划分到同一个限界上下文内

聚合的一些设计原则

聚合用来封装真正的不变性，而不是简单地将对象组合在一起

设计小聚合

 通过唯一标识引用其它聚合

在边界之外使用最终一致性

通过应用层实现跨聚合的服务调用

## 领域事件：解耦微服务的关键

在事件风暴（Event Storming）时，我们发现除了命令和操作等业务行为以外，还有一种非常重要的事件，这种事件发生后通常会导致进一步的业务操作，在 DDD 中这种事件被称为领域事件

领域事件是 DDD 的一个重要概念，在设计时我们要重点关注领域事件，用领域事件来驱动业务的流转，尽量采用基于事件的最终一致，降低微服务之间直接访问的压力，实现微服务之间的解耦，维护领域模型的独立性和数据一致性

DDD 分层架构包含用户接口层、应用层、领域层和基础层

DDD 分层架构有一个重要的原则：每层只能与位于其下方的层发生耦合

DDD 分层架构模型就属于严格分层架构，任何层只能对位于其直接下方的层产生依赖

在严格分层架构中，领域服务只能被应用服务调用，而应用服务只能被用户接口层调用，服务是逐层对外封装或组合的



# 性能测试

在性能市场上，我们总要用具有普适性的指标说明，而不是用混乱的体系。对于TPS中T一定要有一个清楚的定义

用 TPS 来承载“并发”这个概念。并发数是 16TPS，就是 1 秒内整个系统处理了 16 个事务

性能测试分析的能力阶梯视图

1、工具操作：包括压力工具、监控工具、剖析工具、调试工具

2、数值理解：包括上面工具中所有输出的数据

3、趋势分析、相关性分析、证据链分析：就是理解了工具产生的数值之后，还要把它们的逻辑关系想明白

4、最后才是调优：有了第 3 步之后，调优的方案策略就有很多种了，具体选择取决于调优成本和产生的效果

性能分析思路

瓶颈的精准判断
TPS 曲线

之前有很多人在描述性能测试的过程中，说要找到性能测试中曲线上的“拐点”。我也有明确说过，大部分系统其实是没有明确的拐点的

当响应时间增加了，但是TPS 增加得却没有那么多时，可以是认定是拐点，性能瓶颈在加剧，越往后就越明显

准确说所有的系统都有性能瓶颈，只看我们在哪个量级在做性能测试了

TPS 随着压力的变化而变化，那就是有关系。不管压力增不增加，TPS 都会出现曲线趋势问题，那就是无关

响应时间是用来判断业务有多快的，而 TPS 才是用来判断容量有多大的

响应时间的曲线

随着线程的增多，响应时间也在增加

到压到一定数量线程时，TPS 基本上达到上限。

响应时间随着线程数的增加而增加了，系统的瓶颈显而易见地出现了

线程递增

在线程递增的过程中，出现了抖动，可能什么原因？

1、资源的动态分配不合理，像后端线程池、内存、缓存等等

2、数据没有预热

线程递增的策略

1、场景中的线程递增一定是连续的，并且在递增的过程中也是有梯度的

2、场景中的线程递增一定要和 TPS 的递增有比例关系，而不是突然达到最上限

根据响应时间线程递增的幅度

0-50ms 	1

50-100ms	1-3

100-200ms	3-5

200-500ms	5-10

性能衰减的过程

只要每线程每秒的 TPS 开始变少，就意味着性能瓶颈已经出现了。

但是瓶颈出现之后，并不是说服务器的处理能力会下降，应该说 TPS 仍然会上升，在性能不断衰减的过程中，TPS 就会达到上限

响应时间的拆分

在性能分析中，响应时间的拆分通常是一个分析起点。因为在性能场景中，不管是什么原因，只要系统达到了瓶颈，再接着增加压力，肯定会导致响应时间的上升，直到超时为止

如果想知道每个系统消耗了多长时间，就需要链路监控工具来拆分时间了

构建分析决策树

从压力工具中，只需要知道 TPS、响应时间和错误率三条曲线，就可以明确判断瓶颈是否存在

再通过分段分层策略，结合监控平台、日志平台，或者其他的实时分析平台，知道架构中的哪个环节有问题，然后再根据更细化的架构图一一拆解下去

操作系统分析决策树

cpu ：top pidstat

内存：top pidstat

IO：iostat

网络：iftop

进程：pidstat top -Hp

线程：jstack

堆：jmap

场景的比对

​	当你觉得系统中哪个环节不行的时候， 又没能力分析它，你可以直接做该环节的增加。一方面是压测机器的增加，一方面是服务节点的增加

如何录制脚本

性能测试工具的脚本编写能力分为两类，一个是录制，另一个是手工编写

编写 JMeter 脚本

1.1 创建线程组

重要参数

Number of Threads(users)： JMeter 中的线程数，也可以称之为用户数。这个线程数是产生 TPS 的，而一个线程产生多少 TPS，取决于系统的响应时间有多快。用 TPS 这个概念来承载系统的负载能力，而不是用这里的线程数

Ramp-up Period(in seconds)：递增时间，以秒为单位。指的就是上面配置的线程数将在多长时间内会全部递增完

Loop Count ：指的是一个线程中脚本迭代的次数。这里你需要注意，这个值和后面的Scheduler 有一个判断关系

Delay Thread creation until needed： JMeter 所有的线程是一开始就创建完成的，只是递增的时候会按照上面的规则递增。如果选择了这个选项，则不会在一开始创建所有线程，只有在需要时才会创建

Duration：线程会在多少秒之后结束，可以说和loopcount是互斥的关系，如果设置了 Loop Count 为 100，而响应时间是 0.1 秒，那么Loop Count * iteration duration(这个就是响应时间) = 100 * 0.1 = 10秒，即便设置了 Scheduler 的 Duration 为 100 秒，线程仍然会以 10 秒为结束点

2、编写 HTTP 脚本时，要注意以下几点：
1、要知道请求的类型，我们选择的类型和后端接口的实现类型要是一致的。
2、业务的成功要有明确的业务判断（在下面的 TCP 中，我们再加断言来判断）。

3、判断问题时，请求的逻辑路径要清晰

3、断言

断言指的就是服务器端有一个业务成功的标识，会传递给客户端，客户端判断是否正常接收到了这个标识的过程

在做脚本时，断言是必须要加的

## 关联和断言

### 关联

现在做性能测试的，有很多都是单纯的接口级测试，这样一来，关联就用得更少了。因为接口级的测试是一发一收就结束了，不需要将数据保存下来再发送出去

什么样的数据需要关联呢

1、数据是由服务器端生成的
2、数据在每一次请求时都是动态变化的
3、数据在后续的请求中需要再发送出去。

比如常见的 Session ID 就是一个典型的需要关联的数据

工作中常用的添加json提取器

$.提取的值 、下一个请求中的变量名



断言

断言就是判断服务端的返回是不是正确的

断言是根据需要来设计的，而设计断言的前提就是完全理解这个逻辑

对于 HTTP 协议来说，我们在性能分析中，主要关心的部分就是传输字节的大小、超时的设置以及压缩等内容。在编写脚本的时候，要注意 HTTP 头部，至于 Body 的内容，只要能让业务跑起来即可

## 在JMeter中如何设置参数化数据

以 JMeter 的 CSV Data Set Config 为例

参数释义

“Allow quoted data?”：False 和 True。它的含义为是否允许带引号的数据

Recycle on EOF? ：False、True 和 Edit。False 是指在没有参数的时候不循环使用；True 是指在没有参数的时候循环使用。Edit 是指在没有参数的时候会根据定义的内容来调用函数或变量

Stop thread on EOF?：False、True 和 Edit。含义和上面一致

Sharing mode : All threads、Current thread group、Currentthread、Edit

参数是在所有线程中生效，在当前线程组生效，还是在当前线程中生效。选择了 Edit 之后，会出现一个输入框，就是说这里并不是给引用函数和参数使用的，而是要自己明确如何执行 Sharing mode

## 做参数化前,要考虑什么

### 1、参数化数据应该用多少数据量？

根据业务场景计算参数化数据量

场景一	单线程内可循环使用的数据 比如用户填入登录名和密码登录

做脚本时考虑的是，有多少线程（Thread）就配置多少用户，让每个线程在同一个用户上多次循环执行

在这样的场景中，有多少线程就需要准备多少用户数据，即线程数=用户数

场景二  不可循环使用的数据，比如说电商系统，用同一个用户账号不停循环购买商品，就不符合业务场景

做脚本时，在压力测试工具中模拟出来的线程的每一次迭代来代表一个用户

不可循环使用的数据，在这样的场景中，就需要考虑场景的 TPS 和持续时间了

用户数据的计算方法 tps*持续时间（秒）

场景三	在一个线程之中，可以循环使用固定条目的数据，比如电商网站查看商品列表

这样的场景没有固定的条数限制，只能根据实际的业务判断
所以在配置参数之前，我们需要先判断这个参数是什么类型的数据

### 2、参数化数据从哪里来？

第一类
用户输入的数据在后台数据库中已存在，比如我们上面示例中的用户数据。
这类数据必须查询数据库之后再参数化到工具中
1、存在后台数据库中
2、需要用户主动输入
3、用户输入的数据会和后台数据库中的数据做比对
第二类
用户输入的数据在后台数据库中不存在。在业务流中，这些数据会 Insert 或 Update 到数据库中
1、数据库中原本不存在这些数据；
2、在脚本执行成功后会将这些数据 insert 或 update 到数据库中；
3、每个用户输入的数据可能相同，也可能不同，这取决于业务特点。

这类数据必须通过压力工具做参数化，要满足生产环境中数据的分布,也要满足性能场景中数据量的要求

### 3、参数多与少的选择对系统压力有什么影响？

参数取得过多，对系统的压力就会大；参数取得过少，不符合真实场景中的数据量，则无法测试出系统真实的压力

### 4、参数化数据在数据库中的直方图是否均衡？

对于参数化数据来说，如果数据取自于数据图，我们通常要检查一下数据库中的数据直方图。 

对于直接从生产上拿的数据来说，数据的分布更为精准。

但是对于一些在测试环境中造的数据，则一定要在造数据之后，检查下数据分布是否与生产一致

首先分析业务逻辑，某一类型的业务数据量是否在合理范围内

然后我们过滤掉不合理的数据即可

## 性能测试场景：如何进行场景设计

基准性能场景

什么是基准场景？基准场景就是对单接口或者单业务的测试

基准性能场景是为了测试出单业务的最大容量，以便在混合容量场景中判断哪个业务对整体容量最有影响

首先，我们要列出自己要测试的业务比例、业务目标 TPS 和响应时间指标

一定要知道，接口的TPS再高，都无法说明容量场景的情况，除非这个服务只有这一个接口

不要用所谓的”最大 TPS 拐点“这样的描述来说明 TPS 曲线，性能的衰减是逐步的，在最大 TPS 出现之前，就已经可以判断瓶颈是否出现了

容量性能场景

如果在你的项目中，有特定的业务日，那就要根据业务日的业务比例，重新做一个针对性的场景

关注业务的容量测试TPS和最大TPS，如果两者接近，将来业务扩展了，这两个业务将会先受到影响

## 性能测试场景：如何理解业务模型

回放的逻辑，就是可以在每一个业务产品和基础架构的层面做接口的回放，甚至我们可以直接在数据库中回放 SQL。这些手段，都是为了模拟生产的业务模型

生产数据统计
首先我们从生产环境取出数据，粒度到秒级，取出所有业务的交易量数据

业务量级按天统计的生成图

从这样的数据中取出业务量最高的一天，再以小时为单位统计出业务量比例

可以看出哪个小时的业务量最大

如果需要更细的数据，我们可以以分钟为单位看一下这个小时内的业务量分布

再以小时为单位做出百分比图

1、通用业务场景模型。就是将这一天的所有业务数加在一起，再将各业务整天的交易量加在一起，计算各业务量的比例。
3、哪个小时的业务量比较大，建立此小时的业务模型。将此消失的业务比例直接拿出来用。

收集线上日志，通过Elk分析业务比例

## 如何进行监控设计

### 监控设计步骤

首先，你要分析系统的架构。在知道架构中使用的组件之后，再针对每个组件进行监控

其次，监控要有层次，要有步骤。应该是先全局，后定向定量分析

最后，通过分析全局、定向、分层的监控数据做分析，再根据分析的结果决定下一步要收集什么信息，然后找到完整的证据链

架构图

做性能监控之前，先画一个最简单的架构图，看一下架构中各有什么组件，各有什么服务，将这些列下来，再找对应的监控手段和方式，看哪种手段和方式在性能测试过程中成本最低，效率最高

监控设计

1、我们要对整个架构做分层
2、在每一个层级上列出要监控的计数器
3、寻找相应的监控工具，实现对这些计数器的监控。如果一个工具做不到，在定位过程中考虑补充工具
4、要做到对每层都不遗漏

在企业中，我们也是首先考虑快速的监控实现。但是，还要一点要考虑，就是监控的持久有效性，能一直用下去。所以，在快速实现了之后，在必要时，会做一些二次开发，定制监控

什么是全局监控呢

OS 查看的第一层

DB 层（MySQL）

1、连接报表

2、临时表报表

3、线程表

4、Innodb缓存池报表

5、Innodb锁报表

6、Innodb数据、页、行报表

7、基本信息

8、索引报表

9、操作报表

10、查询和排序报表

11、查询缓存报表

12、表锁报表

13、表信息报表

定向监控

OS 层之定向监控细化 1

DB 层之定向监控

1、连接报表

SELECT COUNT(*) FROM information_schema.processlist

2、临时表报表

SELECT * FROM INFORMATION_SCHEMA.INNODB_TEMP_TABLE_INFO

3、线程表

select * from performance_schema.threads;

4、Innodb缓存池报表

select * from INFORMATION_SCHEMA.INNODB_BUFFER_POOL_STATS\G;

5、Innodb锁报表

select * from INFORMATION_SCHEMA.INNODB_LOCKS;

6、Innodb数据、页、行报表

7、基本信息

8、索引报表

9、操作报表

10、查询和排序报表

11、查询缓存报表

12、表锁报表

13、表信息报表

监控工具

1、性能分析中，TPS 和响应时间的曲线是要有明显的合逻辑的趋势的。如果不是，则要降线程， 增加 Ramp-up 来让 TPS 趋于平稳。
2、我们要对曲线的趋势敏感，响应时间的增加不可以过于陡峭，TPS 的增幅在一开始要和线程数对应。
3、当 TPS 和响应时间曲线抖动过于强烈，要想办法让曲线平稳下来，进而分析根本原因，才能给出线上的建议配置



# 全链路压测

重要的原则

线上系统是不允许有脏数据的
压测流量落影子库，正常流量落正常库
压测不能把系统压崩溃
压测是模拟流量最高峰时用户的操作行为，所以综合性的流量模型需要跟实际情况相符

# 其他资料

[微信红包系统是如何应对高并发的](http://www.52im.net/thread-2548-1-1.html)

[Feed流系统设计-总纲](https://zhuanlan.zhihu.com/p/72882547)

[现代IM系统中的消息系统架构 - 架构篇](https://zhuanlan.zhihu.com/p/65119683)

[system-design](https://www.hiredintech.com/system-design)

[程序员转型架构师，推荐你读这几本书](https://developer.aliyun.com/article/721088?spm=a2c6h.14164896.0.0.1fe999bdnE8TZn)

[架构师之路](https://z.itpub.net/stack/detail/10131)

[架构师之路17年精选80篇]https://mp.weixin.qq.com/s/CIPosICgva9haqstMDIHag

GIT

git init ：初始化本地库



工作区  暂存区 本地库

git add 文件

git commit -m "注释" 文件



日志展示

git log

git log --pretty=oneline

git log --oneline

git reflog

reset命令：前进或后退历史版本

git reset --hard 索引（log命令中显示的索引），本地库指针移动的同时，重置工作区、重置暂存区

git diff 将工作区中的文件和暂存区中的文件进行比对 

git status

git branch -v 查看分支

git branch  新分支名称 ：创建分支

git checkout 分支名称：切换分支

git merge  分支名称：合并分支

解决冲突

1、避免不同的人对一个文件进行修改

2、在修改之前，先执行pull，再push

# 系统高并发

三种通用方法：横向扩展、缓存和异步

分层有什么好处

分层的设计可以简化系统设计，让不同的人专注做某一层次的事情。

再有，分层之后可以做到很高的复用。

最后一点，分层架构可以让我们更容易做横向扩展

分层架构的不足	

​	增加了代码的复杂度

​	如果我们把每个层次独立部署，层次间通过网络来交互，那么多层的架构在性能上会有损耗

如何提升系统性能

性能优化原则

首先，性能优化一定不能盲目，一定是问题导向的

其次，性能优化也遵循“八二原则”

再次，性能优化也要有数据支撑

最后，性能优化的过程是持续的

性能的度量指标

平均值、最大值、分位值

一般我们度量性能时都会同时兼顾吞吐量和响应时间，比如我们设立性能优化的目标时通常会这样表述：在每秒 1 万次的请求量下，响应时间 99 分位值在 10ms 以下

高并发下的性能优化

1、提高系统的处理核心数

2、减少单次任务响应时间

CPU 密集型系统中，需要处理大量的 CPU 运算，那么选用更高效的算法或者减少运算次数就是这类系统重要的优化手段

IO 密集型系统指的是系统的大部分操作是在等待 IO 完成，这里 IO 指的是磁盘 IO 和网络IO。我们熟知的系统大部分都属于 IO 密集型，比如数据库系统、缓存系统、Web 系统

# 系统高可用

1、系统设计

预先考虑如何自动化地发现故障，发生故障之后要如何解决

还需要掌握一些具体的优化方法，比如failover（故障转移）、超时控制以及降级和限流

发生 failover 的节点可能有两种情况：

​	是在完全对等的节点之间做 failover

​	是在不对等的节点之间，即系统中存在主节点也存在备节点，Paxos，Raft

除了故障转移以外，对于系统间调用超时的控制也是高可用系统设计的一个重要考虑方面

系统自适应保护从整体维度对应用入口流量进行控制，结合应用的 Load、总体平均 RT、入口 QPS 和线程数等几个维度的监控指标，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性

限流是指对进入系统的用户请求进行流量限制，如果访问量超过了系统的最大处理能力，就会丢弃一部分的用户请求，保证整个系统可用，保证大部分用户是可以访问系统的

降级是为了保证核心服务的稳定而牺牲非核心服务的做法

失败隔离

​	将失败限制在一个较小的范围之内，使故障影响范围不扩大。具体实现失败隔离的主要架构技术是消息队列

异地多活

​	将数据中心分布在多个不同地点的机房里，这些机房都可以对外提供服务，用户可以连接任何一个机房进行访问，这样每个机房都可以提供完整的系统服务，即使某一个机房不可使用，系统也不会宕机，依然保持可用

​	异地多活的架构考虑的重点就是，用户请求如何分发到不同的机房去。这个主要可以在域名解析的时候完成

​	另一个至关重要的技术点是，因为是多个机房都可以独立对外提供服务，所以也就意味着每个机房都要有完整的数据记录

​	同一条数据，可能同时在两个数据中心被修改了，为了解决这种数据冲突的问题，可以让多个机房在某个时刻是有一个主机房的，某些请求只能到达主机房才能被处理，其他的机房不处理这一类请求，以此来避免关键数据的冲突

2、系统运维

通过自动化测试减少系统的Bug

通过自动化监控尽早发现系统的故障

为了提升系统的可用性，重视变更管理尤为重要。除了提供必要回滚方案，以便在出现问题时快速回滚恢复之外，另一个主要的手段就是灰度发布

灰度发布指的是系统的变更不是一次性地推到线上的，而是按照一定比例逐步推进的

故障演练指的是对系统进行一些破坏性的手段，观察在出现局部故障时，整体的系统表现是怎样的，从而发现系统中存在的，潜在的可用性问题

# 系统可扩展

拆分是提升系统扩展性最重要的一个思路，它会把庞杂的系统拆分成独立的，有单一职责的模块。相对于大系统来说，考虑一个一个小模块的扩展性当然会简单一些。将复杂的问题简单化

## 存储层的扩展性

存储拆分首先考虑的维度是业务维度

再次拆分是按照数据特征做水平的拆分

不能随意地增加节点，因为一旦增加节点就需要手动地迁移数据，成本还是很高的。所以基于长远的考虑，最好一次性增加足够的节点以避免频繁地扩容。

## 业务层的扩展性

一般会从三个维度考虑业务层的拆分方案，它们分别是：业务纬度，重要性纬度和请求来源纬度

按业务维度

把相同业务的服务拆分成单独的业务池，每个业务依赖独自的数据库资源，不会依赖其它业务的数据库资源。

当某一个业务的接口成为瓶颈时，我们只需要扩展业务的池子，以及确认上下游的依赖方就可以了，这样就大大减少了扩容的复杂度。

按业务的重要性

根据业务接口的重要程度，把业务分为核心池和非核心池。

我们可以优先保证核心池的性能，当整体流量上升时优先扩容核心池，降级部分非核心池的接口，从而保证整体系统的稳定性。

按请求的来源

根据接入客户端类型的不同做业务池的拆分

比如说，服务于客户端接口的业务可以定义为外网池，服务于小程序或者 HTML5 页面的业务可以定义为 H5 池，服务于内部其它部门的业务可以定义为内网池





