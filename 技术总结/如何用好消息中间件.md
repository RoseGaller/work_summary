# 文件读写的特性

读

顺序读:绝大部分对消息文件的读访问都是顺序读取

尾部读：大部分的消息生产后立即就会被消费，直接命中PageCache

写

追加写：消息只在文件尾部追加写入

不可变性：已写入的消息具有不可变性，不会被修改

# Push vs Pull

## Push

push模式很难适应消费速率不同的消费者，因为消息发送速率是由Broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息

## Pull

pull模式则可以根据Consumer的消费能力以适当的速率消费消息,简化Broker的设计

Pull模式不足之处是，如过生产者没有数据，消费者可能会陷入循环中，一直返回空数据。

# 如何解决分布式事务

## 本地事务表（去哪儿Qmq）

### 执行步骤

 	开启本地事务

​	执行业务操作

​	向同实例消息库插入消息

​	事务提交

​	向server发送消息

​	server回应消息

​	如果server回复成功则删除消息

### 事务补偿

​	扫描未发送消息

​	发送未发送成功的消息

​	删除补偿成功的消息

消息的发送在事务提交之后执行，此时数据库已经释放锁，减少了锁的占有时间，提高了并发

只涉及一次与中间件的网络交互，发送成功的消息对消费者来说立即可见

## 发送半消息(阿里Rocketmq)

### 执行流程

(1) 发送消息（half消息）

(2) 服务端响应消息写入结果

(3) 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）

(4) 根据本地事务状态执行Commit或者Rollback

### 事务补偿

(1) 对没有Commit/Rollback的事务消息，从服务端发起一次“回查”

(2) Producer收到回查消息，检查回查消息对应的本地事务的状态

(3) 根据本地事务状态，重新Commit或者Rollback

# 常见问题

## 如何解决丢失问题

### 生产端

发收到Broker的ack确认响应，就表示消息发送成功

### 服务端

Broker收到消息会进行持久化存储，并且同步到多个副本

### 消费端

在处理完业务逻辑之后，发送ack确认、幂等性

## 如何解决幂等问题

1、设置业务唯一标志

UUID

MySql的主键

雪花算法

Leaf（美团）

uid-generator（百度）

Tinyid（滴滴）

2、消费端在执行业务逻辑前先判断此消息是否处理过

去哪儿开源的消息中间件QMQ默认提供了基于db的幂等处理器，也可以很容易扩展自定义的幂等处理器

## 如何解决积压

接入监控系统，查看发送和消费的速度，确定积压的原因

生产端发送太快

​	扩容消费者实例，每一个分区对应一个消费者

​	系统降级：通过关闭一 些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要的服务

​	熔断：如果某个分区积压的数据过多，将此分区熔断，在熔断期内，不再向此分区发送数据，将数据发送至其他分区

消费端消费太慢

​	首先查看是否实例数少于分区数，如果是则进行扩容消费者实例

​	优化业务逻辑

​	查看日志，是否有错误；打印堆栈信息，是否触发了死锁或资源等待

​	可以考虑接入去哪网开源的消息中间件，没有分区的概念，可以启用多个消费者拉取数据消费，没有重平衡的概念

## 如何解决严格顺序

全局有序

把消息队列数配置成 1，生产者和消费者 也只能是一个实例，这样才能保证全局严格顺序。

局部有序

根据消息的某个属性作为 Key，可以用队列数量取模的简单方法来计算队列编号。

## 如何避免‘挖坟’

某个消费者拉取比较老的数据，导致pagecache填充大量老的数据；最新的数据被挤出PageCache，当其他消费者拉取最新的数据，由于pagecache中不存在，不得不从磁盘读取数据，降低拉取数据的性能

在主从模式下，当拉取的消息过于老时，不再从master拉取消息，而是由slave处理拉取请求，防止老数据污染master服务器上的PageCache



# 开源项目

## Kafka

### 生产端

自定义分区策略

开启压缩

​	根据CPU、带宽选择合适的压缩算法

无消息丢失配置

使用带有回调通知的 send 方法， producer.send(msg, callback)

ACK机制

0：Producer不等待Broker的ACK，这提供了最低延迟，Broker一收到数据还没有写入磁盘就已经返回，当Broker故障时有可能丢失数据

1：Producer等待Broker的ACK，Partition的Leader落盘成功后返回ACK，如果在Follower同步成功之前Leader故障，那么将会丢失数据

-1（all）：Producer等待Broker的ACK，Partition的Leader和Follower全部落盘成功后才返回ACK

设置 retries 为一个较大的值。 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了retries > 0 的 Producer 能够自动重试消息发送，避免消息丢失。

设置 unclean.leader.election.enable = false。这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader,如果Broker落后原先的Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。

设置 replication.factor >= 3。这也是 Broker 端的参数。最好将消息多保存几份

确保消息消费完成再提交，Consumer 端有个参数 enable.auto.commit，最好把它设置成 false,并采用手动提交位移的方式

ProducerInterceptor拦截器

onSend：该方法会在消息发送之前被调用

onAcknowledgement：该方法会在消息成功提交或发送失败之后被调用

Producer Exactly Once

0.11版本的Kafka，引入了幂等性：Producer不论向Server发送多少重复数据，Server端都只会持久化一条

将Producer的参数中enable.idompotence设置为true,开启幂等特性

开启幂等性的Producer在初始化时会被分配一个PID，发往同一Partition的消息会附带Sequence Number
而Borker端会对<PID,Partition,SeqNumber>做缓存，当具有相同主键的消息提交时，Broker只会持久化一条

### 事务

#### 概述

确保Producer端在一个事务中发送的多条消息，要么都成功，要么都失败

为了解决分布式事务问题，Kafka 引入了事务协调者这个角色，负责在服务端协调整个事务

Kafka 集群中一个特殊的主题用于记录事务日志

#### 流程

当开启事务的时候，生产者会给协调者发一个请求来开启事务，协调者在事务日志中记录下事务 ID

生产者还要给协调者发送请求，告知发送的消息属于哪个主题和分区，被协调者记录在事务日志中。

生产者像发送普通消息一样发送事务消息，保存在消息对应的分区中。当客户端消费时，暂时过滤尚未提交的事务消息

消息发送完成后，生产者给协调者发送提交或回滚事务的请求，由协调者来开始两阶段提交，第一阶段，协调者把事务的状态设置为“预提交”，并写入事务日志。到这里，实际上事务已经成功了

第二阶段，协调者在事务相关的所有分区中，都会写一条“事务结束”的特殊消息，最后，协调者记录最后一条事务日志，标识这个事务已经结束了

### Broker服务端

#### 可靠性保证

提供数据冗余， 确保系统高可用和消息高持久性

基于领导者（Leader-based）的副本机制

分成领导者副本和追随者副本，分区在创建时要选举一个副本，称为领导者副本，其余的副本称为追随者副本；

追随者副本不处理客户端请求，唯一的任务就是从领导者副本异步拉取消息，实现与领导者副本的同步

分区领导者副本挂掉了，kafka借助于zk可以实时感知到，并开启新一轮的领导者选举

方便实现Read-your-writes、方便实现单调读

创建Topic的时候可以指定分区的副本数

In-sync Replicas（ISR）

都是与Leader保持同步的副本，只有ISR里的成员才有被选为Leader的可能

 replica.lag.time.max.ms Follower 副本能够落后 Leader 副本的最长时间间隔，当前默认值是10秒

Unclean 领导者选举（Unclean Leader Election）

unclean.leader.election.enable 参数控制是否允许从非同步副本中选举领导者

非同步副本落后Leader太多，如果选择这些副本作为新 Leader，就可能出现数据的丢失。但是可以保证分区Leader副本一直存在，不至于停止服务，保证了高可用性

如果禁止从非同步副本中选举Leader副本，维护了数据的一致性，避免了消息的丢失，但是牺牲了可用性

#### 一致性保证

##### LEO(Log end offset)

日志末端位移，记录了该副本日志中下一条消息的位移值

##### HW(high watermark)

HW值不会大于LEO值。小于等于 HW值的所有消息都被认为是“已备份”的(replicated)，影响分区数据对消费者的可见性 

使用HW值来决定副本备份的进度，而HW值的更新通常需要额外一轮FETCH RPC才能完成，可能会导致备份数据丢失、备份数据不一致

何时更新LEO

Leader写Log时自动更新自己的LEO值

Leader在处理Follower FETCH请求时。一旦Leader接 收到Follower发送的FETCH请求，它先从Log中读取相应的数据，给Follower返回数据前，先更新远程副本中的Follower的LEO。

Follower发送FETCH请求后，Leader将数据返回给Follower，此时Follower开始Log写数据， 从而自动更新LEO值。

何时更新HW

Leader broker上保存了一套Follower副本的LEO以及自己的LEO。 当尝试确定分区HW时，它会选出所有满足条件的副本，比较它们的LEO(包括Leader的LEO)，并选择最小的LEO值作为HW值。

Follower向Log写完从Leader同步的数据之后，尝试更新自己的HW值。 比较当前LEO值与FETCH响应中Leader的HW值，取两者的小者作为新的HW值

##### Leader Epoch	

所谓Leader epoch实际上是一对值:<epoch, offset>:
1. epoch表示Leader的版本号，从0开始，Leader变更过1次，epoch+1
2. offset对应于该epoch版本的Leader写入第一条消息的offset

Leader 副本对定期地将Leader Epooch写入到一个 checkpoint 文件中。
当Leader写Log时它会尝试更新整个缓存:如果这个Leader首次写消息，则会在缓存中增加一个条目;否则就不做更新
每次副本变为Leader时会查询这部分缓存，获取出对应Leader版本的位移，则不会发生数据不一致和丢失的情况。

#### 请求如何处理

Kafka 使用的是Reactor 模式

Acceptor线程

负责连接的创建

采用轮询的方式为此连接选择一个Processor线程，负责后续的数据读写

一组Processor线程

num.network.threads，用于调整Processor的数目

读取数据封装成Request将其放到RequestChannel中。Request中包含了Processor的Id标志。RequestChannel是所有的Processor线程共享的

从responseQueue中获取Broker处理之后的响应信息。然后发送出去。responseQueue是Processor线程独有的。Broker处理完成后根据Request中的ProcessorId从RequestChannel获取对应的Processor线程，将Response加入到此Processor的responseQueue中。

请求的接收和写回都由同一个Processor处理

KafkaRequestHandlerPool请求处理线程池

num.io.threads调整线程池的大小；运行时可以动态调整

初始时创建KafkaRequestHandler线程并启动，从RequestChannel中获取请求交由KafkaApis处理

KafkaApis负责处理Kafka各种请求逻辑

Kafka中的请求分类

数据类请求

PRODUCE 和 FETCH 这类请求

控制类请求

LeaderAndIsr、StopReplica 这类请求

控制类请求可以直接令数据类请求失效

控制类请求享有比数据类请求更高的优先处理级别，不应该将两种请求一视同仁的处理

Kafka将两种请求进行了分离。分别创建了Acceptor线程和Processor线程池，分别处理数据类和控制类请求

#### 消费者组重平衡

消费者需要定期地发送心跳请求到Broker端的协调者，以表明它还存活着。
老版本中心跳请求和数据拉取请求在同一个线程中处理，如果消费处理逻辑比较耗时，就会导致心跳请求无法及时发送到协调者，导致协调者认为此消费者已经离开消费组。
新版本中使用了单独的线程处理心跳请求，重平衡的通知机制正是通过心跳线程来完成的
heartbeat.interval.ms设置了心跳的间隔，同时控制了重平衡通知的频率，值越小，消费端越能提早感知到已经发生了重平衡
session.timeout.ms：消费端参数，超过一定的时间，协调者没有收到消费者的心跳请求，就会触发重平衡

重平衡流程

消费者启动时，根据groupId查找所在的group协调器并建立连接

消费者发送JoinGroup请求到协调者。协调者会从这些消费者中择一个担任这个消费者组的领导者

选出领导者之后，协调者会把消费组下的成员信息和订阅的主题信息发送领导者，领导者为每个消费者分配应该消费哪些主题分区，然后将分配方案封装成SyncGroup，发送给协调者

其他成员也会向协调者发送SyncGroup请求，但是请求中不包含实际的内容，协调者会返回给消费者应该消费哪些主题分区

#### 控制器

借助Zookeeper管理和协调整个Kafka 集群

控制器选举

Broker 在启动时，会尝试去ZooKeeper中创建 /controller 节点。第一个成功创建 /controller节点的Broker会被指定为控制器

主题管理（创建、删除、增加分区）

分区重分配

Preferred领导者选举

集群内成员管理（Broker的新增、主动关闭、宕机）（借助Zookeeper的Watch机制）

数据服务（控制器保存了最全的元数据信息，向其他Broker提供数据服务）

底层的设计改进

老版本中，Kafka控制器是多线程设计。当多线程访问共享的控制器缓存数据，为了保护数据安全性，控制器使用ReentrantLock 同步机制，拖慢了整个控制器的处理速度

新版本中，将控制器中对共享数据的操作封装成ControllerEvent，放到ControllerEventManager的queue中，由ControllerEventThread处理ControllerEvent。好处是只有一个线程对共享数据操作，不再需要同步机制保证线程安全性，提高了性能

新版本中将之前同步操作 ZooKeeper 全部改为异步操作

#### 物理存储

日志存储

​	每个主题的分区对应一个磁盘目录，消息以分区为单位进行存储

​	每个主题分区目录下存放log、index、timeindex三个文件

​	索引文件是稀疏索引，它不会为每条日志都建立索引信息，但是有序，采用二分法进行查找

零拷贝

​	零拷贝并不是不需要拷贝，而是减少不必要的拷贝次数

​	传统方式实现，实际经过四次copy。 磁盘->内核->用户空间->socket buffer -> 网卡

​	零拷贝避免了内核和用户空间的数据拷贝

​	Linux 2.4+ 内核通过 sendfile 系统调用，提供了零拷贝

页缓存

​	把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问

​	Memory Mapped Files,简称mmap，将磁盘文件映射到内存, 用户通过修改内存修改磁盘文件。工作原理是直接利用操作系统的Page来实现磁盘文件到物理内存的直接映射。完成映射之后对物理内存的操作会被同步到硬盘上

顺序写入

​	采用了文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消息，并且也不允许修改已写入的消息

#### kafka调优

##### 性能调优

优化漏斗是一个调优过程中的分层漏斗，层级越靠上，其调优的效果越明显，整体优化效果是自上而下衰减的

第 1 层：应用程序层。它是指优化 Kafka 客户端应用程序代码。比如，使用合理的数据结构、缓存计算开销大的运算结果，抑或是复用构造成本高的对象实例等。

不要频繁地创建 Producer 和 Consumer 对象实例。对构建开销比较的对象，尽量复用。

资源用完及时关闭

合理利用多线程来改善性能

第 2 层：框架层。根据实际场景恰当地配置关键参数的值必要时修改kafka源码

保持Broker端和客户端的参数一致

第 3 层：JVM 层，合理配置JVM参数

设置合理的堆大小，建议6~8G

建议使用G1收集器

第 4 层：操作系统层。对CPU、磁盘IO、内存、网络调优

禁掉 atime 更新。避免每次写操作都修改文件的元信息

文件系统选择 ext4 或 XFS。尤其是 XFS 文件系统，它具有高性能、高伸缩性等特点

swappiness设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程

ulimit -n :如果设置得太小，你会碰到 Too Many File Open 这类的错误，
:vm.max_map_count:如果太小，在一个主题数超多的 Broker 机器上，会出现OutOfMemoryError：Map failed的严重错误，因此生产环境中适当调大此值，比如将其设置为 655360。具体设置方法
是修改 /etc/sysctl.conf 文件，增加 vm.max_map_count=655360，保存之后，执行sysctl -p 命令使它生效。

##### 调优延迟

Broker端

增加 num.replica.fetchers 值以加快 Follower 副本的拉取速度，减少整个消息处理的延时

Producer端

设置linger.ms=0，将消息尽快发送出去

禁用压缩，压缩需要消耗CPU时间，增加消息发送的延迟

最好不要设置 acks=all，设置acks=1

Consumer端

 fetch.min.bytes=1，只要Broker端有能返回的数据，立即令其返回给Consumer，缩短Consumer消费延时

##### 调优TPS

###### Broker

num.replica.fetchers 表示的是 Follower 副本用多少个线程来拉取消息。增加该值，可以缩短同步间隔，快速响应生产请求

避免经常性的 Full GC

###### Producer

batch.size：增加消息批次的大小

 linger.ms：批次缓存时间

启用压缩，LZ4 和 zstd

最好不要设置 acks=all 以及开启重试

buffer.memory：增大缓冲空间

###### Consumer

fetch.min.bytes：增加一次拉取的字节数

使用多线程处理业务逻辑

### 消费者

#### Consumer Group 

每个Consumer Group 都有一个唯一的Group ID标志

Consumer Group 下可以有一个或多个 Consumer 实例

主题下的Partition只能分配给组内的某个 Consumer 实例消费

理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数。

#### 位移的管理

老版本的 Consumer Group 把位移保存在 ZooKeeper中。ZooKeeper并不适合进行频繁的写更新

在新版本的 Consumer Group 中，将位移保存在 Kafka 内部主题__consumer_offsets

位移主题的Key中应该保存3部分内容：<GroupID，主题名，分区号 >；Value包括位移、提交时间。位移主题是 Kafka 自动创建的，那么该主题的分区数是 50，副本数是 3

 enable.auto.commit 为 true，表示自动提交；在消费端的后台会定时的提交消费位移信息，时间间隔由auto.commit.interval.ms（默认为5秒）

位移提交的实现

commitSync

调用 commitSync() 时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果，这个状态才会结束。影响应用的TPS

commitAsync

它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了

Kafka 使用Compact 策略来删除位移主题中的过期消息。对于相同key的多条消息，只会保存最新的消息。Broker端由后台线程Log Cleaner进行删除

#### 重平衡

##### 引起重平衡的原因

组成员数发生变更

订阅主题数发生变更

订阅主题的分区数发生变更

##### 缺陷

在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成

Rebalance 效率不高，Group 下的所有成员都要参与进来

Rebalance 很慢。 Group 下成员很多

##### 避免重平衡

1、尽量避免订阅主题数、订阅主题的分区数变更

2、避免Consumer Group 下的 Consumer 实例数量发生变化，大部分情况下是由于Group下实例数减少

​		Broker端的参数session.timeout.ms，心跳超时时间，即如果Group Coordinator在10秒之内没有收到心跳，它就会认为这个Consumer实例已经挂了

​		Consumer参数heartbeat.interval.ms，控制发送心跳请求的间隔，这个值设置得越小，Consumer 实例发送心跳请求的频率就越高。频繁地发送心跳请求会额外消耗带宽资源，但好处是能够更加快速地知晓当前是否开启组成员数量发生变化订阅主题数量发生变化订阅主题的分区数发生变化重平衡

​			max.poll.interval.ms 参数，用于控制 Consumer 实际消费能力对Rebalance 的影响，它限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔。它的默认值是 5 分钟，超过5分钟， Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。

​			避免GC导致的Stop The World

注：Kafka对心跳机制进行了修改，将发送心跳与拉取消息进行分离，这样使得发送心跳的频率不受拉取的频率影响

##### Group Coordinator

专门为 Consumer Group 服务，负责为 Group 执行Rebalance 以及提供位移管理和组成员管理等

如何为某个consumer group确定Coordinator所在的Broker

​	确定由位移主题的哪个分区来保存该 Group 数据：
​	partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)

找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator

##### CommitFailedException异常怎么处理

当消息处理的总时间超过预设的 max.poll.interval.ms 参数值并且用户显式调用 KafkaConsumer.commitSync() 方法时，Kafka Consumer 端会抛出 CommitFailedException 异常

1. 缩短单条消息处理的时间

2. 增加 Consumer 端允许下游系统消费一批消息的最大时长。 Consumer 端参数 max.poll.interval.ms 的值。在最新版的 Kafka 中，该参数的默认值是 5 分钟

3. 减少下游系统一次性消费的消息总数。这取决于 Consumer 端参数 max.poll.records的值。当前该参数的默认值是 500 条

4. 下游系统使用多线程来加速消费

kafka Java Consumer 端还提供了一个名为 StandaloneConsumer 的独立消费者，独立消费者也要指定group.id 参数才能提交位移。如果你的应用中同时出现了设置相同 group.id 值的消费者组程序和独立消费者程序，那么当独立消费者程序手动提交位移时，Kafka 就会立即抛出CommitFailedException 异常，

##### 监控消费进度

使用 Kafka 自带的命令行工具 kafka-consumer-groups 脚本
$ bin/kafka-consumer-groups.sh --bootstrap-server <Kafka broker 连接信息> --describe  --group testGroup

使用 Kafka Java Consumer API 编程

调用 AdminClient.listConsumerGroupOffsets 方法获取给定消费者组的最新消费消息的位移

获取订阅分区的最新消息位移

执行相应的减法操作，获取 Lag 值并封装进一个 Map 对象

使用 Kafka 自带的 JMX 监控指标

Kafka 消费者提供了一个名为 kafka.consumer:type=consumer-fetch-manager-metrics,client-id=“{client-id}”的 JMX 指标，有两组属性：records-lag-max 和 records-lead-min，它们分别表示此消费者在测试窗口时间内曾经达到的最大的 Lag 值和最小的 Lead 值。
Lead值是指消费者最新消费消息的位移与分区当前第一条消息位移的差值。Lead 越来越小，甚至是快接近于0了，预示着消费者端要丢消息了。 Kafka 的消息是有留存时间设置的，默认是1周。假如消费者程序足够慢，慢到它要消费的数据快被 Kafka 删除了，就会导致数据丢失

##### ConsumerInterceptor拦截器

onConsume：该方法在消息返回给 Consumer 程序之前调用。也就是说在开始正式处理消息之前

onCommit：Consumer 在提交位移之后调用该方法

## RocketMq（阿里）

### 消息堆积问题的解决方案

在有 Slave 情况下，Master发现Consumer访问堆积在磁盘的数据时，会向Consumer下达一个重定向指令，令Consumer从 Slave 拉取数据

默认情况下，如果堆积数据（拉取的数据所处的位置之后新增的数据）超过总内存的的40%，建议从slave拉取数据；避免'挖坟'导致尾部消息缓存命中率下降

监测消费组下的各消费者的消费进度，如果消费进度远小于写入进度，禁止此消费组拉取消息

### 存储模型

所有数据单独存储到一个 Commit Log，完全顺序写，随机读

每个主题的分区都有单独的索引文件，在消息写入时异步建立索引

### 存储优化

1、MappedByteBuffer，预分配内存，填充数据，防止读写时频繁发生缺页中断

2、锁定内存，防止页的回收

### 刷盘策略

同步刷盘

​	要等待刷盘完成才返回

异步刷盘

​	写完 PAGECACHE 直接返回

### 消息查询

按照 Message Id 查询消息

按照 Message Key 查询消息

### 服务端消息过滤

Broker端根据Tag的Hashcode进行过滤

Consumer根据tag内容进行过滤

### 消息拉取

使用长轮询方式从Broker端拉取消息

如果没有拉取到消息，会将PullRequest请求挂起，保存至PullRequestHoldService

PullRequestHoldService定时检测，消费的主题分区如果有新数据写入，则执行拉取请求；判断拉取请求是否已经超时。拉取请求的唤醒是被动的，有一定的时间延迟。

### 顺序消息

无法利用集群 FailOver 特性

依赖于队列数量

热点问题，导致消息堆积

### 事务消息

1、发送Prepare类型的消息
2、发送成功并返回SEND_OK，则执行本地事务，调用TransactionListener的executeLocalTransaction方法
3、事务执行成功，则发送RANSACTION_COMMIT_TYPE消息，回滚发RANSACTION_ROLLBACK_TYPE消息。以Oneway的方式发送消息，只关注发送成功，不关注响应

Prepare类型的消息对消费者是不可见的

Broker端会对Prepare类型的消息进行回查，给Producer端发送CHECK_TRANSACTION_STATE类型的请求，执行TransactionListener中的checkLocalTransaction，检测事务的执行情况

Broker端将处于Commit状态的事务消息，移到目标主题当中，建立索引，供消费者读取

RocketMQ 中的事务，确保执行本地事务和发消息这两个操作的原子性，RocketMQ 增加了一个事务反查的机制，来尽量提高事务执行的成功率和数据一致性

### 定时消息

不支持任意时间精度，支持特定的 level

HA

Slave 启动一个线程，不断从 Master 拉取 Commit Log 中的数据，然后再异步构建出Consume Queue 数据结构

HAService负责Slave的数据同步；

单独的数据同步端口，使用Java的NIO管理网络通信

### 死信队列

当一条消息初次消费失败，消息队列 RocketMQ 会自动进行消息重试；达到最大重试次数后，若消费依然失败，将其发送到死信队列

一个死信队列对应一个 Group ID

一个死信队列包含了对应 Group ID 产生的所有死信消息，不论该消息属于哪个 Topic

有效期与正常消息相同，均为 3 天，3 天后会被自动删除

### NameServer

架构设计

​	NameServer之间不需要通信

​	Broker消息服务器在启动的时向所有NameServer注册

​	NameServer与每台Broker保持长连接，并间隔30S检测Broker是否存活，如果检测到Broker宕机，则从路由注册表中删除

路由信息管理

​	保存关于Broker集群的整个路由信息和用于客户端查询的队列信息

## Qmq（去哪儿网）

1、延迟消息，默认支持两年内的消息（时间轮）

2、不同消费组之间的隔离（时间片）

## DeFiBus（微众银行）

1、生产者的隔离

​	当往某个队列发送消息失败时，将队列标记为隔离状态，在隔离过期之前将不再往这个队列发送消息，避免再次失败，降低失败概率

2. Consumer端的隔离  

   RocketMq数据的拉取是单线程的，在正常情况下，每次拉消息请求的执行都很快，不会有卡顿。一旦有Broker故障导致PullRequest的执行发生了卡顿，则该Consumer监听的所有Queue都会因为PullRequest执行的延迟而出现消息消费延迟

​		此处的隔离指的是将疑似有问题的任务隔离到另外的线程中执行，保证拉消息线程能够正常处理其他正常的任务。

## DDMQ（滴滴）

1、扩展了延迟消息的存储

​	使用DDMQ的生产SDK将延迟消息生产到PProxy中，然后PProxy会将延迟消息写入到提前配置好的 
inner topic 中。之后 Chronos 会消费 inner topic的消息并存储到内置的 RocksDB 存储引擎中。
Chronos 内置的定时服务会将到期的消息再次发送给 DDMQ 供业务方消费

2、实现了broker主从自动切换

​	 引入Zookeeper，从Nameserver中选出切换主从的Leader节点，每天Nameserver将探测到的Broker的信息注册到Zookeeper，Leader会根据各个注册到zk的broker的存活信息，决定是否切换

# 设计实现

## 生产端

### 数据压缩

​	考虑解压缩速率和压缩比，在内存紧张而CPU空闲时选择合适的压缩算法

​	考虑当前的瓶颈是在CPU还是在网络

​	压缩算法：ZIP，SNAPPY，LZ4，GZIP，XZ

### 发送方式

#### 单向发送

发送消息后立即返回，不关心发送结果，例如日志发送

#### 同步发送

发送消息后等待响应

#### 异步发送

发送消息后立即返回，在提供的回调方法中处理响应

#### Request-Reply同步发送

请求方发出消息后进行阻塞等待，直到消费者消费完这条消息返回响应结果

在每条请求消息中增加REPLY_TO属性来唯一标识每一个请求方实例

### 分区策略

随机

轮询

取模

### 消息类型

单条消息

批量消息

顺序消息

全局有序

局部有序

延时消息

​	支持固定时间粒度的RocketMq

​	支持任意时间粒度的Qmq

​	借助rocksdb实现任意时间粒度的DDMQ

过滤消息

事务消息

### 容断隔离机制

在发送消息前，会根据分区策略选择一个分区，如果分区发生故障导致发送异常，将此分区标记为隔离状态。在隔离期内不再往该分区发消息

当某个分区消息积压严重时，客户端触发熔断，优先往其他分区发消息，暂停往该熔断分区发送消息

## 消费端

### 消费类型

#### 广播消费

每一条消息需要投递到一个消费组下面所有的消费者实例，每个消费者消费的消息都是相同的

#### 集群消费

主题下的每个分区只会被消费组下的一个消费者实例消费，每个消费者处理的消息不同

### 拉取方式

#### 推送

服务端主动推送，实时性好，如果消费端处理慢，造成数据积压

#### 拉取

根据自身的处理的效率，拉取数据，不会有挤压，但有延迟

### 处理消息的类型

##### 并发消费

线程池中的线程可以并发对同一个消息队列的消息进行消费

##### 顺序消费

线程池中的线程对消息队列中的消息只能串消费

会进行加锁操作（本地对消费的队列加锁、broker端也对队列加锁）

### 重平衡

#### 触发的原因

订阅的主题发生变化（可控）

主题的分区发生变化（可控）

消费组下的消费者实例发生变化（不可控）

#### 避免重平衡

消费者故障是最常见的引发重平衡的原因，应尽力避免消费者故障，做好活性探测

主动控制订阅主题的变更以及主题下分区的变更

#### 如何判断消费者故障

消费端通过向服务端发送心跳包，服务端周期性进行探测消费者是否存活

控制发送心跳的频率、心跳的超时时间、连续超时的次数

服务端，可考虑将心跳请求与其他的请求相隔离，避免其他慢请求导致心跳出现延迟

#### 重平衡的不同实现

##### Kafka

影响消费端的TPS

如果消费组的消费者实例太多导致重平衡很慢

效率不高，每次重平衡时消费组的所有的消费者实例都会参与，不会考虑局部性原理，但是局部性原理对于提升系统性能特别重要

##### Qmq（去哪）

取消了重平衡

每个Topic对应一组索引文件，无Partition概念

消费者实例拉取时会根据拉取的Topic对应的索引文件，获取可以读取的offset，然后将读取的offset写入对应的pull log，记录在索引文件的拉取的逻辑偏移

可以很好解决数据积压的问题

##### RocketMQ重平衡

###### 旧的重平衡方式

重平衡和数据的拉取分离，重平衡不会影响消费端的TPS

启用单独的线程处理重平衡，每20秒执行一次；获取消费组下的所有消费者实例，以主题为单位为消费组下的每个消费者实例分配分区

重平衡之后，封装拉取请求，通知拉取线程池去拉取数据

拉取数据时，会判断请求的有效性，即此分区是否已经分配其他消费者实例

###### 全新的POP消费模型

避免消费者实例hang住，出现消费速度很慢甚至无法消费问题，进而导致消息堆积

一个分区的消费可以被所有的消费者拉取，可以有效避免消息的积压问题

将重平衡放到Broker端， broker会根据一定的算法将分区的消息分配消费者，会有加锁操作，并记录拉取的信息（offset），在未回复ack时，拉取的数据对其他消费者来说是不可见，超时后，重新分配给其他消费者

### 消息消费隔离

背景

某个消费组里含有大量的消费者实例，导致服务端大部分时间都在处理此消费组下的拉取请求，而其他的消费组下的消费者实例的拉取请求迟迟得不到处理

实现

Qmq引入actor模型，很好的做到公平调度

每个消费组对应一个Actor，该消费组下的消费者实例的拉取请求都存在Actor中

每个actor分配了一个最大执行时间(时间片)，如果该时间片耗完，即使有未处理的拉请求不再执行该actor，这个时候会将该actor放到线程池队列的末尾，继续执行其他的Actor

### 存活检测

周期性发送心跳请求

心跳请求和拉取请求相隔离，使用不同的线程处理，避免消费缓慢导致心跳超时，进而导致重平衡

### 流控

消费者本地缓存消息数

消费者本地缓存消息大小

## 服务端

### 存储设计

所有的Topic共享一个消息文件

Partition模型（RocketMQ）

一组消息文件用于存放消息，每个Partition对应一组索引文件

最大限度的利用了"磁盘在批量顺序写入时具有最佳性能"的特性，随着Topic增多没有明显的性能下降，可以提供更的Topic

局限性是灵活性欠佳，很难做到以Topic维度进行数据的复制、迁移和删除

非Partition模型（Qmq去哪儿）

没有采用基于partition的存储模型

一组消息文件用于存放消息

每个Topic对应一组索引文件（consume log）

每个消费者实例对应一组pull log，pull log记录的是拉取的消息在consume log中的sequence很好的解决消费者实例扩缩容的问题

以partition为单位进行存储（Kafka），适合批量消费

每个topic的每个partition都包含消息文件和索引文件，可能还有时间戳索引文件

批量写入时具备较好的性能；消费时都是顺序读取；以分区为存储单元，在数据复制、迁移上更加灵活

随着Partition的数量增多，写入时需要频繁的在多个消息文件之间切换，性能会显著下降

以topic为单位进行存储

每个Topic对应一组消息文件，顺序存放这个Topic的消息；每个Partition对应一组索引文件

在兼顾灵活性的同时，具有较好的性能，并且单个Topic可以支持更多的并发

### 索引设计

稀疏索引

​	节省空间，降低了查找速度

稠密索引

​	占用的空间多，查找速度快

### 请求处理

不同的请求使用不同的线程池，避免互相影响

如果操作系统PageCache繁忙。对生产消息的请求进行限流

如果请求在队列中积压的时间超过阈值，将其快速失败

### 避免内存溢出和频繁的垃圾回收

自动内存管理机制

对象池

​	对于需要频繁使用，占用内存较大的一次性对象，自行回收并重用这些对象

​	建立一个对象池。收到请求后，在对象池内申请一个对象，使用完后再放回到对象池中，这样可以反复地重用这些对象，有效地避免频繁触发垃圾回收

​	样例

​		Netty中的Recyle

​		Java中的Integer，默认对-128到127进行缓存

### 零拷贝

磁盘文件->内核中的PageCache->用户空间->Socket缓冲区->网卡，涉及四次拷贝

零拷贝避免了用户空间和内核空间的数据拷贝，减少了上下文切换

磁盘文件->内核中的PageCache->Socket缓冲区->网卡，涉及三次拷贝

如果网卡支持 SG-DMA（The Scatter-Gather Direct Memory Access）技术，去除 Socket 缓冲区的拷贝，只有 2 次内存拷贝磁盘文件->内核中的PageCache->网卡

### 刷盘机制

#### 同步刷盘

在返回写成功状态时，消息已经被写入磁盘

具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘， 然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写 成功的状态

##### 组提交

将多个刷盘操作合并成一个

减少了系统调用和上下文切换的次数

#### 异步刷盘

在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作返回快，吞吐量大

当内存里的消息量积累到一定程度时，统一触发写磁盘动作，快速写入磁盘

### 主从复制

主服务器负责消息的存储和拉取

从服务器只负责从主服务器复制数据，不对外提供服务

#### 同步复制

等Master和Slave均写成功后才返回给客户端写成功状态

如果Master出故障， Slave上有全部的备份数据，不会出现数据的丢失，但是同步复制会增大数据写入延迟，降低系统吞吐量

#### 异步复制

只要Master写成功 即可反馈给客户端写成功状态

如果Master出了故障，有些数据因为没有被写入Slave，有可能会丢失，但是系统拥有较低的延迟和较高的吞吐量

复制请求和其他的请求相隔离

使用独立的端口，处理从服务的连接、复制请求

避免其他的慢请求操作导致复制的延迟

建议Master和Slave配置成异步刷盘方式，主从之间配置成同步复制方式，这样即使有一台机器出故障，仍然能保证数据不丢

### 高效的磁盘IO

#### FileChannel+DirectBuffer

提高写入性能，避免了堆内存的一次拷贝

通过DirectBuffer写数据，是为了避免写数据时，发生GC导致数据发生变化

数据写入到DirectBuffer中不会立即commit，而是需要积攒若干页（默认4页）后，批量commit，写入PageCache

由于DirectBuffer中的数据必须commit之后才会被消费到，导致了数据消费的及时性

#### mmap

将文件的内容的全部或一部分直接映射到进程的地址空间，映射完成后，可以像访问普通内存一样做其他的操作，不必再调用read、write等系统操作

mmap并不分配物理地址空间，它只是占有进程的虚拟地址空间，当真正读写并发生缺页时才会分配真正的物理内存

为避免频繁发生缺页中断，对文件进行预热，预先分配内存

为了避免当前写的文件占用的内存被回收，对占用的区域进行锁定

#### buffered I/O（缓存IO）

写数据时先将数据写入用户缓冲区 ，然后再将用户缓冲区里的数据拷贝到内核缓冲区PageCache

如果是读的话则是先从内核缓冲区拷贝到用户缓冲区，再从用户缓冲区读数据

# PageCache

## 什么是PageCache

PageCache 是操作系统在内存中给磁盘上的文件建立的缓存。在读写文件的时候，并不会直接去读写磁盘上的文件，应用程序实际操作的都是PageCache

## 读数据

一种是 PageCache 中有数据，那就直接读取，这样就节省了从磁盘上读取数据的时间

另一种情况是，内存中没有数据，这时候操作系统会引发一个缺页中断，操作系统把数据从文件读到PageCache 中，然后应用程序再从 PageCache中继续把数据读出来

## 写数据

写入数据时，操作系统会先把数据写入到内存中的 PageCache，然后再一批一批地写到磁盘上

刷盘机制可以依赖操作系统，应用程序也可以自己控制刷盘操作

**最理想的情况，消息刚刚写入就被消费者消费**

## 如何产生？

写数据时会先写入内核缓冲区，如果内核缓冲区中还没有这个Page，就会发生PageFault 会去分配一个Page，数据写入后，该 Page 是一个DirtyPage，当DirtyPage中的内容同步到磁盘后，该Page变为Clean Page。读文件产生的Page Cache，它的内容跟磁盘内容是一致的，一开始是Clean Page。

## 如何回收？

### 何时回收

在申请内存的时候，即使没有可用的内存，只要还有足够可回收的Page Cache，就可以通过回收Page Cache 的方式来申请到内存

### 回收的方式

#### 直接回收

在进程申请内存的过程中同步进行的回收

可能会消耗很多时间，进而导致进程的后续行为都被迫等待，造成很长时间的延迟

#### 后台回收

不会影响应用的执行，应用进程和回收进程同时运行，互不影响

### 如何查看回收情况

 sar -B 1
02:14:01 PM  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff

02:19:01 PM      5.97    489.67  88026.03      0.18  48526.07   1061.53      0.00   1061.42     99.99

pgscank/s : kswapd(后台回收线程) 每秒扫描的page个数。
pgscand/s: Application 在内存申请过程中每秒直接扫描的 page个数。
pgsteal/s: 扫描的page中每秒被回收的个数。
%vmeff: pgsteal/(pgscank+pgscand), 回收效率，越接近100说明系统越安全，越接近0说明系统内存压力越大

### 如何查看脏页的积压和回写

cat /proc/vmstat | egrep "dirty|writeback"
r_dirty 40
nr_writeback 2

nr_dirty 表示当前系统中积压了多少脏页
nr_writeback 则表示有多少脏页正在回写到磁盘中，单位都是 Page(4KB)

## 内核如何维护？

内核通过inactive和active链表对pagecache进行管理

第一次读取文件后，文件内容都是inactive的，会放到inactive链表上。内存紧张时inactive链表上pagecache是会首先被回收掉的。有很多情况下文件内容往往只被读一次，它们占用的pagecache需要首先被回收掉

第二次读取后，这些内容就会从inactive链表里给提升到active链表里，也就是二次机会法；二次机会法避免出现大量的一次性数据查询占用过多的pagecache，从而把热点数据从缓存中挤掉的情况

在内存紧张时，会优先把inactive list的部分page给回收掉，为了维持inactive/active的平衡，也会把active list的部分page给移到到inactive list上

## 引发的业务抖动的原因

### 1、直接内存回收

背景

进程申请内存的过程中同步进行的回收，导致进程的后续行为都被迫等待，造成很长时间的延迟

解决

及早地触发后台回收来避免应用程序进行直接内存回收

配置

当内存水位低于 watermark low 时，就会唤醒 kswapd 进行后台回收，然后 kswapd 会一直回收到 watermark high

vm.min_free_kbytes = 4194304，可以增大 min_free_kbytes 这个配置选项来及早地触发后台回收；min_free_kbytes需要合理设置，既不造成较多的内存浪费，又能避免掉绝大多数的直接内存回收

### 2、系统中脏页过多

如果存在较多脏页就可能涉及在回收过程中进行回写，这可能会造成非常大的延迟

控制好系统中积压的脏页数据

sar -r 来观察系统中的脏页个数
vm.dirty_background_bytes = 0 #脏数据占用空间字节数超过此阈值，后台进程异步写入磁盘
vm.dirty_background_ratio = 10#内存可以填充脏数据的百分比。这些脏数据稍后会有后台进程写入磁盘
vm.dirty_bytes = 0 #脏数据占用字节数超过此阈值，以直接内存回收的方式将其写入磁盘，容易造成IO卡顿
vm.dirty_expire_centisecs = 3000	#脏数据能存活的时间。当调用flush时，如果脏数据存活的时间超过此阈值，将其写入磁盘。时间越长，造成丢数据的风险越大
vm.dirty_ratio = 20 #用脏数据填充的最大系统内存量，超过了同步回收
vm.dirty_writeback_centisecs  #指定多长时间 pdflush/flush/kdmflush 这些进程会唤醒一次

### 3、系统 NUMA 策略配置不当

设置 zone_reclaim_mode 的目的是为了增加业务的 NUMA 亲和性，但是在实际生产环境中很少会有对 NUMA 特别敏感的业务

将配置参数修改为0，就避免了在其他 node 有空闲内存时，不去使用这些空闲内存而是去回收当前 node 的 Page Cache，也就是说，通过减少内存回收发生的可能性从而避免它引发的业务延迟

numactl --hardware查看是否还有一半内存空闲，但是还是频频发生direct reclaim

## 如何避免回收而引起的性能问题

对于重要的数据，可以通过 mlock(2) 来保护它，防止被回收

对于不重要的数据（比如日志），那可以通过 madvise(2) 告诉内核来立即释放这些 Page Cache

madvise可以告诉内核你预计会在哪些内存区域进行读取或写入操作，从而让内核能够做出更优的内存管理决策

MADV_NORMAL：使用该值告诉内核这是一个常规的、无特殊属性的内存区域。这是默认的建议类型

MADV_RANDOM：告诉内核这个内存区域会被随机地访问

MADV_SEQUENTIAL：告诉内核这个内存区域会被顺序地访问

MADV_WILLNEED：告诉内核这个内存区域将在不久的将来被访问

MADV_DONTNEED：告诉内核这个内存区域将不再被访问

## 如何查看使用情况

通过lsof可以查看某个应用打开的文件

然后再使用fincore可以看这些文件有多少内容在pagecache。或者应用程序里直接调用mincore也可以查看page cache有多少

## 合适的文件系统

Ext3文件系统耗时约1s左右，且删除文件时，磁盘IO压力极大，会导致IO写入超时

Ext4文件系统删除1G大小的文件通常耗时小于50ms

## 合适的磁盘调度算法

磁盘IO调度算法需要调整为 deadline，因为deadline算法在随机读情况下，可以合并读请求为顺序读，从而提高读IO吞吐量





# 其他资料

[Helix](http://helix.apache.org/)

[uReplicator](https://github.com/uber/uReplicator)

[58同城分布式消息队列WMB](https://mp.weixin.qq.com/s/2vPnQ2XYVBa3tCOAFhFIvw)

[快手万亿级别Kafka集群应用实践与技术演进之路](https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&mid=2247496484&idx=1&sn=4238cc7f88860559861178a083e5b475&chksm=fbea4aebcc9dc3fdb370a413e38daace82cbfb431108b1348bd20b13dc896c31eff39978a525&scene=4)

[京东JMQ](https://www.jiqizhixin.com/articles/2019-01-21-19)

[Rocketmq全新的消费模型](https://developer.aliyun.com/article/780035?spm=a2c6h.13262185.0.0.17ff12aexOcLfd)
