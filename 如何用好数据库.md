# 数据扩容

1、停机扩容

2、平滑扩容

平滑扩容就是将数据库数量扩容成原来的2倍，比如：由2个数据库扩容到4个数据库

​	1、新增2个数据库

​	2、配置双主进行数据同步

​	3、应用程序开启双写

​	4、数据同步完成*后，修改数据库配置，删除双主同步，并应用程序关闭双写

​	5、数据一致性校验*

​	6、编写程序删除新旧数据库上多余的数据

# 监控

## 可用性监控

## 性能监控

## 主从复制监控

### 主从同步的链路状态

### 主从复制的延迟

# 分布式数据库

## 主键策略

### UUID

使用UUID做主键，可以在本地生成，没有网络消耗，所以生成性能高。但是UUID比较长，没有规
律性，耗费存储空间。如果UUID作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，影响性能

### SNOWFLAKE

SnowFlake是Twitter开源的分布式ID生成算法，结果是一个long型的ID，long型是8个字节，64-bit。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号，最后还有一个符号位，永远是0

SnowFlake生成的ID整体上按照时间自增排序，并且整个分布式系统内不会产生ID重复，并且效率较高。经测试SnowFlake每秒能够产生26万个ID。缺点是强依赖机器时钟，如果多台机器环境时钟没同步，或时钟回拨，会导致发号重复或者服务会处于不可用状态。因此一些互联网公司也基于上述的方案做了封装，例如百度的uidgenerator（基于SnowFlake）和美团的leaf（基于数据库和SnowFlake）等

### 数据库ID表

单独的创建一个MySQL数据库，在这个数据库中创建一张表，这张表的ID设置为自动递增，其他地方需要全局唯一ID的时候，就先向这个这张表中模拟插入一条记录，此时ID就会自动递增

虽然可行，但是性能和可靠性都不够好

### Redis生成ID

Redis是单线程的，可以用生成全局唯一的ID。可以用Redis的原子操作 INCR和INCRBY来实现

也可以使用Redis集群来获取更高的吞吐量。假如一个集群中有5台Redis。可以初始化每台Redis的值分别是1,2,3,4,5，然后步长都是5

## 数据分片

### 基于范围分片

根据特定字段的范围进行拆分。

新的数据可以落在新的存储节点上，如果集群扩容，数据无需迁移。

数据热点分布不均，数据冷热不均匀，导致节点负荷不均

### 哈希取模分片

先计算分片字段的哈希值，然后再对数据库数量取模

实现简单，数据分配比较均匀，不容易出现冷热不均，负荷不均的情况

扩容时会产生大量的数据迁移，绝大部分数据需要重新分配和迁移

### 一致性哈希分片

用Hash取模的方式进行拆分，后期集群扩容需要迁移旧的数据。使用一致性Hash算法能够很大程度的避免这个问题

一致性Hash是将数据按照特征值映射到一个首尾相接的Hash环上，同时也将节点（按照IP地址或者机器名Hash）映射到这个环上。对于数据，从数据在环上的位置开始，顺时针找到的第一个节点即为数据的存储节点

一致性Hash在增加或者删除节点的时候，受到影响的数据是比较有限的，只会影响到Hash环相邻的节
点，不会发生大规模的数据迁移

## 数据复制

### 同步复制

### 异步复制

## 一致性

### 强一致性

### 最终一致性

## 分布式事务

### 中心化事务

#### TCC

#### SAGA

### 非中心化事务

#### Percolator

### 避免分布式事务

#### OceanBase数据库

单台机器负责增删改，定期将增删改操作同步至对应的数据所在的机器，进行合并

## 存储引擎

### B+树

对读操作优化的存储结构，能够支持高效的范围扫描

但是有写放大、磁盘存储不连续、页分裂及合并的问题

### LSM

随机写优化为顺序写，但是有读放大、写放大的劣势

# 分库分表

## 原则

能不切分尽量不切分

根据业务的类型，判断是否可以冷热数据分离，对老数据进行归档

如果要切分一定要选择合适的切分规则，提前规划好

数据切分尽量通过数据冗余或表分组降低跨表join的可能

对于分库分表之后的富查询，可以借助es、hbase实现

## 方式

垂直分库

水平分库

垂直分表

水平分表

# 一条sql语句的执行过程

## 连接器

管理连接，权限认证

过多使用长连接后，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面。

可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection 来重新初始化连接资源

## 查询缓存

之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个
value 就会被直接返回给客户端

查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。

注意，MySQL 8.0 版本直接将查询缓存的整块功能删掉了

## 分析器

词法分析

​	识别出SQL语句里面的字符串分别是什么，代表什么

语法分析

​	ast抽象语法树、 antlr4

​	语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足 MySQL 语法

## 优化器

两种优化方式，基于执行成本的优化（CBO cast）和基于规则的优化(RBO rule)

优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。除此之外，优化器还会结合是否使用临时表、是否排序等因素进行综合判断

有时MySQL 选错索引可能是在在判断扫描行数的时候出了问题。扫描行数是根据统计信息来估算记录数，统计信息是根据采样的来的。采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数

当使用普通索引查询数据时，优化器会估算两个选择的代价，一个是回表的代价，另一个是直接扫描主键索引的代价。

对于由于索引统计信息不准确导致的问题，可以用 analyze table 来解决

## 执行器

操作存储引擎，返回结果

## 存储引擎

存储数据，提供读写接口

读

优先将磁盘中的数据加载到内存中

内存缓冲池

索引查询

自适应hash索引

# 更新语句是如何执行的

执行器先从引擎中查找数据，如果在内存中，直接返回，如果不在内存中，查询后返回

执行器拿到数据后，会先修改数据，然后调用引擎接口重新写入数据

引擎将数据更新到内存中，同时写数据到redolog中，此时处于prepare阶段，并通知执行器执行完成，随时可以操作

执行器生成这个操作的binglog（是属于MySQLServer层的，并不专属于Innodb）

执行器调用引擎的事务提交接口，引擎把刚刚写完的redo改成commit状态,更新完成

涉及到undolog、redolog、binlog、changebuffer、doublebuffer

# 存储引擎

## Innodb

表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数innodb_file_per_table 控制的。

在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的

通过 delete 命令是不能回收表空间的但是可以复用

使用 alter table A engine=InnoDB 命令来重建表。

### Read View

Read View是事务进行快照读操作的时候生产的读视图，在该事务执行快照读的那一刻，会生成一个数据系统当前的快照，记录并维护系统当前活跃事务的id，最大作用是用来做可见性判断的

RC级别下，每一条读操作语句都会创建新的Read View

RR级别下，当第一次select时，会创建一次Readview，之后的读操作基于ReadView去读

Read View会用到回滚日志undolog，回滚段日志太长可能导致慢查询

而长事务就会导致回滚日志过长，在实际开发中要避免长事务

当系统里没有比这个回滚日志更早的 read-view 的时候，回滚段才会被删除

### MVCC

#### 概念

读不加锁，读写不冲突；只在Read Commited 和 Repeatable Read 两种隔离级别下工作

#### 快照读

读取的是记录的可见版本（有可能是历史版本），不用加锁

简单的 select 操作，属于快照读，不需要加锁

#### 当前读

读取的是记录的最新版本，都会加锁，保证其他事务不会再并发修改这条记录

特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁

#### 流程

#### 隐含字段

DB_ROW_ID：主键Id，没有指定主键时，自动生成

DB_TRX_ID：最新更新这条行记录的事务Id

DB_ROLL_PT：指向当前记录项的 Rollback Segment 的 Undo log记录，通过这个指针才能查找之前版本的数据

并发访问(读或写)数据库时，对正在事务内处理的数据做多版本的管理。以达到用来避免写操作的堵塞，从而引发读操作的并发问题

事务未提交之前，Undo保存了未提交之前的版本数据，Undo 中的数据可作为数据旧版本快照供
其他并发事务进行快照读

##### 三个全局属性

trx_list:一个数值列表，用来维护Read View生成时刻系统正活跃的事务ID

up_limit_id:记录trx_list列表中事务ID最小的ID

low_limit_id:Read View生成时刻系统尚未分配的下一个事务ID

##### 比较规则

​	主要是将要符合查找条件的数据的最新记录中的DB_TRX_ID取出来，与系统当前其他活跃事务的id去对比，如果DB_TRX_ID跟Read View的属性做了比较，不符合可见性，那么就通过DB_ROLL_PTR回滚指针去取出undolog中的DB_TRX_ID做比较，即遍历链表中的DB_TRX_ID，直到找到满足条件的DB_TRX_ID,这个DB_TRX_ID所在的旧记录就是当前事务能看到的最新老版本数据

​		1、首先比较DB_TRX_ID < up_limit_id,如果小于，则当前事务能看到DB_TRX_ID所在的记录，如果大于等于进入下一个判断

​		2、接下来判断DB_TRX_ID >= low_limit_id,如果大于等于则代表DB_TRX_ID所在的记录在Read View生成后才出现的，那么对于当前事务肯定不可见，如果小于，则进入下一步判断

​		3、判断DB_TRX_ID是否在活跃事务中，如果在，则代表在Read View生成时刻，这个事务还是活跃状态，还没有commit，修改的数据，当前事务也是看不到，如果不在，则说明这个事务在Read View生成之前就已经开始commit，那么修改的结果是能够看见的。

### 内存

#### BufferPool

Buffer Pool 对应的一片连续的内存被划分为若干个页面，页面大小与InnoDB 表空间使用的页面大小一致，默认16K，表记录和索引会在page页中缓存，可以减少磁盘IO操作,提高读写性能

将innodb_buffer_pool_size设置为总内存大小的60%-80%， innodb_buffer_pool_instances可以设置为多个

为了更好地管理这些page，为每个page都创建了控制信息，包括page所属的表空间编号、页号、page在buffer pool中的地址、链表节点信息等



##### page的类型

###### clean page

干净的page，表示未被修改，存放刚从磁盘读取的数据

###### dirty page

脏数据，表示被修改

###### free page

空闲的page，未被使用

##### page的管理

###### free list

表示空闲缓冲区，管理free page

###### flush list

如果我们修改了Buffer Pool中某个缓冲页的数据，它就与磁盘上的页不一致了，这样的缓冲页也称为脏页(dirty page)

每次修改缓冲页后，我们并不着急立即把修改刷新到磁盘上，而是在未来的某个时间点进行刷新

每个被修改过的缓冲页对应的控制块都会作为一个节点加入到这个链表中

管理dirty page，内部page按修改时间排序

###### lru list

表示正在使用的缓冲区，管理clean page和dirty page

#### 改进版的LRU

按照某个比例将LRU链表分成两半，分为young区和old区，young区存放多次访问的热数据，old用区于存放只访问一次的数据

innodb_old_blocks_pct，默认情况下old区域在LRU链表中所占的比例是37%，启动时修改此选项来控制old 区域在LRU链表中所占的比例

innodb_old_blocks_time变量的默认值是1000，单位是ms，也就意味着对于从磁盘加载到LRU链表中old区域的某个页来说，如果第一次和最后一次访问该页面的时间间隔小于1s，那么该页是不会加入到young区域的

扫描时先将数据页先放到Old区，当数据页再次访问时，计算距离上次访问的时间差，如果超过配置的阈值，就将其放到young区，否则还是位于old区

在顺序扫描的时候，每个数据页两次访问的时间差很小，不会将其放入到young区

避免了全表扫描过程中，大量的冷数据页（只需要访问一次，后续不再访问）占用内存，将热数据页剔除内存，导致的缓存命中率下降



对于young区域的缓冲页来说，我们每次访问一个缓冲页就要把它移动到LRU链表的头部，这样开销是不是太大了

为了解决这个问题，其实我们还可以提出一些优化策略，比如只有被访问的缓冲页位于young 区域1/4的后面时，才会被移动到LRU链表头部。这样就可以降低调整LRU链表的频率，从而提升性能



#### Linux中的LRU

第一次读取文件后，文件内容都放到inactive链表上，只有再次访问才会从inactive链表上转移到active上，active链表存放业务需要多次访问的数据

在内存紧张的情况下优先回收inactive链表上的数据，为了维护inactive链表和active链表的平衡，就需要将active链表上的数据转移到inactive链表

第二次机会法，避免大量只读一次的文件占用大量内存，将业务经常访问的数据挤出内存

#### change buffer

当需要更新一个数据页时，如果数据页在内存中就直接更新
而如果这个数据页没有在内存中，InooDB 会将这些更新操作缓存在 changebuffer 中，这样就避免了从磁盘中读入这个数据页
在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作

将更新操作记录在 change buffer，减少磁盘的随机读

适用于普通索引的更新和更新之后不需要立刻读的场景。不适用于唯一索引的更新

#### Adaptive Hash Index

自适应哈希索引，InnoDB存储引擎会监控对表索引的查找，如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，所以称之为自适应。

#### Log Buffer

日志缓冲区，用来保存要写入磁盘上log文件（Redo/Undo）的数据，日志缓冲
区的内容定期刷新到磁盘log文件中

### 锁

锁主要是加在索引上，如果对非索引字段更新,行锁可能会变表锁

#### 两阶段锁协议

锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放

#### 锁类型

表锁

行锁

单个行记录的锁

Gap Lock 锁

间隙锁，锁定一个范围，不包括记录本身

Next-key Lock 锁

同时锁住数据，并且锁住数据之间的间隙

#### 死锁的检测

1、获取不到锁，直接进入等待，直到超时；
超时时间可以通过参数innodb_lock_wait_timeout 来设置
超时时间不好控制，太大导致等待时间过长，太小容易造成误伤

2、发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行
将参数 innodb_deadlock_detect 设置为 on，开启死锁检测，死锁检测会耗费大量的CPU资源

死锁检测算法wait-graph

MySQL维护一个等待图;其中节点表示事务;边表示事务之间的依赖关系

如果事务A等待事务B持有的资源;就会在等待图中添加一条从A指向B的边

MySQL会定时检测图中是否存在环来判断是否发生死锁。通过选择牺牲者进行回滚来解决死锁问题

#### 解决热点行更新导致的性能问题

##### 1、临时关闭死锁检测

##### 2、控制并发度

​	在客户端对相同行的更新，顺序执行

​	在服务端，对于相同行的更新，在进入引擎之前排队，数据库内部实现排队

​	将一行数据改成逻辑上的多行来减少冲突

#### 查看行锁信息

show status like 'innodb_row_lock%';

注意行锁的等待时长、等待次数、平均等待时长

#### 如何避免死锁

加锁顺序一致

尽量基于 primary 或 unique key 更新数据

单次操作数据量不宜过多，涉及表尽量少；避免长事务

减少范围更新

#### 行级锁优化建议

尽量控制事务的大小，减少锁定的资源量和锁定时间长度

尽可能让所有的数据检索都通过索引来完成，从而避免因为无法通过索引加锁而升级为表级锁定

尽可能减少基于范围的数据检索过滤条件

在业务环节允许的情况下，尽量使用较低级别的事务隔离，以减少因为事务隔离级别锁带来的附加成本

在应用中，尽可能按照相同的访问顺序来访问，防止产生死锁；通常情况下，死锁都是应用设计的问题，通过调整业务流程、事务大小、数据库访问的SQL语句，绝大多数死锁都可以避免

#### 不同情况下的加锁实现

##### 组合一:id主键+RC

Table t1(id primary key,name )

id是主键，Read Committed隔离级别，给定SQL:delete from t1where id = 10; 只需要将主键上，id = 10的记录加上X锁即可

##### 组合二:id唯一索引+RC

Table t1(name primary key,id unique  key)

给定SQL:delete from t1where id = 10,首先会将unique索引上的 id=10索引记录加上X锁，同时，会根据读取到的name列，回主键索引(聚簇索引)，然后将聚簇索引上的主键索引项加X锁

在主键上加锁，是为了让其他的增删改操作感知到delete的存在，否则就违背了同一记录上的更新/删除需要串行执行的约束

##### 组合三:id非唯一索引+RC

Table t1(name primary key,id unique  key)

若id列上有非唯一索引，那么对应的所有满足SQL查询条件的记录，都会被加锁。同时，这些记录在主键索 引上的记录，也会被加锁

##### 组合四:id无索引+RC

若id列上没有索引，SQL会走聚簇索引的全扫描进行过滤，由于过滤是由MySQL Server层面进行的。因此每 条记录，无论是否满足条件，都会被加上X锁

##### 组合五:id主键+RR

加锁情况与组合一相同

##### 组合六:id唯一索引+RR

加锁情况与组合二相同

##### 组合七:id非唯一索引+RR

Table t1(name primary key,id unique  key)

相比组合三，多了GAP锁，GAP锁不是加在记录上的，而是加在两条记录之间的位置

Repeatable Read隔离级别下，id列上有一个非唯一索引，对应SQL:delete from t1 where id = 10; 首先， 通过id索引定位到第一条满足查询条件的记录，加记录上的X锁，加GAP上的GAP锁，然后加主键聚簇索引上的记 录X锁，然后返回，然后读取下一条，重复进行。直至进行到第一条不满足条件的记录，此时，不需要加记录 X锁，但是仍旧需要加GAP锁

##### 组合八:id无索引+RR

在Repeatable Read隔离级别下，如果进行全表扫描的当前读，那么会锁上表中的所有记录，同时会锁上聚 簇索引内的所有GAP，杜绝所有的并发 更新/删除/插入 操作

##### 组合九:Serializable

读写均加锁，串行执行

### 事务

#### ACID

原子性

事务的所有操作，要么全部完成，要么全部不完成，不会结束在某个中间环节

一致性

事务开始之前和事务结束之后，数据库的完整性限制未被破坏

约束性（唯一索引）

隔离性

当多个事务并发访问数据库中的同一数据时，所表现出来的相互关系

持久性

事务完成之后，事务所做的修改进行持久化保存，不会丢失

#### 隔离性

读未提交

读到一个事务的中间过程

读已提交

读到其他事务已经提交的数据

可重复读

默认的级别，通过gap锁实现，在这种级别下会经常发生死锁、低并发等问题

可串行化

所有的实现都是通过锁来实现的

**对于SQL语句而言，隔离级别越高，InnoDB存储引擎给记录添加的锁就越严格，产生锁冲突的可能性就越高，对并发的性能影响就越大**

#### 两阶段提交

将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"

写入redolog处于prepare阶段 -> 写binlog -> 提交事务redolog处于commit状态

两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案

### 聚集索引

主键索引的叶子节点会存储数据行，也就是说数据和索引是在一起

辅助索引只会存储主键值，对于辅助索引的查询且在无覆盖索引的情况下需要查询两颗索引树

### 自适应哈希索引

存储引擎会监控表上各个索引页的查询，当某些索引值访问非常频繁时，会在内存中基于B+Tree索引再创建一个哈希索引



### Undo Log

存放记录修改前的数据

用来实现事务的回滚、实现多版本并发控制

### Redo Log

类似WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘；优化随机写为顺序写

当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log buffer，适当的时候将这个操作记录更新到磁盘redo log文件中

有一组文件，可以循环写入，文件大小是是固定的。write pos表示当前写入的位置，checkpoint表示当前要擦除的位置，擦除记录前要把记录更新到数据文件。如果write pos追上checkpoint，表示写满，阻塞当前的执行的变更操作，停下来先擦掉一些记录

持久化策略

0：每次事务提交时都只是把 redo log 留在 redo log buffer 中 

1：每次事务提交时都将 redo log 直接持久化到磁盘

2：每次事务提交时都只是把 redo log 写到 page cache，由操作系统决定调用fsync

InnoDB 有一个后台线程，每隔1秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘

如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次

每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了

 MySQL 的“双 1”配置，指的就是 sync_binlog 和innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。

redolog是顺序写，并且可以组提交（group commit）机制进行优化

日志逻辑序列号（log sequence number，LSN）

LSN是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redolog， LSN 的值就会加上 length

如果三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo logbuffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160

1、trx1 是第一个到达的，会被选为这组的 leader；
2、等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了160；
3、 trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于160 的 redo log，都已经被持久化到磁盘
4、这时候 trx2 和 trx3 就可以直接返回了

一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好

为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间

1、redolog prepare :write

2、binlog write

3、redolog prepare fsync

4、binglog fsync

5、redolog commit write

想提升 binlog 组提交的效果，可以一下两个参数来实现

binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;

binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用fsync

### binlog

binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用

一个事务的 binlog 是不能被拆开的，所以系统给每个线程分配一个binlog cache，存放一个 完整的事务

事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中

持久化策略

sync_binlog=0 的时候，表示每次提交事务都只 write（把日志写入到文件系统的 page cache），不 fsync

sync_binlog=1 的时候，表示每次提交事务都会执行 fsync

 sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才fsync

在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。但是如果主机宕机，会丢失最近N个事务的binlog日志

### doublebuffer

主要解决由于宕机引起的物理写入操作中断，数据页不完整的问题，Mysql中页的单位是16k，而操作系统一般是4k

## [MyRocks](https://blog.csdn.net/n88Lpo/article/details/108970551)

写流程

每个事务都有一个writebatch对象，用于缓存该事务在提交前修改的所有数据。

事务提交时，将缓存的数据写入WAL文件缓冲区，根据配置参数选择是否持久化

将提交的数据写入内存的active memtable，当active memtable占用空间达到阈值会变为immutable，再生成新的active memtable

读流程

首先查找本事务对应的writebatch中是否存在请求的数据

接着查找memtable，包括active和immutable

然后基于sst文件元数据查找所需的数据对应的文件是否缓存在block cache中。如果没有被缓存，那么需将对应的SST文件加载到block cache中

优点分析

存储效率高，不存在页内碎片

顺序写

存储空间小。写sst文件时，进行前缀压缩，每16条记录才有一条完整的

压缩效率高

## MyISAM

不支持事务

支持表级锁

记录表的行数

索引和数据分开存储

二级索引树的叶子节点存储主键所在的磁盘位置。

# 主从复制

## 流程

备库会启动两个线程，io_thread和 sql_thread

io_thread 负责与主库建立连接，主库校验用户名、密码后，开始按照备库传过来的位置，从本地读取 binlog，发给备库

备库拿到 binlog 后，写到本地文件，称为中转日志（relay log）

sql_thread 读取中转日志，解析出日志里的命令，并执行

## 复制策略

### 单线程复制

5.6 版本之前，只支持库级别的单线程复制

### 多线程复制

同一个事务不能被拆开，必须放到同一个线程执行

不能造成更新覆盖，对同一行进行更新的两个事务，必须被分发到同一个线程执行

### 5.6版本的并行复制策略

支持的粒度是按库并行

如果主库上的表都放在同一个DB里面，这个策略就没有效果了

### 基于分组的并行复制

通过对事务进行分组，然后进行组提交。以事务的粒度并行复制

InnoDB事务提交采用的是两阶段提交模式。一个阶段是prepare，另一个是commit。并行复制基于一个前提，即所有已经处于prepare阶段的事务，都是可以并行提交的。这个阶段的事务都是没有冲突的。在一个组里提交的事务，一定不会修改同一行。

### 基于 WRITESET 的并行复制

基于write-set的并行复制，以row的粒度并行复制

MySQL会有一个集合变量来存储事务修改的记录信息（主键哈希值），所有已经提交的事务所修改的主键值经过hash后都会与那个变量的集合进行对比，来判断改行是否与其冲突，并以此来确定依赖关系，没有冲突即可并行

## 复制方式

### 异步复制

当Master不需要关注Slave是否接受到Binlog时，即为传统的主从复制，即异步复制

### 半同步复制

当Master在事务提交之后等待Slave接收到Binlog之后返回ACK时，才会向应用程序返回操作成功，即为半同步复制。

但是有一个问题，此时主库可以看到修改后的数据，若是此时主库宕机，有可能从库还没来得及将relaylog执行，就会发生主从不一致

### 增强半同步

Master写数据到BINLOG后&#xff0c;就开始等待从库的应答ACK，直到至少一个从库写入Relay Log后，并将数据落盘&#xff0c;然后返回给主库消息，通知主库可以执行Commit操作;然后主库开始提交到事务引擎层，应用此时可以看到数据发生了变化。

如果主从延迟过大，会降低主库的写性能，超过一定阈值（ rpl_semi_sync_master_timeout），半同步会切换成异步模式，不再等待从库的确认，而是直接提交事务，从而降低客户端延迟，但是带来了数据丢失的风险

## 主备延迟的原因

备库所在机器的性能要比主库所在的机器性能差

备库的压力大

大事务；一次性地用 delete 语句删除太多数据；大表 DDL

备库延迟时间

备库上执行show slave status命令，返回结果seconds_behind_master，用于表示当前备库延迟了多少秒

## 如何解决主从不一致

### 1、忽略不计

### 2、强制读主库

### 3、选择性读主库

1、写入数据库时，记录在哪个库、哪张表、哪一个主键封装成一个可，写入到缓存，并设置主从的延时时间为超时时间

2、读数据时，先到缓存中查找，如果没有查找到，说明最近没有发生过写请求，直接到从库读取

## 主备切换的策略

### 可靠性优先策略

保证数据不丢失，只有当seconds_behind_master为0时，才会切换

但是会有一段时间不可写入

### 可用性优先策略

导致数据不一致

## 写入高可用

### 双主双写

两台服务器都可以进行写操作，互为主从，任何一台服务器数据变更，都会通过复制应用到另外一方的数据库中

如果双主双都使用自增ID，会产生Id冲突、更新丢失的问题

1、数据库层面解决，不同初始值，相同递增步长

2、数据库上层应用程序控制id生成

通过配置文件中的server_id解决双主模式下的循环复制问题

### 双主单写

建议双主单写的模式（keepalived）

实现

### MMM

Master-Master Replication Manager For MySQL

也是双主模式，但是业务上同一时间只允许一个节点进行写入

包含writer和reader两种角色，分别对应写节点和读节点

每台节点都安装agent，向monitor上报状态信息

当写节点出现故障，会自动移除该节点上的VIP

写操作切换到读节点，并将其角色改为writer

将所有Slave节点会指向新的主库

monitor角色：监控集群内数据库的状态，在出现异常时发布切换命令，一般和数据库分开部
署

agent角色：运行在每个 MySQL 服务器上的代理进程，monitor 命令的执行者，完成监控的探针
工作和具体服务设置，例如设置 VIP（虚拟IP）、指向新同步节点

### MHA

Master High Availability

目前只支持一主多从的架构，要搭建MHA，要求每个复制集群中最少有三台数据库服务器

由MHA Manager和MHA Node两部分组成

MHA Manager管理所有的复制集群，负责检测Master是否宕机、故障转移、检查复制情况

MHA Node运行在每台MySQL服务器上，负责保存和复制master的二进制日志、上报节点状态

# 日志文件类型

## 错误日志

记录了运行过程中遇到的所有严重的错误信息

## 慢查询日志

收集查询时间比较长的SQL语句

## Binlog日志

记录表结构和表数据的变更

用途

主从复制

数据恢复

三种格式

statement

记录SQL 语句的原文；可能会出现主备数据不一致的情况

row

在BINLOG里记录每一行完整记录，包括所有列的值;,会占用太多的空间，同时耗费大量的IO

mixed（前两种格式的混合）

MySQL会判断SQL 语句是否可能引起主备不一致，如果有可能，就用row 格式，否则就用 statement 格式

## undolog

保存修改之前的数据

## redolog

将更新操作记录到redolog中，优化随机写为顺序写

## relaylog

在主从复制环境中产生的日志

为了从机可以从中继日志中获取到主机同步过来的SQL语句，然后执行到从机中

# 慢的原因

查询字段没有建立索引，走全表扫描

建立的索引区分度太低，重复的数据太多，走全表扫描

等行锁

​	通过 sys.innodb_lock_waits 表查到是谁占着这个写锁

undo log回滚段太长，导致快照读的时间过长

等 MDL 锁

​	一个线程正在表 t 上请求或者持有 MDL 写锁，把 select语句堵住了

​	设置 performance_schema=on，然后通过查询 sys.schema_table_lock_waits 这张表，就可以找出造成阻塞的process id，把这个连接用 kill 命令断开

脏页过多，需要刷盘

​	内存不足时，需要将脏页刷新到磁盘；一个查询需要淘汰的脏页太多，会导致的查询的时间过长

​	redo log写满，flush脏页到磁盘这种情况会导致mysql不再接受更新请求，所有的更新请求都会堵住

​	innodb_max_dirty_pages_pct 是脏页比例上限，默认75%

​	刷新一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉
​	innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的

​	innodb_io_capacity ：会告诉 InnoDB 磁盘能力，建议设置成磁盘的 IOPS（可以通过 fio 这个工具来测试）

# 索引

## 优势

提高检索效率，降低IO成本

索引自动排序，降低排序的成本

## 劣势

索引会占据磁盘空间

降低更新表的效率，增删改时也会涉及到索引的维护

## 索引类型

主键索引

在 InnoDB 里，叶子节点存的是整行数据，主键索引也被称为聚簇索引；尽量使用主键查询

是一种特殊的唯一索引，不允许有空值

唯一索引

索引列中的值必须是唯一的

普通索引

在定义索引的列中插入重复值和空值

组合索引

多个字段组合上创建的索引

非主键索引

在 InnoDB 里，叶子节点内容是主键的值，非主键索引也被称为二级索引

## 索引结构

有序数据组

等值查询和范围查询场景中

只适用于静态存储引擎，对于数据不会再修改

哈希表

适用于只有等值查询的场景

B树

查询不稳定，中间节点和叶子节点都会存储数据，无法进行范围查询

B+树

查询稳定，只有叶子节点存储数据，叶子节点之间有前后引用，方便范围查询

## 维护的问题

页的分裂

插入的页已经满了，需要申请新的页，需要挪动部分数据，性能会下降

页的合并

相邻两个页由于删除了数据，空间利用率很低，会将数据页做合并

## 索引设计的考虑原则

主键的有序性

自增主键；每次插入记录，都是追加操作，不会涉及到页的分裂和合并

主键占用的空间

主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小

## 索引的重建

原因

索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引可以让页面的利用率最高，也就是索引更紧凑、更省空间

方法

重建普通索引

alter table T drop index k;
alter table T add index(k);

重建主键索引

 alter table T engine=InnoDB

## 索引失效

对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃使用这个索引

数据类型不匹配（在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字）

做join查询时，两表的字符集不同

索引优化器没有正确统计出扫描的行数
使用analyze table tableName命令，可以用来重新统计索引信息
采用 force index 强行选择一个索引

# mysql优化

## 索引的优化

覆盖索引

包含了所有查询字段的索引

可以减少树的搜索次数，显著提升查询性能；查询的数据都可以在普通索引树上获得，不需要回主索引树查询

前缀索引

建立索引时关注的是区分度，区分度越高，意味着重复的键值越少
定义好长度，既节省空间，又不用增加太多的查询成本

注意:使用前缀索引就用不上覆盖索引对查询性能的优化

更新统计信息（Analyze Table）

Hint优化，方便调优（FORCE INDEX、USE INDEX、IGNORE INDEX、STRAIGHT_JOIN）

检查连接字段数据类型、字符集；避免使用类型转换

## 优化GroupBy

如果对group by语句的结果没有排序要求，要在语句后面加 order by null

尽量让group by过程用上表的索引

如果group by需要统计的数据量不大，尽量使用内存临时表，适当调大tmp_table_size 参数，避免用到磁盘临时表

如果数据量太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果

虚拟列.在 MySQL 5.7 版本支持了 generated column 机制，用来实现列数据的关联更新；alter table t1 add column z int generated always as(id % 100), add index(z);

## 优化OrderBy

1 order by 原理

通过索引直接返回有序数据或者通过 Filesort 进行排序

使用 explain 来查看该排序 SQL 的执行计划，重点关注 Extra 字段

如果该字段里显示是 Using index，则表示是通过有序索引直接返回有序数据

如果该字段里显示是 Using filesort，则表示该 SQL 是通过 Filesort 进行的排序

Filesort 并不一定是在磁盘文件中进行排序的，也有可能在内存中排序，内存排序还是磁盘排序取决于排序的数据大小和 sort_buffer_size 配置的大小，如果 “排序的数据大小” < sort_buffer_size: 内存排序；如果 “排序的数据大小” > sort_buffer_size: 磁盘排序

Filesort 下的排序模式

< sort_key, rowid >双路排序（又叫回表排序模式）：是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行 ID，然后在 sort buffer 中进行排序，排序完后需要再次取回其它需要的字段

< sort_key, additional_fields >单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序，如果内存不足的话，会使用临时文件辅助排序

MySQL 通过比较系统变量 max_length_for_sort_data 的大小和需要查询的字段总、大小来判断使用哪种排序模式

如果查询字段的长度小于max_length_for_sort_data ，那么使用 < sort_key, additional_fields >排序模式

如果查询字段的长度大于max_length_for_sort_data ，那么使用 <sort_key, rowid> 排序模式

Mysql认为如果查询字段长度过大，会占用更多的内存，可能会触发磁盘文件排序，此时就会选择双路排序

rowid 双路排序会要求回表多造成磁盘读，因此不会被优先选择

对经常排序的字段建立索引，避免排序

## 优化Join

Multi-Range Read 

setoptimizer_switch="mrr_cost_based=off"

回表查询往往涉及到随机访问，性能相对较差；Multi-Range Read 的做法就是先将主键放在内存中，然后进行排序，排序之后依次到主键索引中查找记录；尽量使用顺序读盘

Batched Key Access

set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';

## 服务器优化

### 硬件优化

配置较大的内存

配置高速磁盘，比如SSD

配置多核处理器

合理分配磁盘IO，将磁盘IO分配到多个设备

文件系统优化

文件系统使用缓存来提升读性能，使用缓冲来提升写性能

默认情况下，Linux会记录文件最近一次被读取的时间信息，我们可以在挂载文件系统的时候使用noatime来提升性能

Direct I/O允许应用程序在使用文件系统的同时绕过文件系统的缓存，避免缓存那些只被读取一次的数据

推荐在Linux下使用XFS文件系统，它是一种高性能的日志文件系统，特别擅长处理大文件

### 参数优化

内存分配器

建议把内存分配器换成tcmalloc，tcmalloc适合分配256KB以下的内存且多线程环境的场景

IO调度算法

DeadLine 调度算法，分别为读、写请求创建了不同的 I/O 队列，并确保达到最终期限的请求被优先处理

## 优化思路

业务层面

1、避免前台面对用户的业务和后台面对运营人员的业务同时操作同一个数据库实例

2、避免创建无所谓的索引

数据量层面

如果单表数据量过大，水平分表；

如果某些字段长度过大，不经常查询，修改，垂直分表

数据调优层面

设置合理的内存池大小

开启慢查询功能

 使用explain 令去查看有问题的SQL的执行计划

Id：

查询语句中每出现一个SELECT关键字，就会为它分配一个唯一的id值

对于连接查询来说，一个SELECT关键字后面的FROM 子句中可以跟随多个表。在连接查询的执行计划中，每个表都会对应一条记录，但是这些记录的id值都是相同的

对于包含子查询语句来说，就可能涉及多个SELECT关键字。所以在包含子查询的执行计划中，每个select关键字都会对应一个唯一的id

查询优化器可能对涉及子查询的查询语句进行重写，从而转换为连接查询(当然这里指的是半连接)。如果想知道查询优化器对某个包含子查询的语句是否进行了重写，直接查看执行计划就好

select type：

SIMPLE:查询语句中不包含UNION或者子查询的查询都算作SIMPLE类型

PRIMARY:对于包含UNION、UNIONALL或者子查询的大查询

使用show profile查看SQL的性能瓶颈，执行过程中资源占用信息

type:

执行计划的一条记录代表着 MySQL 对某个表执行查询时的访问方法，其中的type列就表明了这个访问方法是啥

const:使用唯一索引或者主键

eq_ref:执行连接查询时，如果被驱动表是通过主键或者不允许存储NULL值的唯一二级索引列等值匹配的方式进行访问的(如果该主键或者不允许存储NULL 值的唯一二级索引是联合索引，则所有的索引列都必须进行等值比较)，则对该被驱动表的访问方法就是eq ref

Ref：辅助索引的等值查找

range:索引范围扫描

Index_merge:表示查询使用了两个以上的索引，最后取交集或者并集

index:索引全表扫描，把索引从头到尾扫一遍，常见于使用索引列就可以处理不需要读取数据文件的查询、可以使用索引排序或者分组的查询

all:这个就是全表扫描数据文件，然后再在server层进行过滤返回符合要求的记录

Extra

Using index:使用覆盖索引执行查询时，Extra 列将会提示该额外信息

Using index condition：如果在查询语句的执行过程中使用索引条件下推特性，在 Extra 列中将会显示Using indexcondition

索引条件下推特性只是为了在扫描某个扫描区间的二级索引记录时，尽可能减少回表操作的次数，从而减少I/O操作

Usingwhere:当某个搜索条件需要在server层进行判断时，在Extra列中会提示Usingwhere

Using temporary:在许多查询的执行过程中，MySQL 可能会借助临时表来完成一些功能，比如去重、排序之类的

Usingfilesort：如果某个查询需要使用文件排序的方式执行查询，就会在执行计划的Extra列中显示Usingfilesort提示

rows：

在查询优化器决定使用全表扫描的方式对某个表执行查询时，执行计划的rows 列就代表该表的估计行数

如果使用索引来执行查询，执行计划的rows列就代表预计扫描的索引记录行数

## 优化细节

隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。根据业务需求，设置合理的隔离级别

主从复制模式下，主库避免建立无谓的索引。对于OLTP和OLAP使用不同的从库，根据业务的不同建立索引

尽量控制事务的大小，将涉及加锁的sql尽量放在事务最后执行

设置合理的冗余字段

将字段很多的表分解成多个表

对于需要经常联合查询的表，可以建立中间表，以提高查询效率

使用OPTIMIZE TABLE来重新利用未使用的空间，消除删除和更新造成的文件碎片

## 插入数据优化

禁用唯一性检查

禁用外键检查

禁止自动提交

## 查询长事务

select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>=60;

业务端，避免不必要的读事务

## DML锁

当对一个表做增删改查操作的时候，加 MDL读锁；当要对表做结构变更操作的时候，加 MDL 写锁

只要对表申请了DML写锁，后续所有对表的增删改查操作都会阻塞

给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，要特别小心，以免对线上服务造成影响

# 应用层优化

使用高效连接池

减少对MySQL的访问次数,合并读写

增加Redis缓存层，避免每次读请求都到达数据库

单表过大及时归档

代码层读写分离

表的索引提前规划

对于OLTP业务和OLAP业务使用不同的从库，根据业务的不同建立不同索引

# 深入理解数据库

## 优化分页查询

根据自增且连续主键排序的分页查询

优化前：select * from t1 limit 99000,2;

优化后：select * from t1 where id >99000 limit 2;  适用主键自增连续无删除

查询根据非主键字段排序的分页查询

扫描整个索引并查找到没索引的行的成本比扫描全表的成本更高，所以优化器放弃使用索引

select * from t1 order by a limit 99000,2;

select * from t1 f inner join (select id from t1 order by a limit 99000,2)g on f.id = g.id;

让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录

## 优化Join语句

1 关联查询的算法

1.1 Nested-Loop Join 算法

一个简单的 Nested-Loop Join(NLJ) 算法一次一行循环地从第一张表（称为驱动表）中读取行，在这行数据中取到关联字段，根据关联字段在另一张表（被驱动表）里取出满足条件的行，然后取出两张表的结果合集

explain 分析 join 语句时，在第一行的就是驱动表。优化器会优先选择小表做驱动表

1.2 Block Nested-Loop Join 算法

Block Nested-Loop Join(BNL) 算法的思想是：把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比，如果满足 join 条件，则返回结果给客户端

1.3 Batched Key Access 算法

NLJ 的关键思想是：被驱动表的关联字段有索引

BNL 的关键思想是：把驱动表的数据批量提交一部分放到 join_buffer 中

原理

1. 将驱动表中相关列放入 join_buffer 中

2. 批量将关联字段的值发送到 Multi-Range Read(MRR) 接口

3. MRR 通过接收到的值，根据其对应的主键 ID 进行排序，然后再进行数据的读取和操作

而 Multi-Range Read 优化的设计思路是：查询辅助索引时，对查询结果先按照主键进行排序，并按照主键排序后的顺序，进行顺序查找，从而减少随机访问磁盘的次数。

4. 返回结果给客户端

2 优化关联查询

2.1 关联字段添加索引

2.2 小表做驱动表

2.3 临时表

##  重新认识 count()

当 count() 统计某一列时，比如 count(a)，a 表示列名，是不统计 null 的

count(*) 无论是否包含空值，都会统计

MyISAM 引擎会把表的总行数存在磁盘上

InnoDB 并不会保留表中的行数

## 为什么添加索引能提高查询速度?

跟索引相关的一些算法

二分查找法

二叉查找树

平衡二叉树

​	满足二叉查找树的定义，另外必须满足任何节点的两个子树的高度差最大为 1

B 树

B 树可以理解为一个节点可以拥有多于 2 个子节点的多叉查找树

B 树中同一键值不会出现多次，要么在叶子节点，要么在内节点上

B 树也是有缺点的，因为每个节点都包含 key 值和 data 值，因此如果 data 比较大时，每一页存储的 key 会比较少；当数据比较多时，同样会有：“要经历多层节点才能查询在叶子节点的数据”的问题

B+ 树

所有叶子节点中包含了全部关键字的信息

各叶子节点用指针进行连接

非叶子节点上只存储 key 的信息，这样相对 B 树，可以增加每一页中存储 key 的数量

2 B+ 树索引

在数据库中，B+ 树的高度一般都在 2 ~ 4 层，所以查找某一行数据最多只需要 2 到 4 次 IO。而没索引的情况，需要逐行扫描，明显效率低很多

2.1 聚集索引

InnoDB 的数据是按照主键顺序存放的，而聚集索引就是按照每张表的主键构造一颗 B+ 树，它的叶子节点存放的是整行数据

聚集索引对于主键的排序查找和范围查找速度非常快

2.2 辅助索引

辅助索引的叶子节点并不会放整行数据，而存放的是键值和主键 ID

当通过辅助索引来寻找数据时，InnoDB 存储引擎会遍历辅助索引树查找到对应记录的主键，然后通过主键索引来找到对应的行数据

## 优化order by

1 order by 原理

通过索引直接返回有序数据或者通过 Filesort 进行排序

怎么确定SQL 所使用的排序方式

使用 explain 来查看该排序 SQL 的执行计划，重点关注 Extra 字段

如果该字段里显示是 Using index，则表示是通过有序索引直接返回有序数据

如果该字段里显示是 Using filesort，则表示该 SQL 是通过 Filesort 进行的排序

Filesort 并不一定是在磁盘文件中进行排序的，也有可能在内存中排序，内存排序还是磁盘排序取决于排序的数据大小和 sort_buffer_size 配置的大小，如果 “排序的数据大小” < sort_buffer_size: 内存排序；如果 “排序的数据大小” > sort_buffer_size: 磁盘排序

Filesort 下的排序模式

< sort_key, rowid >双路排序（又叫回表排序模式）：是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行 ID，然后在 sort buffer 中进行排序，排序完后需要再次取回其它需要的字段

< sort_key, additional_fields >单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序

MySQL 通过比较系统变量 max_length_for_sort_data 的大小和需要查询的字段总大小来判断使用哪种排序模式

如果 max_length_for_sort_data 比查询字段的总长度大，那么使用 < sort_key, additional_fields >排序模式

如果 max_length_for_sort_data 比查询字段的总长度小，那么使用 <sort_key, rowid> 排序模式

2、order by 优化

排序字段添加索引

多个字段排序优化

多个字段排序的情况，如果要通过添加索引优化，得注意排序字段的顺序与联合索引中列的顺序要一致。

先等值查询再排序的优化

对于先等值查询再排序的语句，可以通过在条件字段和排序字段添加联合索引来优化此类排序语句

## 分析SQL执行效率

### 通过慢查询日志

Explain 

可以获取 MySQL 中 SQL 语句的执行计划，比如语句是否使用了关联查询、是否使用了索引、扫描行数等

show profiles

能够更清楚地了解 SQL 执行过程的资源使用情况，能让我们知道到底慢在哪个环节

show profile for query queryID;

show profile all for query queryID; 查看更详细的信息

 trace 

使用 trace 查看优化器如何选择执行计划

### 通过 show processlist

显示哪些线程正在运行。关注state，表示运行状态，info，表示执行的SQL语句

如果看到 State 的值一直处于“Sending to client”，就表示服务器端的网络栈写满了。

MySQL 是“边读边发的”，获取一行，写到 net_buffer 中，默认是 16k。重复获取行，直到 net_buffer 写满，调用网络接口发出去。如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送

如果客户端接收得慢，会导致 MySQL 服务端由于结果发不出去，处于“Sending to client”。此时需要优化客户端程序

如果State的值一直处于“Sending data”，并不一定是指“正在发送数据”，而可能是处于执行器过程中任意阶段

### 关注内存命中率

Innodb中Buffer Pool 对查询的加速效果，依赖一个重要指标，就是内存命中率

执行show engine innodb status ，显示内存命中率。

如果命中率过低，可以思考是分配内存太小，还是某些SQL语句扰乱了热点数据页的换出

InnoDB中Buffer Pool 的大小是由参数 innodb_buffer_pool_size 确定的，一般建议设置成可用物理内存的 60%~80%

## 避免索引失效

应该避免隐式转换

like查询不能以%开头

范围查询时，包含的数据比例不能太大

不建议对条件字段做运算及函数操作

## 如何优化数据导入

1 、一次插入多行的值

2 、关闭自动提交

3 、参数调整

innodb_flush_log_at_trx_commit：控制重做日志刷新到磁盘的策略，有0 、1和2三种值

0：master线程每秒把redo log buffer写到操作系统缓存，再刷到磁盘

1：每次提交事务都将redo log buffer写到操作系统缓存，再刷到磁盘

2：每次事务提交都将redo log buffer写到操作系统缓存，由操作系统来管理刷盘

sync_binlog：控制binlog的刷盘时机，可配置0、1或者大于1的数字

0：二进制日志从不同步到磁盘，依赖OS刷盘机制

1：二进制日志每次提交都会刷盘

n(n>1) : 每n次提交落盘一次

## 哪些情况需要添加索引

1 数据检索

无索引时type 字段为 ALL，有索引时type 字段为 ref

2 聚合函数

索引能提升 max() 函数的效率，同理也能提升 min()函数的效率

3 排序

如果对单个字段排序，则可以在这个排序字段上添加索引来优化排序语句

如果是多个字段排序，可以在多个排序字段上添加联合索引来优化排序语句；

如果是先等值查询再排序，可以通过在条件字段和排序字段添加联合索引来优化排序语句

4 避免回表

通过添加覆盖索引让 SQL 不需要回表，从而减少树的搜索次数，让查询更快地返回结果

如果条件字段和需要查询的字段有联合索引的话，其实只查询一次辅助索引可以，免去了回表查询

5 关联查询

通过在关联字段添加索引

普通索引和唯一索引有哪些区别？

有普通索引的字段可以写入重复的值，而有唯一索引的字段不可以写入重复的值

1 Insert Buffer

对于非聚集索引的插入时，先判断插入的非聚集索引页是否在缓冲池中。如果在，则直接插入；如果不在，则先放入 Insert Buffer 中，然后再以一定频率和情况进行 Insert Buffer 和辅助索引页子节点的 merge 操作

增加 Insert Buffer 有两个好处：减少磁盘的离散读取，将多次插入合并为一次操作

使用 Insert Buffer 得满足两个条件：索引是辅助索引，索引不是唯一

2 Change Buffer

可以对 insert、delete、update 都进行缓存

Change Buffer 也得满足这两个条件：索引是辅助索引，索引不是唯一

唯一索引必须要将数据页读入内存才能判断是否违反唯一性约束。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 Change Buffer 了

3 普通索引和唯一索引的区别

对于唯一索引来说，查找到第一个记录返回结果就结束了

对于普通索引，查找到满足条件的第一个记录，还需要查找下一个记录，直到不满足条件

数据修改时，普通索引可以用 Change Buffer，而唯一索引不行。

4 普通索引和唯一索引如何选择

如果业务要求某个字段唯一，但是代码不能完全保证写入唯一值，则添加唯一索引，让这个字段唯一

如果代码确定某个字段不会有重复的数据写入，则可以选择添加普通索引

## 联合索引

联合索引：是指对表上的多个列进行索引。适合 where 条件中的多列组合，在某些场景可以避免回表

where 条件中，经常同时出现的列放在联合索引中

创建索引时，把离散性最大的列放在联合索引的最左边

explain 中的 key_len 列用于表示这次查询中，所选择的索引长度有多少字节，常用于判断联合索引有多少列被选择了

比如int类型，key_len = 4+1，int 为 4 bytes，允许为 NULL，加 1 byte

## 覆盖索引

从辅助索引中就可以查询到结果，不需要回表查询聚集索引中的记录

使用覆盖索引的优势：因为不需要扫描聚集索引，因此可以减少 SQL 执行过程的 IO 次数

## 选错索引的原因

1、show index 的使用

查看某张表的索引详情

2、Cardinality 取值

Cardinality 表示该索引不重复记录数量的预估值。如果该值比较小，那就应该考虑是否还有必要创建这个索引

3、统计信息不准确导致选错索引

一般情况下，优化器会考虑扫描行数、是否使用临时表、是否排序等因素，然后选择一个最优方案去执行 SQL 语句

MySQL 中扫描行数并不会每次执行语句都去计算一次，因为每次都去计算，数据库压力太大了。实际情况是通过采样统计信息来预估扫描行数。这个统计信息就可以看成 show index 中的 Cardinality

analyze命令可以用来重新统计信息

4、单次选取的数据量过大导致选错索引

# OceanBase

## RootServer

管理集群中的所有服务器，数据分布以及副本管理

一主一备，主备之间数据强同步

## UpdateServer

存储增量更新数据

一主 一备，主备之间可以配置不同的同步模式。可以和RootServer共用物理服务器

写数据时先写到memstore，当memstore占用的空间达到一定阈值，会当前的memstore冻结，新的memstore被启用，此后新的写入写到新的memstore，冻结的memstore的数据会被转存到磁盘，转存结束后，冻结的memstore占用的空间会被释放。

手动或者定时的合并，将增量的修改数据和chunk server中的基线数据进行合并。合并会消耗一定的cpu、磁盘和网络等资源，导致系统性能的下降。可以降低合并线程的优先级，在系统负载过大的情况下可以放慢合并的速度

特殊场景下会出现修改量太大超出UpdateServer的内存，可以通过分库来解决，分库后每个库的修改量减少，每个库对应一个Oceanbase集群

为了实现范围查询，UpdateServer采用B树来保存修改增量。基于Copy-on-write实现数据的修改

通过copy-on-write，UpdateServer实现了读写事务互不影响。读写分离，到达UpdateServer的读写事务请求，分成读事务和写事务两个相互独立的队列

通过group commit机制，主备UpdateServer都减少了网络IO次数和磁盘IO次数，增加了写事务响应时间，但是提升了系统的TPS

## ChunkServer

存储基线数据，一般往往存储三份

## MergeServer

接收并解析用户的SQL请求，转发给相应的ChunkServer或者UpdateServer

# Percolator去中心化分布式事务

## 前提

使用此事务模型的前提是事务的参与者，即数据库，要支持多版本并发控制（MVCC）

## 流程

准备阶段

1、Percolator客户端，从中心化ID服务器获取一个id，记为ts，之后使用这个ts作为标记这个事务的唯一id 

2、从每个事务要操作的记录中，选取一个记录作为主锁，主锁的选择是随机的

3、向每个事务参与者（即数据库）发送写请求，并且发送ts和主锁信息

4、数据库接到请求后，写日志、在lock字段添加锁信息、写入ts

提交阶段

Percolator客户端只需要和拥有主锁的数据库通讯，发送Commit 指令，且不用附带其他信息

增加一条新的记录标有事务提交的时间，表明此事务提交成功，清除写入的主锁信息

后台线程异步向其他数据库发送提交请求，清除写有的主锁信息

# 普通、唯一索引的选择

## 查询过程

对于普通索引来说，查找到满足条件的第一个记录后，需要查找下一个记录，直到碰到第一个不满足条件的记录

对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索

InnoDB 按数据页为单位来读写的。当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存，每个数据页的大小默认是 16KB。普通索引查询时，下一条记录如果在同一页中，两者的性能差距微乎其微

## 更新过程

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，InooDB 会将这些更新操作缓存在 changebuffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。

对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束，必须要将数据页读入内存才能判断，唯一索引的更新就不能使用 change buffer。

对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer 的使用效果最好

这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，建议你尽量选择普通索引。
如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。

而在其他情况下，change buffer 都能提升更新性能。

# 字符串字段加索引

使用前缀索引，定义好长度，就可以做到既节省空间，又不用回主键索引上额外增加太多的查询成本

首先，可以使用count(distinct 列名)这个语句，算出这个列上有多少个不同的值：然后，依次选取不同长度的前缀来看这个值，count(distinct left(列名，4-7))

**前缀索引用不上覆盖索引对查询性能的优化**

对于前缀的区分度不够好（前缀长度过长）的情况时，可以使用倒序存储，也可以使用使用hash（crc32）字段，用hash值填充，并且建立索引

# MySQL性能优化最佳实践

1、当只要一行数据时使用 LIMIT 1

当我们只关心数据表有多少记录行而不需要知道具体的字段值时，“SELECT 1 FROM TABLE”是一个很不错的SQL语句写法，

SELECT 1 FROM TABLE可以减少系统开销&#xff0c;提高运行效率。因为此时数据库就不会去检索数据表里每条具体的记录和每条记录里每个具体的字段值并将它们放到内存

2、在 Join 表的时候使用相同类型的列，并为其建立索引

3、避免 SELECT *

4、使用 ENUM 而不是 VARCHAR。比如“性别”，“国家”，“民族”，“状态”，这些字段的取值是有限而且固定的

5、从 procedure analyse()取得建议

procedure analyse()会让 MySQL 帮你去分析你的字段和其实际的数据，并会给你一些有用的建议

6、尽可能的使用 NOT NULL

7、拆分大的 DELETE 或 INSERT 语句

8、垂直分割

垂直分割”是一种把数据库中的表按列变成几张表的方法，这样可以降低表的复杂度和字段的数目，从而达到优化的目的

9、固定长度的表会更快

10、把 IP 地址存成 UNSIGNED INT

11、避免使用Delete，用Update代替做软删除

12、使用group by时，如无排序的需求，建议加order by null

13、尽量不要在数据库里做运算

14、不要使用大偏移量的limit分页

15、批量insert语句最好采用bulk insert的方法，如insert into table(xxx) values (xxx),(xxx),每个批次以执行时间小于100ms为原则

16、update/delete尽量根据主键进行操作

17、用好覆盖索引

​		在二级索引上直接返回结果，不用再去对应的主键索引上取数据

# 如何进行表结构设计

1、确定需求和目标

​	熟悉业务，了解应用程序需要执行哪些操作

​	以及每个表将用于存储哪些数据

​	了解使用数据库的相关方，比如用户、运营人员、OLAP，为其分配不同的数据库

2、选择适当的数据类型

​	根据业务场景需求，选择合适的类型，最短的长度

​	有助于确保数据的完整性和准确性，并可优化性能

​	所有字段必须为 NOT NULL，空值则指定 default 值，空值难以优化，查询效率低

​	短数据使用 TINYINT 或 SMALLINT

​	浮点数存在误差问题,对货币等对精度敏感的数据，应该使用decimal

​	mysql5.7版本 ,通过length获取字段的长度，返回的是占用字节的长度，而不是字符的长度，

​	单个数字和字母分别占用1个字节，汉字占用3个字节

​	char(10) 中的10代表10个字符,固定占位10，不足时，会填充；适用于存储固定长度的字符串，如身份证号、电话号码等

​	varchar(10),用多少占多少，适用于存储长度可变的字符串，如用户名、邮件地址

​	IP 处理：数据库内置了两个 IP 相关的函数 INET_ATON()、INET_NTOA()，可以实现 IP 地址和整数的项目转换，用 INT UNSIGNED存储 IP

TIMESTAMP 处理：使用内置的函数(FROM_UNIXTIME()，UNIX_TIMESTAMP())，可以将日期转化为数字，用 INT UNSIGNED 存储日期和时间

​	不建议使用 TEXT/BLOB

3、设计主键

​	为每个表设计一个主键

​	主键是唯一标识表中每一行的字段。通常使用自增的整数作为主键

4、避免外键

5、优化表结构

​	经常查询的字段建立索引，尽可能使用联合索引，避免同一个字段重复建立索引

​	适当冗余，避免多表查询

​	对于不经常使用的字段或者大字段，单独存储

SHOWENGINEINNODB STATUS语句来查看InnoDB存储引擎运行过程中的一些状态信息

查看优化器生成执行计划的整个过程

如果想打开 optimizer trace 功能，必须首先把enabled 的值改为on

使用SHOWENINGEINNODBSTATUS获取锁信息

### MySQL监控工具innotop

# 资料

[数据库设计1](https://15721.courses.cs.cmu.edu/spring2020/schedule.html)

[数据库设计2](https://15445.courses.cs.cmu.edu/fall2020/schedule.html)

[MemSQL](https://docs.singlestore.com/db/v8.1/introduction/how-singlestoredb-works/)

[High-Performance Concurrency Control Mechanisms for Main-Memory Databases](https://arxiv.org/pdf/1201.0228v1.pdf)

[PostgreSQL](http://www.interdb.jp/pg/index.html)

[数据库内核月报](http://mysql.taobao.org/monthly/)

[sqlite](https://www.sqlite.org/index.html)

[Principles of Data-Intensive Systems](https://web.stanford.edu/class/cs245/slides/)

[How does a relational database work](https://coding-geek.com/how-databases-work/)

[数据库论文阅读目录](https://github.com/EthanDBer/DatabasePapersReadingLists)

[Awesome Database Learning](https://gitee.com/mirrors_pingcap/awesome-database-learning)

[PostgreSQL学习资料](https://github.com/digoal/blog)

[h2database](http://h2database.com/html/quickstart.html)

# 如何保证数据不丢失crash-safe？

将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"

写入redolog，处于prepare阶段 -> 写binlog -> 提交事务，redolog处于commit状态

两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案

如果提交事务时宕机，重启时，redolog 和binlog都是完整的，可以恢复过来

如果写binlog失败，重启时，发现binlog是不完整的，回滚

一个正常结束的事务，prepare和commit是成对存在的，重启时发现成对存在，直接从redolog中恢复，如果不是，则判断binlog是否完整，如果完整，恢复，否则，回滚
