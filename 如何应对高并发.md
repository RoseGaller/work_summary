高并发的本质，**就是海量的读和写**

# 如何应对高并发

## 架构原则：“4 要 1 不要”

1、数据要尽量少	

首先是指用户请求的数据能少就少。

其次，还要求系统依赖的数据能少就少，包括系统完成某些业务逻辑需要读取和保存的数据

2、请求数要尽量少

减少请求数最常用的一个实践就是合并 CSS 和 JavaScript 文件

合并请求

门面模式，为客户端访问的多个接口提供统一的接口

客户端限制单位时间内请求次数

按钮置灰，不可点击

浏览器、App端缓存

Nginx内容缓存

​		Nginx 会将多个并发请求合并为1条回源请求，并锁住所有的客户端请求，直到回源请求返回后，才会更新缓存，同时向所有客户端返回响应

3、路径要尽量短

缩短请求路径不仅可以增加可用性，同样可以有效提升性能（减少中间节点可以减少数据的序列化与反序列化），并减少延时

多个相互强依赖的应用合并部署在一起，把远程过程调用（RPC）变成 JVM 内部之间的方法调用

多机房部署，避免跨机房服务调用

将数据放在离用户近的地方

​		DNS用户就近接入

​		CDN

将频繁访问数据，放入缓存

4、依赖要尽量少

所谓依赖，指的是要完成一次用户请求必须依赖的系统或者服务，这里的依赖指的是强依赖。

要减少依赖，我们可以给系统进行分级，比如 0 级系统、1 级系统、2 级系统、3 级系统，0 级系统如果是最重要的系统，那么 0 级系统强依赖的系统也同样是最重要的系统

5、不要有单点

应用无状态化，可以任意扩容。

存储服务本身很难无状态化，一般要通过冗余多个备份的方式来解决单点问题

架构是一种平衡的艺术，而最好的架构一旦脱离了它所适应的场景，一切都将是空谈。

## 流量削峰

### 排队

最容易想到的解决方案就是用消息队列来缓冲瞬时流量，把同步的直接调用转换成异步的间接推送，中间通过一个队列在一端承接瞬时的流量洪峰，在另一端平滑地将消息推送出去。

排队，就是把“一步的操作”变成“两步的操作”，其中增加的一步操作用来起到缓冲的作用

### 答题

延缓请求，起到对请求流量进行削峰的作用，从而让系统能够更好地支持瞬时的流量高峰

### 分层过滤

层过滤其实就是采用“漏斗”的方式，对请求进行分层过滤，从而过滤掉一些无效的请求

大部分数据和流量在用户浏览器或者 CDN 上获取，这一层可以拦截大部分数据的读取

nginx代也可以缓存数据，拦截大部分数据的读取

应用服务层，本地缓存、远端缓存，对系统做好保护和限流

数据库层完成数据的强一致性校验

## 处理热点数据

1、优化

优化热点数据最有效的办法就是缓存热点数据，本地缓存、远端缓存（redis）、nginx缓存、多副本存放

2、限制

限制更多的是一种保护机制

对热点数据的key计算Hash，然后根据 Hash 做分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点数据占用太多的服务器资源，而使其他请求始终得不到处理

3、隔离

数据隔离

​	启用单独的 Cache 集群或者MySQL 数据库来放热点数据

系统隔离

​	系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外 99% 分开，让请求落到不同集群中

## 如何设计兜底方案

### 高可用建设

#### 架构阶段

避免系统出现单点

分布隔离

异步化

异地容灾

#### 编码阶段

错误捕获

异步线程

超时处理

限流保护

#### 测试阶段

自动化对比测试

#### 发布阶段

多版本发布

分批发布

#### 运行阶段

实时监控报警

过载保护

自动降级

#### 故障发生

快速恢复

故障定位

### 降级

所谓“降级”，就是当系统的容量达到一定程度时，限制或者关闭系统的某些非核心功能，从而把有限的资源保留给更核心的业务

执行降级无疑是在系统性能和用户体验之间选择了前者

### 限流

当系统容量达到瓶颈时，通过限制一部分流量来保护系统，并做到既可以人工执行开关，也支持自动化保护的措施

限流既可以是在客户端限流，也可以是在服务端限流

限流的实现方式既要支持 URL 以及方法级别的限流，也要支持基于QPS 和线程的限流

### 拒绝服务

当系统负载达到一定阈值时，例如 CPU 使用率达到 90% 或者系统 load 值达到 2*CPU 核数时，系统直接拒绝所有请求

在最前端的 Nginx 上设置过载保护，当机器负载达到某个值时直接拒绝HTTP 请求并返回 503 错误码，在 Java 层同样也可以设计过载保护

## 提高性能

### 性能指标

服务端性能，一般用 QPS（Query Per Second，每秒请求数）来衡量，另一个就是响应时间（Response Time，RT），它可以理解为服务器处理响应的耗时

正常情况下响应时间（RT）越短，一秒钟处理的请求数（QPS）自然也就会越多

总 QPS =（1000ms / 响应时间）× 线程数量

### 影响因素

性能就和两个因素相关了，一个是一次响应的服务端耗时，一个是处理请求的线程数

要提升性能我们就要减少 CPU 的执行时间，另外就是要设置一个合理的并发线程数，通过这两方面来显著提升服务器的性能

### 如何发现瓶颈

JProfiler 和 Yourkit 这两个工具，它们可以列出整个请求中每个函数的 CPU 执行时间，可以发现哪个函数消耗的 CPU 时间最多，以便针对性地做优化

怎样简单地判断 CPU 是不是瓶颈呢？一个办法就是看当 QPS 达到极限时，服务器的CPU 使用率是不是超过了 95%，如果没有超过，那么表示 CPU 还有提升的空间，要么是有锁限制，要么是有过多的本地 I/O 等待发生。

### 如何优化系统

1、 减少序列化

序列化大部分是在 RPC 中发生的，因此避免或者减少 RPC 就可以减少序列化

可以将多个关联性比较强的应用进行“合并部署”，而减少不同应用之间的 RPC 也可以减少序列化的消耗。
所谓“合并部署”，就是把两个原本在不同机器上的不同应用合并部署到一台机器上，当然不仅仅是部署在一台机器上，还要在同一个 Tomcat 容器中，且不能走本机的 Socket，这样才能避免序列化的产生

2、Java 极致优化

对大流量的 Web 系统做静态化改造，让大部分请求和数据直接在 Nginx 服务器或者 Web 代理服务器（如 Varnish、Squid 等）上直接返回，而 Java 层只需处理少量数据的动态请求

直接使用 Servlet 处理请求，避免使用传统的 MVC 框架

直接输出流数据。使用 resp.getOutputStream() 而不是 resp.getWriter() 函数，可以省掉一些不变字符数据的编码，从而提升性能；数据输出时推荐使用 JSON 而不是模板引擎（一般都是解释执行）来输出页面

3、并发读优化

采用应用层的 LocalCache，即在系统的单机上缓存相关的数据

对于动态数据，会采用“被动失效”的方式缓存一定时间，失效后再去缓存拉取最新的数据

## 海量读请求

### 分散的读请求

当百万的 QPS 属于不同用户时，因缓存是集群化的，所有到达业务后台的请求会根据一定路由规则（如 Hash），分散到请求缓存集群中的某一个节点

假设一个节点最大能够支撑 10W QPS，我们只需要在集群中部署 10 台节点即可支持百万流量

#### 1、架构尽量不要分层

​	读服务的业务逻辑都比较简单，性能主要消耗在网络传输上。读服务要尽可能和数据靠近，减少网络传输

​	比如数据前置，浏览器缓存、CDN缓存

#### 2、代码尽可能简单

​	如果一定要引入，必须经过严格的压测

​	精细化地按需打印日志

​	对于读取的内容要在存储处按需取，如果存储为 MySQL，则不要使用 select *，需要手动指定你要查询的字段。如果存储为 Redis，则使用 Redis 的 hash 结构存储数据

#### 3、缓存的懒加载模式

​	在初始的时候，所有数据都存储在数据库中。

​	当读服务接受请求时，会先去缓存中查询数据，如果没有查询到数据，就会降级到数据库中查询，并将查询结果保存在 Redis 中。

​	保存在 Redis 中的数据会设置一个过期时间，防止数据库的数据变更了，请求还一直读取缓存中的脏数据

存在的问题：

1、存在缓存穿透的风险

​		针对数据库中没有的数据，可以在缓存中设置一个占位符。在第二次请求处理时，读取缓存中的占位符即可识别数据库中没有此数据，然后直接返回给业务前台系统即可。
​	使用占位符虽然解决了穿透的问题，但也带来了另外一个问题。如果恶意请求不断变换请求的条件，同时这些条件对应的数据在数据库中均不存在，那么缓存中存储的表示无数据的占位符也会把整个缓存撑爆，进而导致有效数据被缓存清理策略清除或者整个读服务宕机。
​	对于此种恶意请求，就需要在业务上着手处理。对于请求的参数可以内置一些 token 或者一些验证数据，在读服务中前置进行校验并拦截，而不是透传到缓存或数据库中

2、缓存集中过期导致雪崩
	将设置的过期时间随机化，避免同一时间过期

3、懒加载无法感知实时变更

​	在缓存中设置过期时间，虽然可以让用户感知到数据的变更。但感知并不是实时的，会有一定延迟

​	修改数据库，删除缓存

​	订阅binlog，重写缓存

4、懒加载无法摆脱毛刺的困扰

​	使用懒加载的缓存过期方案，还有一个无法避免的问题，就是性能毛刺。当缓存过期时，读服务的请求都会穿透到数据库中，对于穿透请求的性能和使用缓存的性能差距非常大，时常是毫秒和秒级别的差异

#### 4、全量缓存的基本架构

​	全量缓存是指将数据库中的所有数据都存储在缓存中，同时在缓存中不设置过期时间的一种实现方式

​	所有数据都存储在缓存里，读服务在查询时不会再降级到数据库里，所有的请求都完全依赖缓存。此时，因降级到数据库导致的毛刺问题就解决了

​	全量缓存对数据更新要求更加严格，要求所有数据库已有数据和实时更新的数据必须完全同步至缓存，不能有遗漏。一种有效的方案是采用订阅数据库的 Binlog 实现数据同步

​	将 Binlog 的中间件（Canal）挂载至目标数据库上，就可以实时获取该数据库的所有变更数据。对这些变更数据解析后，便可直接写入缓存里

**任何方案在带来某一方面的提升时，必然是在其他方面做出了一些取舍，架构其实是一门平衡的艺术**

**全量缓存存在的问题**			

第一个问题：提升了系统的整体复杂度

第二个问题：缓存的容量会成倍上升，相应的资源成本也大幅上升	
		首先是存储在缓存中的数据需要经过筛选，有业务含义且会被查询的才进行存储。比如数据库常见的修改时间、创建时间、修改人、数据有效位等一些记录性字段可以不存储在缓存中

​	其次是存储在缓存中的数据可以进行压缩。采用 Gzip、Snappy 等常见的压缩算法进行处理，但压缩算法通常较消耗 CPU。

​	节约缓存的技巧	
​		技巧一：将数据按 JSON 格式序列化时，可以在字段上添加替代标识，表示在序列化后此字段的名称用替代标识进行表示
​		技巧二：如果你使用的缓存是 Redis 且使用了其 Hash 结构存储数据。其 Hash 结构的 Field 字段，也可以使用和上述 JSON 标识一样的模式，使用一个较短的标识进行代替

多机房实时热备

为了提升性能和可用性，可以将数据同步模块写入的缓存由一个集群变成两个集群.两套缓存集群可以分别部署到不同城市的机房或者同城市的不同分区。另外，读服务也相应地部署到不同城市或不同分区

异步并行化

对于需要多次和存储交互的场景，可以采用异步并行化的方式——接收到一次读请求后，在读服务内部，将串行与存储交互的模式改为异步并行与存储进行交互

Binlog 如何高效消费

1、全串行的方式进行消费

​	在消费时，对此 Binlog 文件使用 ACK 机制进行串行消费，每消费一条确认一条，然后再消费一条，以此重复

2、采用并行的方式提升吞吐量及扩展性

​	借用了 MQ 进行拆分。在 Binlog 处仍然进行串行消费，但只是 ACK 数据。ACK 后数据直接发送到 MQ 的某一个 Topic 里即可。因为只做 ACK 并转发至 MQ，不涉及业务逻辑，所以性能消耗非常小

​	为避免并行性带来的数据乱序的问题，将对同一条数据的修改记录都发送到同一个分区中，即根据数据的主键计算分区。

采用 Redis 的 Hash 结构进行局部更新

最后的兜底，直接写入

​	一些关键场景在写完数据库后，主动将数据写入缓存中去。

​	但对于写入缓存可能出现的失败可以不处理，因为主动写入是为了解决缓存延迟的问题，主动写入导致的丢失数据由 Binlog 保障最终一致性



### 集中读请求

即热点数据读请求，当百万 QPS 都属于对同一条数据读取时，即使缓存是集群化的，同一个用户的请求都会被路由至集群中的某一个节点

热点查询是对相同的数据进行不断重复查询的一种场景。特点是次数多，但需要存储的数据少，因为数据都是相同的

#### 热点key探测

##### 京东[HotKey](https://gitee.com/mirrors/Tair.git)

###### etcd集群

​		存放配置热key的规则、worker地址

###### worker节点

​		通过滑动窗口探测热点key，将热点key推送给服务实例

###### 服务实例

​		启动从etcd拉取worker地址，建立连接，拉取热key规则，将符合规则的key上报给worker节点（对key计算hash，根据worker节点的数量取模）；接收worker节点推送的热key，将数据缓存再本机

##### [淘宝Tair](https://gitee.com/mirrors/Tair.git)

###### DataServer端

​		在DataServer上划分一块HotZone存储区域存放热点数据，每个HotZone都存储相同的读热点数据
对于Tair来说，每个key的访问都会落到同一数据节点DataServer上，由DataServer探测热点key，将热点推送其他节点的HotZone中

###### 客户端

​		客户端在第一次请求前初始化时，会获取配置HotZone的数据节点
​		客户端随机选择一个HotZone区域作为自身固定的读写HotZone区域（挑选前将数据节点地址打散）
​		在DataServer未发生变化的情况下，不会改变选择。即每个客户端只访问唯一的HotZone区域
​		客户端收到服务端反馈的热点Key信息后，至少在客户端生效N秒
​		客户端首先请求HotZone节点，如果数据不存在，则继续请求源数据节点，获取数据后异步将数据存储到HotZone节点里

##### [饿了么samaritan](https://github.com/samaritan-proxy/samaritan.git)

###### 设计前提

​			类似于Codis，都是中间层代理
​			所有的 Redis 请求都是经过代理 Samaritan，由代理层进行收集上报热点key
​			不️依赖任何外部组件，外部聚和组件的初衷是为了聚合不同机器的数据.基于局部可以代表整体的原则，那么单实例上的热 key 就可以代表全局的一个情况

###### 实现

​			每个代理会有一个全局的 Hotkey Collector
​			每个Redis的连接维护自己独立的 Counter，Counter 采用LFU 算法（只保留访问频次最高的key）
​			Collector 会定时地去收集每个 Counter 的数据并进行聚合，聚合的时候不会使用真实的计数，而是使用概率计数，并且为了适应访问模式的变化 counter 的值会随着时间衰减

###### 注意

​			当前的方案只能够快速定位系统中的热 key，但并没有真正解决热 key 本身带来的问题，仍旧需要业务方自行改造或者将那些热点 key 调度到单独的节点上

#### 利用应用内的前置缓存

应用内的缓存存储的均是热点数据。当应用扩容后，热点缓存的数量也随之增加。在采用了前置缓存后，在面对热查询时只需扩容应用即可。前端负载均衡器（如 Nginx 等）会将所有请求平均地分发到各应用中去

##### 首先是应用内缓存需要设置上限

​	必须设置容量的上限且设置容量满时的逐出策略。逐出策略可以是 LRU，将最少使用的缓存在容量满时清理掉，因为热点缓存需要存储的是访问次数多的数据。前置缓存也需要设置过期时间

##### 其次是根据业务对待延迟的问题

​	如果业务上可以容忍一定时间的延迟，可以在缓存数据上设置一个刷新时间即可

##### 要把控好瞬间的逃逸流量

​	在初始化时，瞬间出现热点查询或者缓存时间到期，那么所有的请求都会逃逸至后端加载最新的缓存，也有可能把后端缓存打挂

​	为了避免上述情况，在从后端加载数据时，通过加锁，只允许一个请求逃逸请求后端缓存

​	对于数据过期需要更新时，并不主动清理掉数据。其他非逃逸请求使用历史脏数据，而逃逸的那一个请求负责把数据取回来并刷新前置缓存

#### 降级兜底不可少

​	所部署的机器能够支持的 QPS 未必都能够大于当次的热点查询。对于可能出现的超预期流量，可以使用前置限流的策略进行应对

#### 其他前置策略

除了采用后端应用内的前置缓存进行应对外，在前端的架构里也有一些应对手段。比如在接入层（如 Nginx）进行前置缓存（nginx还可实现对请求的合并）、数据前置至离用户更近的 CDN 及开启浏览器缓存

#### 分散存储

将热点数据打散，分散到缓存集群中的各个节点

### 多维度富查询

1、为了满足和原有分库维度不一样的查询，最简单的方式是按新的维度异构一套数据

2、使用 ES 满足多维度查询

​	第一步需要做的便是数据异构，将数据库的数据同步至 ES 中

## 海量写请求

分库分表只解决了容量的问题，并没有解决写服务的高可用问题

写业务是指需要将用户传入的数据进行全部存储的一种场景，写入业务的目标是成功写入。对于写入业务，当出现各种故障时，最重要的是保证系统可写入

### 如何保证随时可写入？

只要有可用存储即可写入。引入写服务集群，当写请求到达时，将数据写入到写服务集群中，然后通过同步模块，将数据写入到目标库中。

### 如何维护可用列表？

可以通过自动感知或人工确认的方式维护可用的数据库列表

在写服务调用数据库写入时，可以设置一个阈值。如果写入某一台数据库，在连续几分钟内，失败多少次，则可以判定此数据库故障，并将此判定进行上报

当整个写服务集群里，超过半数都认为此数据库故障了，则可以将此数据库从可用列表中剔除

为了防止误剔除某一台只是发生网络抖动的数据库，可以在真正下线某一个机器前，增加一个报警，给人工确认一个机会。可以设置当多少时间内，人工未响应，即可自动下线

通过对写服务集群扩容，可以增加写业务的可用性，同时可以提高TPS。写服务集群扩容后，将写请求负载均衡的顺序随机写入升级为按权重写入，比如对新加入的机器设置更高的写入权重，让数据更快地在全部数据库里变得均衡

### 如何保证同步成功？

#### 1、同步模块

​	订阅写服务集群的binlog，根据分库分表规则，写入目标分库分表集群

#### 2、主动同步

​	在写入请求中主动触发同步模块进行迁移，同步模块在接收到请求后，立刻将数据同步至分库分表及缓存中

#### 3、兜底同步

​	主动触发同步模块的请求及同步模块本身运行都有可能出现异常，对于可能出现的异常情况，可以设计兜底策略进行处理

​	兜底的同步对于无状态存储中的数据按创建时间进行不断轮询，轮询会对超过设置的时间阈值（如 5S）仍未得到同步的数据进行主动同步

### 如何保证写入的可见性？

#### 1、写入成功，返回写入的全部数据

​	对于有时延要求的场景，当数据写入随机存储成功后，可以在请求返回前，主动地将数据写入缓存中，同时将此次写入的数据全部返回给前台。但此处并不强制缓存一定要写成功，缓存写入失败也可以返回成功。

#### 2、同步模块同步缓存

​	同步模块除了将数据同步至分库分表，也会写入到缓存中

#### 3、缓存可降级

​	因为主动写入缓存可能存在异常，导致数据未写入缓存，且主动数据同步和兜底同步是先写分库分表再通过 Binlog 刷新缓存，存在一定的延迟。

​	因此在查询时需要具备降级功能，当缓存中未查询到时，可以主动降级到数据库进行一次兜底查询，并将查询到的值存储至缓存中。

### 提高写性能

#### 1、将依赖的串行改并行

#### 2、依赖后置化

​		第一，在写入数据时，对于用户不太关心的数据信息，可以在重要的数据写入成功后，通过一个异步任务进行补齐。对于一些可以后置补齐的数据，可以在写请求完成时将原始数据写入一张任务表

 		第二，整个链路上会有较多外部接口，但大部分场景里，很多接口都是可以后置化的

#### 3、显式设置超时和重试

​	将超时时间设置为 TP999 和 Max 之间的值

​	自动重试只能设置读接口，设置自动重试是为了提高接口的可用性

#### 4、降级方式

​	1、当依赖的是读接口，同时该接口返回的数据只用来补齐本次请求的数据时，可以对其返回的数据采用前置缓存。当出现故障时，可以使用前置缓存顶一段时间，给依赖提供方提供一定的时间去修复缓存。

​	2、对产生故障的依赖进行后置处理，比如需要风控的场景，写入的数据自己可见，其他人不可见，待风控故障恢复后再进行数据校验，校验通过后再允许所有人可见。通过有损+异步最终校验，也是一种常见的降级方案

​	3、对于需要写下游的场景，比如下单，库存故障时，可降级直接跳过库存扣减，但需要提示用户后续可能无货。修复故障后进行异步校验库存。

## 海量扣减请求

### 1、并发修改优化为串行修改

扣减请求，主要就是保证大并发请求时据库中的库存字段值不能为负数	

一种是在应用程序中通过事务来判断，即保证减后库存不能为负数，否则就回滚

一种办法是直接设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时会直接执行 SQL 语句来报错

一种就是使用 CASE WHEN 判断语句，例如：UPDATE item SET inventory = CASE WHEN inventory >= xxx THENinventory-xxx ELSE inventory END

应对大并发的读库存，可以将库存放到缓存中，应用程序的本地缓存，也可以放到nginx中，当库存为0，不再请求后端服务

大并发扣减库存

如果秒杀商品的减库存逻辑非常单一，可以直接在缓存中减库存

如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存

由于 MySQL 存储数据的特点，同一数据在数据库里肯定是一行存储，因此会有大量线程来竞争InnoDB 行锁，而并发度越高时等待线程会越多，TPS会下降，响应时间会上升，数据库的吞吐量就会严重受影响。单个热点商品会影响整个数据库的性能

一个解决思路是遵循前隔离的原则，把热点商品放到单独的热点库中。但是会带来维护上的麻烦

一个解决思路是应用层做排队，按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用太多的数据库连接

在某些场景下有些多条 SQL（比如修改lastmodifytime修改时间字段） 是可以合并的，一定时间内只要执行最后一条 SQL 就行了，以便减少对数据库的更新操作

### 2、随机更新优化为顺序写

顺序写要比随机更新性能好

1、参数校验

2、开启事务

3、扣减明细插入任务数据库

​	任务库主要提供两个作用，一个是事务支持，其次是随机的扣减流水任务的存取;这两个功能均不依赖具体的路由规则，也是随机的、无状态的

4、插入失败，回滚事务

5、插入成功，进行缓存扣减

​		在Redis中的lua 脚本执行时，会按 SKU获取对应的剩余库存状态判断，如果此次扣减的数量大于剩余数量，直接返回错误提示数量不足；否则进行库存的扣减，返回成功

​		对于热门商品的扣减，往往集中到单台redis上，为避免海量请求超过redis负载，将库存按redis的数量进行平均等分，每一个缓存里均存储一等份即可。在处理秒杀请求时，不只是固定地命中某一个缓存分片，而是在每次请求时轮询命中缓存集群中的每一个缓存分片

6、缓存扣减失败，回滚

7、缓存扣减成功，事务提交，结束

缓存扣减失败，两种情况，第一种是扣减的数量不足，第二种就是缓存出现故障，缓存失败的可能性有很多，比如网络不通、调用缓存扣减超时、在扣减到一半时缓存突然宕机（故障 failover）了，以及在上述返回的过程中产生异常等。针对上述请求，都有相应的异常抛出，根据异常进行数据库回滚即可，最终任务库里的数据都是准的

*******

## 库存热点优化

把无序的争抢变为有序的排队，从而提升热点库存扣减的性能问题

## 预热

数据预热

​	预热系统会模拟应用的访问，通过这种访问将数据加载到缓存和数据库中，保证缓存和数据库BP的命中率

应用预热

​	预先建立好连接，防止在高峰时建立连接的开销

​	线程池预热，ThreadpoolExecutor提供了prestartAllCoreThreads方法可以预先启动核心线程 

​	JIT预热，JAVA代码是解释执行的，如果在高峰时同时做JIT编译，会消耗了大量的CPU，系统响应时间会拉长，通过JIT预热，保证代码可以提前充分编译

## 跨地域的分布式系统

​	同城多活

​	异地多活

## RDMA技术（远程直接数据存取）

# 负载均衡

## 含义

将负载(访问的请求)“均衡”地分配到多个处理节点上。这样可以减少单个处理节点的请求量，提升整体系统的性能。

## 类别

代理类的负载均衡服务

以单独的服务方式部署，所有的请求都要先经过负载均衡服务，在 负载均衡服务中，选出一个合适的服务节点后，再由负载均衡服务，调用这个服务节点来实 现流量的分发。

四层负载LVS，七层负载nginx

一般会同时部署 LVS 和 Nginx 来做 HTTP 应用服务的负载均衡。也 就是说，在入口处部署 LVS，将流量分发到多个 Nginx 服务器上，再由 Nginx 服务器分发 到应用服务器上

客户端负载均衡服务

## 负载均衡策略

静态策略

在选择服务节点时，不会参考后端服务的实 际运行的状态

动态策略

依据后端服务的一些负载特性，来决定要 选择哪一个服务节点

Nginx 来说，我们要如何保证配置的服务节点是可用的呢?

淘宝开源的 Nginx 模块nginx_upstream_check_module了，这个模块可以 让 Nginx 定期地探测后端服务的一个指定的接口，然后根据返回的状态码，来判断服务是
否还存活。当探测不存活的次数达到一定阈值时，就自动将这个后端服务从负载均衡服务器 中摘除

如何动态更新nginx的up_stream

nginx-upsync-module

# 数据库

池化技术，数据库连接池

最小连接数

最大连接数

空闲时间

定时检测连接的可用性,，比如使用连接发送“select 1”的命令给数据库看是否会抛出异常(C3P0)

主从分离

分库分表

水平拆分

垂直拆分

任务库

​	优化随机更新为顺序写

​	异步将数据同步给真实的业务数据库

# 分布式系统设计策略

## 心跳检测

检测节点是否存活

 周期检测心跳机制、累计失效检测机制

## 高可用

经过设计来减少系统不能提供服务的时间 

### 主备（MS模式）

Active-Standby模式

当主机宕机时，备机接管主机的一切工作

在数据库高可用性方案中比较常用，如 MySQL、Redis等就采用MS模式实现主从复制。保证高可用

### 互备（MM模式）

两台主机同时运行各自的服务工作

一个系统存在多个master，每个master都具有 read-write能力

在数据库中通过双主，对外提供读写服务并且互相进行数据同步

### 集群

有多个节点在运行，同时可以通过主控节点分担服务请求

集群模式需要解决主控节点本身的高可用问题，一般采用主备模式。

### 脑裂问题

同时用两条心跳线路

引入仲裁机制，由第三方仲裁

Lease机制

## 容错性

IT系统对于错误包容的能力

保障分布式环境下相应系统的高可用或者健壮性

## 负载均衡

使用多台集群服务器共同分担计算任务，把网络请求分配到集群可用的不同服务器节点上，从而达到高可用性及较好的用户操作体验。

## 服务协调

主要用来解决分布式环境下多个进程之间的同步控制，有序的访问某种临界资源
基于缓存redis实现的分布式锁
		使用setnx加锁，并设置过期时间，超过时间自动释放，value值用来标识锁的持有者，释放锁时根据value来判断是否有资格释放锁
基于zookeeper实现的分布式锁
		创建一个目录，获取锁时在此目录下创建临时的顺序节点
		获取目录下的所有节点，如果自己是最小的节点，获取锁
		如果不是，设置监听比自己小的节点

## 服务削峰

​	为了应对短时间上亿用户的涌入，瞬间巨大的流量
​	削峰本质上，就是更多的延缓用户的请求，以及层层过滤用户的访问请求，遵从最后落地到数据库的请求尽量少的原则
​	消息队列削峰
​	流量削峰漏斗：层层削峰
​		CDN
​		缓存
​		后台系统
​		数据库系统

## 服务降级

​	保证核心或者基本服务的正常运行，可以将一些不重要或不紧急的任务进行服务的延时使用或者暂停使用
​	降级策略
​		缓存降级，使用缓存方式来降级部分读频繁的接口
​		读降级，直接禁止相关读的服务请求
​		写降级，直接禁止相关写的服务请求
​		延迟服务，如定时任务延迟处理，消息写入mq延迟处理

## 服务限流

​	通过对并发请求进行限速或者一个时间窗口内的请求数量尽心限速来保护系统，一旦达到限制的速率，则可以拒绝服务、排队或等待

### 	多维度限流

​		客户端
​			防重点击校验
​		nginx
​			限制单位时间内的请求数、限制同一时间的连接数
​		tomcat服务器
​			配置tomcat线程池、配置最大连接数、配置请求队列等参数
​		服务api接口
​			限制单位时间内的调用次数

### 	限流算法

​		计数器
​		滑动窗口
​		漏桶
​			请求会在桶内排队，响应时间拉长
​		令牌桶

## 服务熔断

​	避免调用链中的异常请求，拖垮调用方甚至宕机
​	熔断器的工作机制主要是关闭、打开和半打开这三个状态之间的切换
​	在正常情况下，熔断器是关闭的
​	基于滑动窗口统计异常/超时的百分比，超过配置的阈值，熔断器打开；此时再发起请求，直接被熔断拦截
​	当熔断器打开一段时间后，会转为半打开状态。这时发送一个请求给服务端，如果能够正常地得到服务端的响应，则将状态置为关闭状态，否则设置为打开。

# SRE

## 目的

提升稳定性。提升MTBF，减少故障发生的次数，提升故障发生的间隔；降低MTTR，提升故障修复的效率，减少故障影响的时长

在 Pre-MTBF 阶段（无故障阶段），要做好架构设计，提供限流、降级、熔断这些 Design-for-Failure 的服务治理手段，以具备故障快速隔离的条件；还可以考虑引入混沌工程这样的故障模拟机制，在线上模拟故障，提前发现问题。

在 Post-MTBF 阶段，也就是上一故障刚结束，开启新的 MTBF 阶段，我们应该要做故障复盘，总结经验，找到不足，落地改进措施等。

在 MTTI 阶段，依赖监控系统帮我们及时发现问题

## 指标

MTTI平均故障发现时间

MTTK平均故障认知时间

MTTF平均故障解决时间

MTTV平均故障修复验证时间

## SLA

衡量服务可用性的重要性指标

一般用几个9的SLA服务等级来衡量服务的可用性SLA=（1-年度不用用时间/年度总时间）*100

但是像流量高峰期和流量低峰期分别停机1分钟，对业务的影响结果完全不同

## 应急响应机制

​	应急响应的原则
​		首要原则，第一时间恢复服务
​		影响重大，应升级处理
​		如果短时间解决不了，及时升级处理并尽可能的止损
​	应急响应流程
​		事前预防
​		问题监控
​		及时响应
​		故障定位
​		故障解决
​		事后总结
​		故障回顾
​		改进措施

## 监控报警

​	操作系统监控
​		Zbbix
​		Open-Falcon
​		Promtheus
​	链路监控
​		Cat
​		SkyWalking
​		Zipkin
​		PinPoint
​	业务监控
​	中间件监控
​	报警策略
​		时间维度
​		报警级别
​		阈值设置

## 故障演练（混沌工程）

​	对系统进行一些破坏性的手段，观察在出现局部故障时，整体的系统表现是怎样的，从而发现系统中存在的，潜在的可用性问题

中台

本质上是对业务能力的抽象和共享的过程

# 灰度发布

又名金丝雀发布，指在黑与白之间，能够平滑过渡的一种发布方式。
在其上可以进行 A/B testing， 即让一部分用户继续用产品特性 A，一部分用户开始用产品特性 B

灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调 整问题，以保证其影响度

服务分组或者版本号

# 代码坏味道

## 命名的坏味道

不精准的命名

命名过于宽泛，不能精准描述

命名要能够描述出这段代码在做的事情

好的名字应该描述意图，而非细节

用技术术语命名

解决：编写可维护的代码要使用业务语言，建立团队的词汇表

## 乱用英文的命名

违反语法规则的命名

不准确的英语词汇

英语单词的拼写错误

解决：制定代码规范，比如，类名要用名词，函数名要用动词或动宾短语；建立团队的词汇表；要经常进行代码评审

## 重复的代码、结构

复制粘贴的代码

结构重复的代码

if 和 else 代码块中的语句高度类似

解决：避免复制粘贴，提取一个新的函数出来，把公共的部分先统一掉。

## 长函数

把代码平铺直叙地摊在那里

需求变更只是每次增加了一点点

解决：分离关注点，避免多业务、多层次的代码写到一起

## 大类

职责不单一

字段未分组

解决：把不同的职责拆分开来；将不稳定的字段进行抽离

## 长参数

参数数量过多导致的长参数

标记参数导致的长函数

解决：把长参数封装成一个类；对于静态不变的参数，可以成为软件结构的一部分；根据标记参数，将函数拆分为多个函数

## 滥用控制语句

嵌套的代码

else语句

重复的switch

循环语句

解决：将循环中的内容封装成函数；不要使用else语句；多态取代条件表达式；以卫语句取代嵌套的条件表达式（卫语句（guard clauses）是一种改善嵌套代码的优化代码；编程规则：函数至多有一层缩进）

## 缺乏封装

过长的消息链

解决：隐藏委托关系；好的封装基于行为；以对象取代基本类型

## 变量的声明与赋值分离

变量一次性完成初始化，尽可能使用不变的量，在能够使用 final 的地方尽量使用 final

一次性完成变量的初始化

用声明式的方式进行集合的初始化

## 依赖混乱

## 不一致的代码

方案中的不一致，使用不同的程序库

命名的不一致

代码中的不一致，不同层次的代码耦合在了一起

解决：团队中使用同一的标准程序库，比如guava；分离关注点，分清楚代码应处的层次

## 落后的代码风格

引入Optional可以减少忽略空指针引起的问题

函数式编程

# 代码审查

实现方案的正确性

算法的正确性

代码的坏味道

及时评审

提升评审的频率，比如，每天评审一次

周期过长，累积的问题就会增多，造成的结果就是太多问题让人产生无力感

# 架构的目的

架构设计是为了解决软件复杂度带来的问题

通过熟悉和理解需求，识别系统复杂性所在的地方，然后针对这些复杂点进行架构设计

不需要每个架构都具备高性能、高可用、高扩展等特点，而是要识别出复杂点然后有针对性地解决问题

# 识别系统的复杂度

​	高性能

​	高可用

​		计算高可用

​		存储高可用

​	扩展性

​	安全性

​	成本

# 架构遵循的原则

​	合适原则

​	简单原则

​	演化原则

# 设计原则与思想

## 	单一职责原则

​		不要存在多于一个导致类变更的原因，简单来说， 一个类只负责唯一职责

## 	里氏替换原则

​		在任何父类出现的地方可以用它的子类来替代

## 	依赖倒置原则

​		 要依赖于抽象和接口，不要依赖于具体实现

## 	接口隔离原则

​		调用者不应该强迫依赖它不需要的接口

​		在设计接口时，不要设计出庞大膝肿的接口，因为实现这种接口时需要实现很多不必要的方法。尽量设计出功能单一的接口，这样也能保证实现类的职责单一

## 	迪米特法则

​		最少知识原则。一个对象应该对其他对象保持最少的了解。简单来说，就是要求我们减低类间耦合

## 	 开放－封闭原则

​		程序要对扩展开放，对修改关闭。简单来说，当需求发生变化时，我们可以通过添加新的模块满足新需求，而不是通过修改原来的实现代码来满足新需求

局部并发原则

## 组合和聚和原则

在软件复用时，要尽量先使用组合或者 聚合等关联关系来实现，其次才考虑使用继承关系来实现

采用合成复用原则时，可以将已有对象纳入新对象中，使之成为新对象的一部分，新对象可以调用已有对象的功能

DRY减少信息的重复

KISS保持简单

YAGNI避免过度设计原则

# 服务拆分维度

​	业务维度

​	功能维度

​	资源维度

​		高频高并发场景

​			商品详情	

​			优惠计算

​			热点数据、热点隔离

​		低频突发场景

​			秒杀

​			服务隔离

​		IO密集

​		CPU密集

用户维度

​	2C

​	2B

​	用户端

​	采购端

​	运营端

前后台业务

​	买家业务

​	卖家业务

​	运营业务

# 接口版本控制

RPC接口，消费方指定版本号，请求指定版本好的服务提供方

HTTP接口，Header中指定版本号，业务网关根据根据版本号路由到指定的服务

# 设计模式

对接口编程而不是实现编程,优先使用对象组合而不是继承

## 基石

封装

继承

多态

分类

## 创建型模式

怎么样创建对象
将对象的创建和使用分离
降低系统耦合度

单例

原型

工厂方法

抽象工厂

建造者

## 结构型模式

代理

适配器

桥接

装饰

外观

享元

组合

过滤器

## 行为型模式

模板

策略

命令

职责链

状态

观察者

中介者

迭代者

备忘录

解释器

# CAP理论

CAP 理论含义是，一个分布式系统不可能同时满足一致性（C:Consistency)，可用性（A: Availability）和分区容错性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中的2个

 C一致性 

​	分布式系统当中的一致性指的是所有节点的数据一致，或者说是所有副本的数据一致
A 可用性

 Reads and writes always succeed. 也就是说系统一直可用，而且服务一直保持正常
P 分区容错性 

系统在遇到一些节点或者网络分区故障的时候，仍然能够提供满足一致性和可用性的服务
在分布式系统当中，CAP三个特性我们是无法同时满足的，必然要舍弃一个。三者舍弃一个，显然排列组合一共有三种可能

# BASE理论

什么是BASE理论
BASE：全称：Basically Available(基本可用)，So state（软状态）,和 Eventually consistent（最终一致性）三个短语的缩写

BASE是对CAP中一致性和可用性权衡的结果，BASE理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性

①Basically Available(基本可用)
基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性

②Soft state（软状态）
软状态指的是允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同
节点的数据副本之间进行数据同步的过程中存在延迟。

③Eventually consistent（最终一致性）
最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。

# 异地多活

异地就是指地理位置上不同的地方，多活就是指不同地理位置上的系统都能够提供业务服务

## 同城异区

将业务部署在同一个城市不同区的多个机房

应对机房级别故障的最优架构

## 跨城异区

业务部署在不同城市的多个机房，而且距离最好要远一些

有效应对这类极端灾难事件。跨城异地距离较远带来的网络传输延迟问题，给异地多活架构设计带来了复杂性。导致数据的不一致性

保证核心业务的异地多活

保证核心数据最终一致性

采用多种手段同步数据

存储系统自带的同步、消息队列同步，使用不同的网络连接，可以一个走内网、一个走公网

二次读取，接口访问和同步通道使用不同的网络连接

# 基于共识算法（Raft）的跨机房部署

## 两地三中心

一城市部署两个数据中心，另一城市部署一个数据中心。每个数据中心部署一个数据节点

能满足单个数据中心级的容灾，但是不能满足城市级容灾

## 三地五中心

5 个节点基本平分到了 3 个城市的数据中心，2个中心部署2个副本，1个中心部署1个副本

任何一个城市网络出现了问题，raft 协议都能正常运行，也是普遍使用的较高容灾级别的部署方式

## 三地九中心*

三地九中心并不是直接部署 9 个 Raft 节点，而是将 Raft 节点分为了两层

下面一层按照3 个一组分为了 3 组，分别放在 3 个数据中心。每个数据中心的 3 个节点刚好组成一个Raft 集群，通过 Raft 选主的方式选出来一个主节点。

这样3个数据中心就共有3个主节点。这 3 个主节点之间刚好也可以形成一个 Raft 集群，再选出一个级别更高的 Raft 主节点。这个唯一的主节点负责代表集群对外提供服务

# 数据安全

数据篡改

​	数据签名

请求重放

​	基于时间戳的解决方案、Token，请求幂等

存储安全

​	加密存储，明文数据不落盘，需知道明文的敏感数据加密存储，无需知道明文的数据使用hash存储

敏感信息

​	避免将用户隐私信息明文用于传输展示，服务端数据脱敏

Sql 注入

​	采用预编译Sql、数据检查

XSS 跨站攻击

​	输入输出检查，尽可能把检查逻辑放入后端以防绕过

CSRF 跨站请求

​	验证码、验证Referer、CSRF Token

# 后台系统的归类和共性

##  读业务（资讯类业务系统）

产品

​	微博、头条、知乎、抖音、快手

目的

​	尽可能的保证读的可用性和用户体验

功能要求

​	高可用，保证系统可读（即使不能写，但是需要可以浏览）

​	高性能（比如TP99要在100ms以内）

​	支持QPS非常高

实现

​	读业务的代码尽可能的简单

​	架构尽量不要分层，分层之后多一次网络传输

​	CQRS原则，将读写分离，分开优化

数据前置

​	浏览器，减少请求的次数，降低了延迟

​	CDN，缩短了传输距离，降低了延迟

缓存穿透

​	校验key的合法性，拦截无效请求

​	不存在的key存储空值，但是造成空间的浪费

​	布隆过滤器拦截

缓存集中过期导致雪崩

​	过期时间加上一个随机值，避免同一时间过期

​	多级缓存、前置缓存

nginx缓存

​	开启缓存功能，设置过期时间

​	开启请求合并功能，对于相同的请求只调用一次后台服务

数据变更导致的无法实时感知

​	采用Binlog方式，Canal+Mq

缓存数据压缩

​	将数据按照json格式序列化时，可以在字段上添加较短的替代标志，表示序列化后此字段的名称可以用替代标志进行表示；如果使用了redis中的Hash结构存储，也可以采取上述方式进行存储

热点数据的查询

​	缓存的主从，增加从节点 

​	为了应对热点数据的查询，增加从节点，并发性能并不会翻倍增加，而且造成了资源浪费

读服务中添加前置缓存模块

​	设置缓存容量的上限及逐出策略

​	数据变更感知的问题

​		定期刷新，有一定的延迟

​		实时感知，采用Binlog的方式在变更时主动刷新

控制穿透到缓存、数据库的流量

​		对于相同的查询请求，只有其中一个可以穿透到数据库，防止重复查询

流量超出预期，对读服务进行限流

## 写服务（外卖、打车）

保证写的高可用，支持海量数据的写入

分库分表

​	按用户分库

​	按照业务记录的唯一标志分库

分库分表中中间件

​	代理模式

​	内嵌模式

多维度查询

​	异构数据，通过Binglog方式，将数据导入ES

## 扣减服务（库存）

保障扣减的高可用，保证数据一致性，抗住高并发

纯数据库实现扣减

​	扣减库存、插入流水记录

基于缓存实现缓存扣减

​	1、Redis只支持单条命令的原子性，需要借助Lua实现批量扣减的原子性

​	2、Lua脚本中，首先判断数量是否满足，满足的话就扣减数量、记录流水

​	3、Lua扣减成功后，异步的将扣减内容保存至数据库

​	4、运营后台修改库存时需要同步增加至Redis

​	Redis宕机，扣减成功但是流水记录失败；异步刷新数据库失败；导致出现丢数据、少卖的情况。为了保证不出现少卖的情况需要做对账、异常处理等设计

缓存+数据库构建高可靠的扣减

1、扣减明细插入任务数据库（顺序插入；配置多个任务库，分摊写压力）
2、Redis扣减库存（运营后台修改库存需实时同步至Redis）
3、扣减成功，事务提交；扣减失败，事务回滚
4、异步将任务数据库的数据导入正式数据库

极端情况下，扣减成功后，还没给扣减服务返回响应，Redis就宕机，导致事务回滚，出现丢数据、少卖的情况。

应对热点缓存扣减*

引入秒杀库存分发器，将秒杀商品的库存平均分配到每个缓存分片

应对秒杀流量

扣减服务设置单机限流，实时并且精准；远程的集群限流多一次网络传输而且并不精准

引入兜底限流配置中心，推送每个分片在每台应用中的限流值，避免缓存分片被流量打垮

# 高并发系统分类

## 高并发读

策略1：加缓存

本地缓存或Memcached/Redis集中式缓存

MySQL的Master/Slave

CDN静态文件加速（动静分离）

策略2：并发读

异步RPC

Google的“冗余请求”

客户端同时向多台服务器发送请求，哪个返回得快就用哪个，其他的丢弃，但这会让整个系统的调用量翻倍

策略3：重写轻读

把计算逻辑从“读”的一端移到了“写”的一端

多表的关联查询：宽表与搜索引擎

策略4：读写分离（CQRS架构）

分别为读和写设计不同的数据结构

定时任务定期把业务数据库中的数据转换成适合高并发读的数据结构

## 高并发写

策略1：数据分片

数据库的分库分表

JDK的ConcurrentHashMap实现

Kafka的partition

ES的分布式索引

策略2：任务分片

Map/Reduce

Tomcat的1+N+M网络模型

策略3：异步化

LSM树（写内存+Write-Ahead日志）

凡是不阻碍主流程的业务逻辑，都可以异步化，放到后台去做

策略4：批量

Kafka的百万QPS写入

# 配置中心

## 开源实现

### Apollo

1、用户在Portal操作配置发布，
2、Portal调用Admin Service的接口操作发布
3、Admin Service发布配置后，发送ReleaseMessage给各个Config Service
4、客户端从Config Service拉取配置信息

客户端实现

本地模式

从本地文件读取文件配置信息；注册监听器ConfigChangeListener，监听配置的变更

远端模式

先从Config Service拉取配置信息，然后启动定时器，周期性的从远端拉取配置信息。
启动长轮询，获取发生变更的namespace，客户端获取到namespace后，会立即请求Config Service获取该namespace的最新配置。获取到配置信息后会保存到本地文件

### Nacos

客户端获取配置时优先从本地文件获取，如果获取不到，发送Http请求从远端获取，获取之后调用ConfigFilterChainManager的doFilter方法

注册监听器，监听配置的变化；后台通过长轮询获取变更的配置信息，并调用注册的监听器

客户端实现

拉取模式

Client主动拉取配置信息，服务端不需要对Client进行管理，但是Client不能及时获取更新的数据

推送模式

服务端主动推送最新的配置信息给Client，服务端需要对Client进行管理，服务端的复杂度上升

但是可以保证Client及时获取到最新的配置信息

Client连接比较多时，服务端可能出现瓶颈

对于配置下发敏感且Client数不是太大推荐使用推送模式

当Client数在万级以上推荐使用拉取模式，或者加入中间层，分担服务端的压力

# 注册中心

## 开源实现

### Eureka（AP)

#### EurekeServer

AP模型，实现最终一致性

高可用通过部署多个服务节点实现

每个节点存储全量的服务信息，各个节点都是平等的，无主从之分，每个节点会同步本节点的数据到其他节点

每台Server都需要存储全量的服务数据，Server的内存明显会成为瓶颈，扩容的效果不明显

如果在15分钟内80%的客户端节点都没有正常的心跳，那么Eureka就认为客户端与注册中心发生了网络故障，注册中心进入自我保护机制

在一定时间内没有接收到某个微服务节点的心跳，将会注销该微服务节点(默认90s)

#### 服务消费方

周期性向服务端主动pull服务数据（默认30s）

存在实时性不足以及无谓的拉取性能消耗的问题

#### 服务提供方

启动时，向EurekeServer注册自己的信息

周期性向EurekeServer发送心（默认30s）跳以续约自己的信息

### Zookeeper（CP）

当服务注册数、订阅数超过一定数量，不堪重负

写单点，不能水平扩展

按业务垂直拆分ZK集群

依赖ZK的Session活性心跳机制以及结合临时节点机制

### Nacos（AP/CP）

注册中心分别实现了AP和CP模型，根据namespaceId和serviceName判断选择CP还是AP模型（DelegateConsistencyServiceImpl）

AP模型实现，最终一致性

1、本地存储

2、触发数据变更事件，通过UDP协议向消费方推送变更的服务

3、定时向其他的注册中心同步变更的数据，最终每个Nacos server的数据都保持一致性

CP模型实现	RAFT协议

### Sofa-registry（AP）

支持海量的客户端，引入了中间层Session-Server，它是无状态的，很容易扩容

SessionServer承载客户端的连接，负责服务的发布和订阅
SessionServer也会对发布的服务进行保存，避免每次都请求DataServer
为了保持一致性，当DataServer上的服务信息发生了变更，及时推送变更的服务给SessionServer

DataServer负责数据存储；数据按照dataInfoId一致性哈希算法存储，支持多副本备份。当DataServer扩容时，对数据进行迁入迁出

## 技术要点

### 模型选择CP还是AP

AP可以保证可用性，但不保证消费方能拉取到最新的数据

CP可以保证一致性，但当集群中的多数节点宕机了不能保证可用性

### 服务发布大量注册写请求

将注册的时间随机化，避免同一时间注册

注册中心分片，将注册请求分散到其他节点

添加中间层，也可以缓存服务，合并重复的注册请求，再将合并后的请求发送给注册中心

服务提供方将注册中心的集群地址打散，避免注册请求都发送到同一台注册中心服务器

### 如何处理海量连接

添加中间层

### 如何处理连接超时

遍历扫描

动态分组（时间轮、桶）

### 注册中心容灾考虑

服务调用链路弱依赖注册中心，只有服务发布、下线、扩缩容等必要时依赖

客户端设计考虑容灾，缓存拉取的服务信息

把所有服务清单列表同步一份到配置中心，注册中心发生故障后，可以从配置中心拉取数据

### 服务状态检测

探活，不仅是探测服务提供方是否宕机，还要探测是否可以对外提供正常的服务

服务提供方主动上报心跳，注册中心周期性检测服务提供方是否在一段时间内发送心跳

服务消费方主动向服务提供方发起健康检查，根据一段时间内的成功响应的比率去判断下次是否继续向其发送请求

### 如何优雅下线服务

1、通知注册中心，此服务已下线，从服务列表中删除

2、注册中心通知消费方此服务已经下线，从服务列表中剔除，不再给服务提供者发送请求

3、通知服务提供者被迫下线。服务提供者接受到下线请求后，不再接受后续的请求，并且等待一定的时间将已经接受的请求处理完毕，如果在规定的时间未处理完成，则强制关闭

### 避免通知风暴

如果多个服务集群同时上线或者发生波动时，注册中心推送的消息就会更多，会占用过多的带宽资源

对变更的信息合并压缩

分批间隔发送

### 保护策略

注册中心的自我保护

​		避免发生网络抖动，导致大量的心跳超时，进而剔除大量的服务

客户端自我保护

​		注册中心因为高负载，推送了异常数据。客户端监测服务的可用节点数量下降超过一定阈值，进入自我保护，放弃使用新推送的服务注册信息

灵活方便的扩缩容

方便支撑海量的客户端连接和海量的服务存储

对于海量客户端连接的问题，可以通过添加中间层解决，中间层无状态可以灵活扩容

### 对于海量存储

1、可以将注册中心集群进行分组，服务提供方注册时随机选择某一个分组进行注册，每一组的集群负责存储一部分的服务注册请求

2、基于一致性 Hash 做了数据分片，每台注册中心节点只存储一部分的数据，随着数据规模的增长，只要添加注册中心节点即可

# 分布式事务

## 解决方案

​	seata

​		AT

​		TCC

​		SAGA

​	ServiceComb Pack

​		TCC

​		SAGA

​	RocketMq半消息

​			1、先发送半prepare请求，Broker写消息到HalfTopic

​			2、执行事务操作，事务提交成功，发送commmit请求，将half消息保存到真实队列中，表示消费者可以消费

​		3、Broker定时扫描半消息，然后回调客户端提供的事务回查方法，判断对应的事务是否已经提交成功

​	本地事务表+消息中间件

​		    1、业务操作数据和事务信息存储到同一数据库

​			2、事务提交成功时，将消息发送到消息中间件。若发送成功，将本地事务表中的状态修改为已发送；若发送失败，则重试；后端开启定时任务，扫描本地事务表，将未发送的消息发送到消息中间件。事务提交失败，则将事务回滚		

​	单机事务处理

​			避免分布式事务，所有的事务操作在单台机器通过本地事务上执行，然后定时将事务操作复制到对应的真实的数据库中

## 分布式事务理论

TCC（Try-Confirm-Cancel））

概念

​	一阶段：Try（检测预留资源）

​	二阶段：Confirm（真正的业务操作提交）/Cancel（预留资源释放）

注意事项

​	空回滚：Try未执行，Cancel执行了

​		Try 超时（丢包），分布式事务回滚，触发 Cancel

​		允许空回滚

​	悬挂：Cancel 比 Try 先执行

​		Try 超时（拥堵），分布式事务回滚，触发 Cance，拥堵的 Try 到达

​		拒绝空回滚后的Try 操作

幂等控制

FMT 模式（（Framework-managed transaction）

框架管理事务，托管事务的所有操作，一阶段和二阶段操作均由框架自动生成

一阶段：执行用户SQL，并且保存一条事务日志，包含修改前的数据快照和修改后的数据快照

二阶段：框架自动生成“提交/回滚”操作。提交:删除事务日志；回滚：如果当前的数据是和事务日志中记录的修改后的快照相同，则根据修改前的数据快照进行还原

## 优化点

二阶段异步执行

# 链路追踪

最小的业务代码入侵系统

日志的记录收集对服务器的性能不会产生影响

丰富的查询统计功能

SkyWalking

zipkin

# Service Mesher

servicecomb-mesher（华为）

Mosn（蚂蚁）

Istio

Linkerd

# 分布式ID

特性

​	全局唯一

​	有序

​	具有业务意义

​	保证高可用

​	对数据库友好，占用空间不要太长

实现

​	UUID

​	Redis

​	Zookeeper顺序节点

​	Mongodb

​	Mysql自增ID

​	Snowflake（twitter）

​			整体长度通常是 64 （1 + 41 + 10+ 12 = 64）位，适合使用 Java 语言中的 long 类型来存储；头部是 1 位的正负标识位。紧跟着的高位部分包含 41 位时间戳，通常使用 System.currentTimeMillis()。后面是 10 位的 WorkerID，标准定义是 5 位数据中心 + 5 位机器 ID，最后的 12 位就是单位毫秒内可生成的序列号数目

​	Leaf-segment（美团）

​	tinyid（滴滴）

​	[seqsvr（微信）](https://www.infoq.cn/article/wechat-serial-number-generator-architecture/)

疑问：真的需要集中式的全局唯一Id吗？

# 分布式任务调度

## ElasticJob

使用 jar 的形式提供分布式任务的协调服务

引入分片的概念，将一个任务分解成多个独立的子任务

借助quartz框架，实现Job接口，注入自定义的ElasticJob，实现分布式任务调度

每个任务都有自己的Leader节点，创建Leader节点的服务器为主服务器，在任务开始调度的时候，需要为每个任务节点分配执行的分片项。分片仅可能发生在下次任务触发前

提供了失效转移和错过任务重新执行的功能，但是只适用于运行耗时较长且间隔较长的场景

运维平台

​	 读取作业注册中心展示作业配置和状态，展现作业运行轨迹及执行状态，或更新作业注册中心数据修改作业配置

[Saturn](https://github.com/vipshop/Saturn)

# 限流、熔断、降级 

## [SDS(Service Downgrade System)](https://github.com/didi/sds)

轻量级、简单、易用的限流、熔断、降级系统
sds-client做为客户端，提供了限流、熔断和数据统计等功能
sds-admin作为Server端主要是为了配置降级策略、提供丰富的仪表盘并且保存客户端上传的统计数据

## [Sentinel](https://github.com/alibaba/Sentinel)

以方法为单位，基于滑动窗口，统计过去一段时间内的调用信息，比如调用次数、异常次数、超时时间等等，执行降级策略

## 注意事项

降级时，数据一致性的问题

## 资源隔离

服务分组

线程资源隔离，服务端按请求分队列隔离；调用方工作线程隔离，不同的服务调用使用不同的线程

信号量限制调用的并发数量，无法控制超时时间

## 服务熔断

可熔断的服务

​	非核心、非必要的服务

熔断触发

​	主动触发

​	被动触发

## 降级

有损提供服务，服务柔性可用

浏览计数返回假数据、推荐搜索返回兜底数据，用户不易感知

## 断路器设计

当对下游服务的调用异常量达到设定阈值后，打开断路器，触发熔断，在熔断期内，不会调用调用下游服务，直接调用降级方法；超过了熔断器，尝试调用下游服务，如果服务响应正常，则关闭断路器，否则断路器继续打开状态

状态流转

CLOSE关闭状态

异常量达到阈值，OPEN打开状态

OPEN状态超过一定时间后转为HALF状态

尝试调用下游服务，调用成功，则改为CLIOSE状态，否则处于OPEN状态

# 反向代理

描述

代理服务器，反向代理隐藏了真实的服务端，帮客户端把请求转发到真实的服务器

意义

承载海量连接

保证内网的安全

缓存加速Web请求

负载均衡

分类

硬件反向代理

F5

Netscale

A10

软件反向代理

LVS

主要用于多服务器的负载均衡，工作在网络层

Nginx（七层负载）

模块化

核心模块

标准HTTP模块

可选HTTP模块

第三方模块

事件驱动

异步

单进程

master进程

 监视工作进程的状态

当工作进程死掉后启动新进程

处理信号和通知工作进程

worker进程

处理客户端请求

从主进程处获得信号做相应的处理

非阻塞

  reload

 nginx -s reload

不重启nginx动态加载配置

启动新的woker进程，等待旧的的进程将待处理的请求处理完成或者超过一定时间，将旧的进程关闭。新的进程依次接收请求进行处理

dyups

动态配置upstream

https://github.com/yzprofile/ngx_http_dyups_module

# RPC设计

## 关键特性

### 服务注册/发现

​			选择CP还是AP。在设计超大规模集群服务发现系统的时候，舍弃强一致性，更多地考虑系统的健壮性.
最终一致性才是分布式系统设计中更为常用的策略

### 健康检测

​			判断服务的可用性
​			“连续”心跳失败次数必须到达某一个阈值。如果节点的心跳日志只是间歇性失败，也就是时好时坏，这样，失败次数根本没到阈值，调用方会觉得它只是“生病”了，并且很快就好了。那怎么解决呢？
​			基于滑动窗口，统计成功次数的百分比，可用率低于某个阈值时，进行降权处理

### 路由策略

​			在负载均衡之前，选择符合发送规则的节点
​			IP路由、参数路由

### 集群策略

​			快速失败
​			故障转移（重试）
​			失败自动恢复，后台记录失败请求重选节点定时重发，通常用于消息通知操作

### 负载均衡策略

​			随机
​			轮询
​			本地服务优先
​			一致性哈希
​			最少连接
​			最小耗时
​			自适应（根据服务的处理能力，智能地控制发送给每个服务节点的请求流量）
​				收集运行信息，包括服务器的CPU核数、负载、内存等指标
​				收集耗时数据，如平均耗时、TP99、TP9999

### 异常超时重试

​			业务逻辑必须是幂等的
​			重试时，去掉之前有问题的节点
​			在每次触发重试之前，我们需要先判定下这个请求是否已经超时，如果超时了会直接返回超时异常，否则我们需要重置下这个请求的超时时间
​			加个重试异常的白名单，用户可以将允许重试的异常加入到这个白名单中
​			时间轮实现超时

### 优雅启动

​			启用预热
​				让刚启动的服务提供方应用不承担全部的流量，而是让它被调用的次数随着时间的移动慢慢增加，增加其权重
​			延迟暴露
​				应用启动完成后再将服务注册
​				在服务提供方启动后，接口注册到注册中心前，模拟调用逻辑，从而使 JVM 指令能够预热起来，并且也可以事先预加载一些资源，只有等所有的资源都加载完成后，最后才把接口注册到注册中心

### 优雅关闭，服务下线

​			服务提供方通知注册中心，注册中心通知订阅该服务的消费方；涉及两次网络通信，不能保证实时性
​			服务提供方主动通知消费方
​			实现
​				服务方注册关闭的钩子（Runtime.addShutdownHook ），捕获关闭事件
​				开启关闭标志，通知消费方此服务已下线，并且拒绝接受新的请求
​				等待一定的时间，保证已经接受的请求处理完成
​				对请求进行计数，接入请求计数加1，处理完计数减1，计数为0，唤醒阻塞中的线程，进行资源的释放

### 熔断限流

​			限流（服务方的自我保护）
​				单机限流
​					每个服务节点独立去执行限流逻辑
​				集群限流
​					依赖一个限流服务。调用端在发出请求时，先调用限流服务，如果达了限流阈值，返回限流异常
​			熔断（调用方的自我保护）
​				避免调用链中的异常请求，拖垮调用方甚至宕机
​				熔断器的工作机制主要是关闭、打开和半打开这三个状态之间的切换
​				在正常情况下，熔断器是关闭的
​				基于滑动窗口统计异常/超时的百分比，超过配置的阈值，熔断器打开；此时再发起请求，直接被熔断拦截
​				当熔断器打开一段时间后，会转为半打开状态。这时发送一个请求给服务端，如果能够正常地得到服务端的响应，则将状态置为关闭状态，否则设置为打开。

### 		业务分组（流量隔离）

​			不同的调用方，调用流量不同。当某个调用方的流量突增时，可能影响到其他调用方，导致整体的可用性降低
​			为业务方划分不同的分组，每个业务方只能调用指定分组内的服务
​			根据业务的重要程度的不同划分核心服务和非核心服务，当核心服务的流量突增时，为保证核心服务的可用性，可以将其他业务分组下的服务移到核心服务分组下
​			由于分组之后，业务调用方所能调用的服务减少，出错的概率就升高了，保证调用方的高可用，在调用方配置多个分组，并将配置的分组区分下主次分组，只有在主分组上的节点都不可用的情况下才去选择次分组节点，只要主分组里面的节点恢复正常，就把流量都切换到主分组

## 基础

### RPC通信流程

​			发布 RPC 服务，并将服务注册到服务注册中心上
​			当引用这个服务的应用启动时，会从服务注册中心订阅到相应服务的元数据信息。
​			当服务引用方拿到地址以后，就可以从中选取地址发起调用了

### 可扩展且向后兼容的协议

### 序列化

​			实现
​				JSON序列化
​				JDK 原生序列化
​				Protobuf
​				Hessian
​			优化点
​				对象尽量简单，没有太多的依赖关系，属性不要太多
​				入参对象与返回值对象体积不要太大，更不要传太大的集合
​				对象不要有复杂的继承关系

### 通信模型

​			Reactor模型
​			Proactor模型

### 动态代理

​			JDK动态代理
​			CGLib动态代理
​		功能点扩展
​			SPI机制

### 线程模型

​			IO线程池
​			业务线程池
​				接口级别的线程池
​				方法级别的线程池

### 调用方式

​			oneway
​			同步
​			异步
​				Future
​				Callback

其他		
		方法级别的缓存，减少请求次数
		请求合并，提高了吞吐量，但是增加了延迟

## 开源项目

​	octo-rpc（美团）
​	motan（微博）
​	dubbo（阿里）
​	sofa-rpc(蚂蚁)



# 其他资料

[微信红包系统是如何应对高并发的](http://www.52im.net/thread-2548-1-1.html)

[Feed流系统设计-总纲](https://zhuanlan.zhihu.com/p/72882547)

[现代IM系统中的消息系统架构 - 架构篇](https://zhuanlan.zhihu.com/p/65119683)

[system-design](https://www.hiredintech.com/system-design)

[程序员转型架构师，推荐你读这几本书](https://developer.aliyun.com/article/721088?spm=a2c6h.14164896.0.0.1fe999bdnE8TZn)

[架构师之路](https://z.itpub.net/stack/detail/10131)

[架构师之路17年精选80篇]https://mp.weixin.qq.com/s/CIPosICgva9haqstMDIHag
